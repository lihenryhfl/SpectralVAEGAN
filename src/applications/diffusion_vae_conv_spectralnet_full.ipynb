{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 30 16:07:32 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:1A:00.0  On |                  N/A |\n",
      "| 29%   30C    P8    17W / 250W |    503MiB / 10988MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:1B:00.0 Off |                  N/A |\n",
      "| 29%   28C    P8    11W / 250W |  10652MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:60:00.0 Off |                  N/A |\n",
      "| 30%   32C    P2    81W / 250W |  10632MiB / 10989MiB |     33%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:61:00.0 Off |                  N/A |\n",
      "| 29%   29C    P8    14W / 250W |  10652MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce RTX 208...  Off  | 00000000:B1:00.0 Off |                  N/A |\n",
      "| 29%   27C    P8     8W / 250W |  10654MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce RTX 208...  Off  | 00000000:B2:00.0 Off |                  N/A |\n",
      "| 29%   43C    P2    68W / 250W |  10652MiB / 10989MiB |     17%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce RTX 208...  Off  | 00000000:DA:00.0 Off |                  N/A |\n",
      "| 29%   36C    P2    71W / 250W |  10650MiB / 10989MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce RTX 208...  Off  | 00000000:DB:00.0 Off |                  N/A |\n",
      "| 30%   27C    P8    17W / 250W |  10654MiB / 10989MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../core')))\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Lambda, Subtract, Dense, Conv2DTranspose, Dropout, Reshape, Flatten, UpSampling2D\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.activations import relu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import mnist, cifar10, fashion_mnist\n",
    "from keras.losses import mse\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import train, costs, pairs\n",
    "from data import predict_with_K_fn\n",
    "from layer import stack_layers\n",
    "from util import LearningHandler, make_layer_list, train_gen, get_scale\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    from tensorflow.python import debug as tf_debug\n",
    "\n",
    "    K.set_session(tf_debug.LocalCLIDebugWrapperSession(K.get_session()))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET AND USEFUL FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_get(input_tensors, output_tensors, input_data):\n",
    "    input_data = input_data if isinstance(input_data, list) else [input_data]\n",
    "    input_tensors, output_tensors = list(input_tensors), list(output_tensors)\n",
    "    sess = K.get_session()\n",
    "    return sess.run(output_tensors, dict(zip(input_tensors, input_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_K_fn(K_fn, x, bs=1000):\n",
    "    '''\n",
    "    Convenience function: evaluates x by K_fn(x), where K_fn is\n",
    "    a Keras function, by batches of size 1000.\n",
    "    '''\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    num_outs = len(K_fn.outputs)\n",
    "    shapes = [list(output_.get_shape()) for output_ in K_fn.outputs]\n",
    "    shapes = [[len(x[0])] + s[1:] for s in shapes]\n",
    "    y = [np.empty(s) for s in shapes]\n",
    "    recon_means = []\n",
    "    for i in range(int((x[0].shape[0]-1)/bs + 1)):\n",
    "        x_batch = []\n",
    "        for x_ in x:\n",
    "            x_batch.append(x_[i*bs:(i+1)*bs])\n",
    "        temp = K_fn(x_batch)\n",
    "        for j in range(num_outs):\n",
    "            y[j][i*bs:(i+1)*bs] = temp[j]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.cbook import get_sample_data\n",
    "\n",
    "def imscatter(x, y, samples, shape, ax=None, zoom=1):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    m=samples.shape[0]\n",
    "    i=0\n",
    "    for x0, y0  in zip(x, y):\n",
    "        im = OffsetImage(samples[i].reshape(shape), zoom=zoom)\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "        i=i+1\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "from matplotlib.colors import ListedColormap\n",
    "# cmap1 = ListedColormap(sns.color_palette().as_hex())\n",
    "# cmap2 = ListedColormap(sns.color_palette('bright').as_hex())\n",
    "def plot(x, y=None, x2=None, y2=None, s=10, s2=None, alpha=0.5, alpha2=None, label1=None, label2=None, cmap1=None, cmap2=None, n_imgs=4, shuffle=True):\n",
    "    s2 = s if s2 is None else s2\n",
    "    alpha2 = alpha if alpha2 is None else alpha2\n",
    "    \n",
    "    if x.shape[1:] == (28, 28, 1) or x.shape[1:] == (32, 32, 3):\n",
    "        x = x.reshape(len(x), -1)\n",
    "    \n",
    "    n = x.shape[1]\n",
    "    \n",
    "    if n == 1:\n",
    "        g = plt.figure()\n",
    "        plt.scatter(np.zeros((n,)), x[:,1], c=y, s=s, alpha=alpha, label=label1, cmap=cmap1)\n",
    "        if x2 is not None:\n",
    "            plt.scatter(np.zeros((n,)), x2[:,1], c=y2, s=s2, alpha=alpha2, label=label2, cmap=cmap2)\n",
    "    if n == 3:\n",
    "        %matplotlib notebook\n",
    "        g = plt.figure()\n",
    "        ax = g.add_subplot(111, projection='3d')\n",
    "        ax.set_axis_off()\n",
    "        ax.scatter(x[:,0], x[:,1], x[:,2], c=y, s=s, alpha=alpha, label=label1)\n",
    "        if x2 is not None:\n",
    "            ax.scatter(x2[:,0], x2[:,1], x2[:,2], c=y2, s=s2, alpha=alpha2, label=label2)\n",
    "        g = (g, ax)\n",
    "    elif n == 784 or n == 3072 or n == 24000:\n",
    "        %matplotlib inline\n",
    "        n_imgs = min(n_imgs, len(x))\n",
    "        if n == 784:\n",
    "            img_shape, wdist = (28, 28), -.7\n",
    "        elif n == 3072:\n",
    "            img_shape, wdist = (32, 32, 3), -.7\n",
    "        elif n == 24000:\n",
    "            img_shape, wdist = (100, 80, 3), -.785\n",
    "        \n",
    "        if x2 is None:\n",
    "            g, axarr = plt.subplots(n_imgs, n_imgs)\n",
    "            if shuffle:\n",
    "                p = np.random.permutation(len(x))\n",
    "            else:\n",
    "                p = np.arange(len(x))\n",
    "            n = 0\n",
    "            while n < n_imgs * n_imgs:\n",
    "                i, j = int(n / n_imgs), n % n_imgs\n",
    "                axarr[i,j].axis('off')\n",
    "                if n < len(x):\n",
    "                    axarr[i,j].imshow(x[p[n]].reshape(img_shape))\n",
    "                n += 1\n",
    "        elif x2 is not None:\n",
    "            p = np.random.permutation(len(x))[:n_imgs]\n",
    "            for i in range(n_imgs):\n",
    "                idx = p[i]\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(x2[idx].reshape(img_shape))\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(x[idx].reshape(img_shape))\n",
    "                g = plt.figure()\n",
    "        g.subplots_adjust(wspace=wdist, hspace=0)\n",
    "    else:\n",
    "        g = plt.figure()\n",
    "        plt.scatter(x[:,0], x[:,1], c=y, s=s, alpha=alpha, label=label1, cmap=cmap1)\n",
    "        if x2 is not None:\n",
    "            plt.scatter(x2[:,0], x2[:,1], c=y2, s=s2, alpha=alpha2, label=label2, cmap=cmap2)\n",
    "            \n",
    "    if label1 is not None or label2 is not None:\n",
    "        plt.legend()\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bunny(n=2000, train_set_fraction=.8):\n",
    "    import bunny\n",
    "    a = [np.expand_dims(np.array(bunny.trace2[c]), axis=-1) for c in ['x', 'y', 'z']]\n",
    "    x = np.concatenate(a, axis=-1)\n",
    "    x = x.astype(np.float32)\n",
    "    x = x[np.logical_not(np.any(np.isnan(x), axis=1))]\n",
    "    y = np.arange(len(x))\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction, n=n)\n",
    "\n",
    "def generate_sphere(n=1200, train_set_fraction=.8):\n",
    "    r = 1\n",
    "    alpha = 4.0*np.pi*r*r/(n+1)\n",
    "    d = np.sqrt(alpha)\n",
    "    m_nu = int(np.round(np.pi/d))\n",
    "    d_nu = np.pi/m_nu\n",
    "    d_phi = alpha/d_nu\n",
    "    count = 0\n",
    "    coords = [[], [], []]\n",
    "    y = []\n",
    "    for i in range(0, m_nu):\n",
    "        nu = np.pi*(i+0.5)/m_nu\n",
    "        m_phi = int(np.round(2*np.pi*np.sin(nu)/d_phi))\n",
    "        for j in range(0, m_phi):\n",
    "            phi = 2*np.pi*j/m_phi\n",
    "            xp = r*np.sin(nu)*np.cos(phi)\n",
    "            yp = r*np.sin(nu)*np.sin(phi)\n",
    "            zp = r*np.cos(nu)\n",
    "            coords[0].append(xp)\n",
    "            coords[1].append(yp)\n",
    "            coords[2].append(zp)\n",
    "            y.append(i + j)\n",
    "            count = count +1\n",
    "            \n",
    "    x = np.array(coords).T\n",
    "    y = np.array(y).T\n",
    "        \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction, n=n)\n",
    "\n",
    "def generate_plane(n=1200, train_set_fraction=.8):\n",
    "    # compute number of points in each dimension\n",
    "    n_i = np.int(np.sqrt(n))\n",
    "    n = n_i ** 2\n",
    "    \n",
    "    # compute points on this grid\n",
    "    t = np.mgrid[0:1:1/n_i, 0:1:1/n_i].reshape(2,-1).T\n",
    "    t = np.concatenate([t, np.zeros(shape=(len(t),1))], axis=1)\n",
    "    \n",
    "    # compute rotation\n",
    "    A = np.random.normal(size=(3, 3))\n",
    "    A, _ = np.linalg.qr(A)\n",
    "    \n",
    "    x = np.dot(A, t.T).T\n",
    "    \n",
    "    # y is the sum of the ts\n",
    "    y = t[:,0] + t[:,1]\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_loop(n=1200, train_set_fraction=.8):\n",
    "    t = np.linspace(0, 2*np.pi, num=n+1)[:-1]\n",
    "    \n",
    "    # generate all three coordinates\n",
    "    x = np.empty((n, 3))\n",
    "    x[:,0] = np.cos(t)\n",
    "    x[:,1] = np.sin(2*t)\n",
    "    x[:,2] = np.sin(3*t)\n",
    "    \n",
    "    # y is just t\n",
    "    y = t\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_circle(n=1000, train_set_fraction=.8, alpha=4):\n",
    "    t = np.linspace(0, 2*np.pi, num=n+1)[:-1]\n",
    "#     t = np.log(np.linspace(1, alpha, num=n))\n",
    "    t = t / np.max(t) * 2 * np.pi\n",
    "    \n",
    "    # generate all three coordinates\n",
    "    x = np.empty((n, 2))\n",
    "    x[:,0] = np.cos(t)\n",
    "    x[:,1] = np.sin(t)\n",
    "    \n",
    "    # y is just t\n",
    "    y = t\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_line(n=1200, train_set_fraction=.8):\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    x1 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x2 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x = np.concatenate([x1, x2], axis=1)\n",
    "    \n",
    "    # generate labels\n",
    "#     y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "    y = x1\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_gaussians(n=1200, n_clusters=2, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / n_clusters)\n",
    "    r = 1\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    for x in np.linspace(0, 1, num=n_clusters):\n",
    "        clusters.append(np.random.normal(x, noise_sigma, size=(pts_per_cluster, 2)))\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate(clusters, axis=0)\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_cc(n=1200, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    r = 1\n",
    "\n",
    "    # generate clusters\n",
    "    theta1 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "    theta2 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "\n",
    "    cluster1 = np.concatenate((np.cos(theta1) * r, np.sin(theta1) * r), axis=1)\n",
    "    cluster2 = np.concatenate((np.cos(theta2) * r, np.sin(theta2) * r), axis=1)\n",
    "\n",
    "    # shift and reverse cluster 2\n",
    "    cluster2[:, 0] = -cluster2[:, 0] + 0.5\n",
    "    cluster2[:, 1] = -cluster2[:, 1] - 1\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate((cluster1, cluster2), axis=0)\n",
    "\n",
    "    # add noise to x\n",
    "    x = x + np.random.randn(x.shape[0], 2) * noise_sigma\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_faces(train_set_fraction=.8):\n",
    "    x = np.array(loadmat('frey_rawface.mat')['ff']).T\n",
    "    y = np.arange(len(x)) / len(x)\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_bulldog(train_set_fraction=.8):\n",
    "    x = np.load('BuldogBig.npy').T\n",
    "    y = np.arange(len(x))\n",
    "    print(x.shape)\n",
    "    \n",
    "    x = x / np.max(x)\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def generate_gaussian_grid(train_set_fraction=.8):\n",
    "    dim = 2\n",
    "    n_per_gaussian = 300\n",
    "    scale = .1\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            loc = i - 2, j - 2\n",
    "            xs.append(np.random.normal(loc=loc, scale=scale, size=(n_per_gaussian, dim)))\n",
    "            ys.append([(i * 5) + j] * n_per_gaussian)\n",
    "    x = np.concatenate(xs, axis=0)\n",
    "    y = np.concatenate(ys, axis=0)\n",
    "    \n",
    "    return shuffle_and_return_n(x, y, train_set_fraction)\n",
    "\n",
    "def shuffle_and_return_n(x, y, train_set_fraction, n=None):\n",
    "    if n is None:\n",
    "        n = len(x)\n",
    "    # shuffle\n",
    "    p = np.random.permutation(len(x))[:n]\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "    \n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed data\n",
    "def embed_data(x, dset):\n",
    "    '''\n",
    "    Convenience function: embeds x into the code space using the corresponding\n",
    "    autoencoder (specified by dset).\n",
    "    '''\n",
    "    if not len(x):\n",
    "        return np.zeros(shape=(0, 10))\n",
    "    if dset == 'reuters':\n",
    "        dset = 'reuters10k'\n",
    "\n",
    "    json_path = '../pretrain_weights/ae_{}.json'.format(dset)\n",
    "    weights_path = '../pretrain_weights/ae_{}_weights.h5'.format(dset)\n",
    "\n",
    "    with open(json_path) as f:\n",
    "        pt_ae = model_from_json(f.read())\n",
    "    pt_ae.load_weights(weights_path)\n",
    "\n",
    "    x = x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "    get_embeddings = K.function([pt_ae.input],\n",
    "                                  [pt_ae.layers[3].output])\n",
    "\n",
    "    get_reconstruction = K.function([pt_ae.layers[4].input],\n",
    "                                  [pt_ae.output])\n",
    "    x_embedded = predict_with_K_fn(get_embeddings, x)[0]\n",
    "    x_recon = predict_with_K_fn(get_reconstruction, x_embedded)[0]\n",
    "    reconstruction_mse = np.mean(np.square(x - x_recon))\n",
    "    print(\"using pretrained embeddings; sanity check, total reconstruction error:\", np.mean(reconstruction_mse))\n",
    "\n",
    "    del pt_ae\n",
    "\n",
    "    return x_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: max 1.0, min 0.0, shape (60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'mnist'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = x_train.reshape(len(x_train), -1) / 255\n",
    "    x_test = x_test.reshape(len(x_test), -1) / 255 \n",
    "    latent_dim = 10\n",
    "elif dataset == 'fmnist':\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = x_train.reshape(len(x_train), -1) / 255\n",
    "    x_test = x_test.reshape(len(x_test), -1) / 255 \n",
    "    latent_dim = 10\n",
    "elif dataset == 'mnist_conv':\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = np.expand_dims(x_train, -1) / 255\n",
    "    x_test = np.expand_dims(x_test, -1) / 255 \n",
    "    latent_dim = 10\n",
    "elif dataset == 'fmnist_conv':\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = np.expand_dims(x_train, -1) / 255\n",
    "    x_test = np.expand_dims(x_test, -1) / 255 \n",
    "    latent_dim = 10\n",
    "if dataset == 'cifar10_conv':\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255 \n",
    "    y_train, y_test = y_train.reshape(-1), y_test.reshape(-1)\n",
    "    latent_dim = 20\n",
    "elif dataset == 'bulldog':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_bulldog()\n",
    "    latent_dim = 3\n",
    "elif dataset == 'gaussians':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_gaussians(n=2000, n_clusters=2, train_set_fraction=0.85)\n",
    "    latent_dim = 5\n",
    "elif dataset == 'line':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_line(n=2000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'loop':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_loop(n=5000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'cc':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_cc(n=2000, noise_sigma=0.01, train_set_fraction=0.85)\n",
    "    latent_dim = 3\n",
    "elif dataset == 'circle':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_circle(n=1024, train_set_fraction=0.85, alpha=30)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'plane':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_plane()\n",
    "    latent_dim = 3\n",
    "elif dataset == 'sphere':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_sphere(n=2000)\n",
    "    latent_dim = 4\n",
    "elif dataset == 'bunny':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_bunny(n=20000)\n",
    "    latent_dim = 3\n",
    "elif dataset == 'faces':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_faces()\n",
    "    latent_dim = 2\n",
    "elif dataset == 'gaussian_grid':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_gaussian_grid()\n",
    "    latent_dim = 30\n",
    "\n",
    "x_all = np.concatenate([x_train, x_test], axis=0)\n",
    "    \n",
    "# normalize to between -1 and 1\n",
    "if 'mnist' not in dataset and 'cifar' not in dataset and 'bulldog' not in dataset and 'gaussian_grid' not in dataset:\n",
    "    m, M = np.min(x_train), np.max(x_train)\n",
    "    a = (M + m) / 2\n",
    "    b = (M - m) / 2\n",
    "    x_train, x_test = (x_train - a) / b, (x_test - a) / b\n",
    "print('IMPORTANT: max {}, min {}, shape {} {}'.format(np.max(x_train), np.min(x_train), x_train.shape, x_test.shape))\n",
    "\n",
    "if 'conv' in dataset:\n",
    "    arch = [\n",
    "        {'type': 'Conv2D', 'channels': 64, 'strides':(1,1), 'kernel':4},\n",
    "        {'type': 'Conv2D', 'channels': 64, 'strides':(1,1), 'kernel':4},\n",
    "        {'type': 'MaxPooling2D', 'pool_size': 2},\n",
    "        {'type': 'Conv2D', 'channels': 64, 'strides':(1,1), 'kernel':4},\n",
    "        {'type': 'Conv2D', 'channels': 64, 'strides':(1,1), 'kernel':4},\n",
    "        {'type': 'MaxPooling2D', 'pool_size': 2},\n",
    "#         {'type': 'Dropout', 'rate': 0.8},\n",
    "        {'type': 'Flatten'},\n",
    "        {'type': 'relu', 'size': 1024},\n",
    "        {'type': 'relu', 'size': 1024},\n",
    "        {'type': 'relu', 'size': 512},\n",
    "        {'type': 'linear', 'size': latent_dim},\n",
    "        ]\n",
    "else:\n",
    "#     arch = [\n",
    "#         {'type': 'relu', 'size': 500},\n",
    "#         {'type': 'linear', 'size': latent_dim},\n",
    "#         ]\n",
    "    arch = [\n",
    "            {'type': 'relu', 'size': 1024},\n",
    "            {'type': 'relu', 'size': 1024},\n",
    "            {'type': 'relu', 'size': 512},\n",
    "            {'type': 'relu', 'size': 10},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet:\n",
    "    def __init__(self, inputs, arch, siam_reg, y_true):\n",
    "        self.orig_inputs = inputs\n",
    "        # set up inputs\n",
    "        self.inputs = {\n",
    "                'A': inputs['Unlabeled'],\n",
    "                'B': Input(shape=inputs['Unlabeled'].get_shape().as_list()[1:]),\n",
    "                'Labeled': inputs['Labeled'],\n",
    "                }\n",
    "\n",
    "        self.y_true = y_true\n",
    "\n",
    "        # generate layers\n",
    "        self.layers = []\n",
    "        self.layers += make_layer_list(arch, 'siamese', siam_reg)\n",
    "\n",
    "        # create the siamese net\n",
    "        self.outputs = stack_layers(self.inputs, self.layers)\n",
    "\n",
    "        # add the distance layer\n",
    "        self.distance = Lambda(costs.euclidean_distance, output_shape=costs.eucl_dist_output_shape)([self.outputs['A'], self.outputs['B']])\n",
    "\n",
    "        #create the distance model for training\n",
    "        self.net = Model([self.inputs['A'], self.inputs['B']], self.distance)\n",
    "\n",
    "        # compile the siamese network\n",
    "        self.net.compile(loss=costs.get_contrastive_loss(m_neg=1, m_pos=0.05), optimizer='rmsprop')\n",
    "\n",
    "    def train(self, pairs_train, dist_train, pairs_val, dist_val,\n",
    "            lr, drop, patience, num_epochs, batch_size):\n",
    "        # create handler for early stopping and learning rate scheduling\n",
    "        self.lh = LearningHandler(\n",
    "                lr=lr,\n",
    "                drop=drop,\n",
    "                lr_tensor=self.net.optimizer.lr,\n",
    "                patience=patience)\n",
    "\n",
    "        # initialize the training generator\n",
    "        train_gen_ = train_gen(pairs_train, dist_train, batch_size)\n",
    "\n",
    "        # format the validation data for keras\n",
    "        validation_data = ([pairs_val[:, 0], pairs_val[:, 1]], dist_val)\n",
    "\n",
    "        # compute the steps per epoch\n",
    "        steps_per_epoch = int(len(pairs_train) / batch_size)\n",
    "\n",
    "        # train the network\n",
    "        hist = self.net.fit_generator(train_gen_, epochs=num_epochs, validation_data=validation_data, steps_per_epoch=steps_per_epoch, callbacks=[self.lh])\n",
    "\n",
    "        return hist\n",
    "\n",
    "    def predict(self, x, batch_sizes):\n",
    "        # compute the siamese embeddings of the input data\n",
    "        return train.predict(self.outputs['A'], x_unlabeled=x, inputs=self.orig_inputs, y_true=self.y_true, batch_sizes=batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNet:\n",
    "    def __init__(self, inputs, arch, spec_reg, y_true, y_train_labeled_onehot,\n",
    "            n_clusters, affinity, scale_nbr, n_nbrs, batch_sizes, normalized=False,\n",
    "            siamese_net=None, x_train=None, have_labeled=False):\n",
    "        self.y_true = y_true\n",
    "        self.y_train_labeled_onehot = y_train_labeled_onehot\n",
    "        self.inputs = inputs\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.normalized = normalized\n",
    "        # generate layers\n",
    "        self.layers = make_layer_list(arch[:-1], 'spectral', spec_reg)\n",
    "        self.layers += [\n",
    "                  {'type': 'tanh',\n",
    "                   'size': n_clusters,\n",
    "                   'l2_reg': spec_reg,\n",
    "                   'name': 'spectral_{}'.format(len(arch)-1)},\n",
    "                  {'type': 'Orthonorm', 'name':'orthonorm'}\n",
    "                  ]\n",
    "\n",
    "        # create spectralnet\n",
    "        self.outputs = stack_layers(self.inputs, self.layers)\n",
    "        self.net = Model(inputs=self.inputs['Unlabeled'], outputs=self.outputs['Unlabeled'])\n",
    "\n",
    "        # DEFINE LOSS\n",
    "\n",
    "        # generate affinity matrix W according to params\n",
    "        if affinity == 'siamese':\n",
    "            input_affinity = tf.concat([siamese_net.outputs['A'], siamese_net.outputs['Labeled']], axis=0)\n",
    "            x_affinity = siamese_net.predict(x_train, batch_sizes)\n",
    "        elif affinity in ['knn', 'full']:\n",
    "            input_affinity = tf.concat([self.inputs['Unlabeled'], self.inputs['Labeled']], axis=0)\n",
    "            x_affinity = x_train\n",
    "\n",
    "        # calculate scale for affinity matrix\n",
    "        scale = get_scale(x_affinity, self.batch_sizes['Unlabeled'], scale_nbr)\n",
    "\n",
    "        # create affinity matrix\n",
    "        if affinity == 'full':\n",
    "            W = costs.full_affinity(input_affinity, scale=scale)\n",
    "        elif affinity in ['knn', 'siamese']:\n",
    "            W = costs.knn_affinity(input_affinity, n_nbrs, scale=scale, scale_nbr=scale_nbr)\n",
    "\n",
    "        # if we have labels, use them\n",
    "        if have_labeled:\n",
    "            # get true affinities (from labeled data)\n",
    "            W_true = tf.cast(tf.equal(costs.squared_distance(y_true), 0),dtype='float32')\n",
    "\n",
    "            # replace lower right corner of W with W_true\n",
    "            unlabeled_end = tf.shape(self.inputs['Unlabeled'])[0]\n",
    "            W_u = W[:unlabeled_end, :]                  # upper half\n",
    "            W_ll = W[unlabeled_end:, :unlabeled_end]    # lower left\n",
    "            W_l = tf.concat((W_ll, W_true), axis=1)      # lower half\n",
    "            W = tf.concat((W_u, W_l), axis=0)\n",
    "\n",
    "            # create pairwise batch distance matrix self.Dy\n",
    "            y_ = tf.concat([self.outputs['Unlabeled'], self.outputs['Labeled']], axis=0)\n",
    "        else:\n",
    "            y_ = self.outputs['Unlabeled']\n",
    "\n",
    "        if self.normalized:\n",
    "            y_ = y_ / tf.reduce_sum(W, axis=1)\n",
    "\n",
    "        self.Dy = costs.squared_distance(y_)\n",
    "\n",
    "        # define loss\n",
    "        self.loss = K.sum(W * self.Dy) / (2 * batch_sizes['Unlabeled'])\n",
    "\n",
    "        # create the train step update\n",
    "        self.learning_rate = tf.Variable(0., name='spectral_net_learning_rate')\n",
    "        self.train_step = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "\n",
    "        # initialize spectralnet variables\n",
    "        K.get_session().run(tf.variables_initializer(self.net.trainable_weights))\n",
    "\n",
    "    def train(self, x_train_unlabeled, x_train_labeled, x_val_unlabeled,\n",
    "            lr, drop, patience, num_epochs):\n",
    "        # create handler for early stopping and learning rate scheduling\n",
    "        self.lh = LearningHandler(\n",
    "                lr=lr,\n",
    "                drop=drop,\n",
    "                lr_tensor=self.learning_rate,\n",
    "                patience=patience)\n",
    "\n",
    "        losses = np.empty((num_epochs,))\n",
    "        val_losses = np.empty((num_epochs,))\n",
    "\n",
    "        # begin spectralnet training loop\n",
    "        self.lh.on_train_begin()\n",
    "        i = 0\n",
    "        for i in range(num_epochs):\n",
    "            # train spectralnet\n",
    "            losses[i] = train.train_step(\n",
    "                    return_var=[self.loss],\n",
    "                    updates=self.net.updates + [self.train_step],\n",
    "                    x_unlabeled=x_train_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    batch_sizes=self.batch_sizes,\n",
    "                    x_labeled=x_train_labeled,\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batches_per_epoch=100)[0]\n",
    "\n",
    "            # get validation loss\n",
    "            val_losses[i] = train.predict_sum(\n",
    "                    self.loss,\n",
    "                    x_unlabeled=x_val_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x_train_unlabeled[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batch_sizes=self.batch_sizes)\n",
    "\n",
    "            # do early stopping if necessary\n",
    "            if self.lh.on_epoch_end(i, val_losses[i]):\n",
    "                print('STOPPING EARLY')\n",
    "                break\n",
    "\n",
    "            # print training status\n",
    "            print(\"Epoch: {}, loss={:2f}, val_loss={:2f}\".format(i, losses[i], val_losses[i]))\n",
    "\n",
    "        return losses[:i+1], val_losses[:i+1]\n",
    "\n",
    "    def predict(self, x):\n",
    "        # test inputs do not require the 'Labeled' input\n",
    "        inputs_test = {'Unlabeled': self.inputs['Unlabeled'], 'Orthonorm': self.inputs['Orthonorm']}\n",
    "        return train.predict(\n",
    "                    self.outputs['Unlabeled'],\n",
    "                    x_unlabeled=x,\n",
    "                    inputs=inputs_test,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot[0:0],\n",
    "                    batch_sizes=self.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpectralNet:\n",
    "#     def __init__(self, inputs, arch, spec_reg, y_true, y_train_labeled_onehot,\n",
    "#             n_clusters, affinity, scale_nbr, n_nbrs, batch_sizes, normalized=False,\n",
    "#             siamese_net=None, x_train=None, have_labeled=False, eps=1e-7):\n",
    "#         self.y_true = y_true\n",
    "#         self.y_train_labeled_onehot = y_train_labeled_onehot\n",
    "#         self.eps = eps\n",
    "#         self.inputs = inputs\n",
    "#         self.batch_sizes = batch_sizes\n",
    "#         self.normalized = normalized\n",
    "#         # generate layers\n",
    "#         self.layers = make_layer_list(arch[:-1], 'spectral', spec_reg)\n",
    "#         self.layers += [\n",
    "#                   {'type': 'linear',\n",
    "#                    'size': n_clusters,\n",
    "#                    'l2_reg': spec_reg,\n",
    "#                    'name': 'spectral_{}'.format(len(arch)-1)},\n",
    "#                   {'type': 'Orthonorm', 'name':'orthonorm'}\n",
    "#                   ]\n",
    "\n",
    "#         # create spectralnet\n",
    "#         self.outputs = stack_layers(self.inputs, self.layers)\n",
    "#         self.net = Model(inputs=self.inputs['Unlabeled'], outputs=self.outputs['Unlabeled'])\n",
    "\n",
    "#         # DEFINE LOSS\n",
    "\n",
    "#         # generate affinity matrix W according to params\n",
    "#         if siamese_net is not None:\n",
    "#             input_affinity = tf.concat([siamese_net.outputs['A'], siamese_net.outputs['Labeled']], axis=0)\n",
    "#             x_affinity = siamese_net.predict(x_train, batch_sizes)\n",
    "#         else:\n",
    "#             input_affinity = tf.concat([self.inputs['Unlabeled'], self.inputs['Labeled']], axis=0)\n",
    "#             x_affinity = x_train\n",
    "\n",
    "#         # calculate scale for affinity matrix\n",
    "#         scale = get_scale(x_affinity, self.batch_sizes['Unlabeled'], scale_nbr)\n",
    "\n",
    "#         # create affinity matrix\n",
    "#         W = costs.knn_affinity(input_affinity, n_nbrs, scale=scale, scale_nbr=scale_nbr)\n",
    "\n",
    "#         y_ = self.outputs['Unlabeled']\n",
    "            \n",
    "#         if self.normalized:\n",
    "#             # compute the row and column denominators\n",
    "#             row_norm = 1 / tf.reduce_sum(W, axis=1)\n",
    "#             col_norm = 1 / tf.reduce_sum(W, axis=0)\n",
    "            \n",
    "#             # apply them\n",
    "#             W = tf.einsum('j,ij->ij', col_norm, tf.einsum('i,ij->ij', row_norm, W))\n",
    "            \n",
    "#             # compute D^{-1/2} and apply it\n",
    "#             self.D_half_inv = dhv = tf.sqrt((1 / tf.reduce_sum(W, axis=1)) + self.eps)\n",
    "#             W = tf.einsum('j,ij->ij', dhv, tf.einsum('i,ij->ij', dhv, W))\n",
    "#             self.normalized_output = y_ * tf.expand_dims(dhv, -1)\n",
    "        \n",
    "#         self.Dy = costs.squared_distance(y_)\n",
    "\n",
    "#         # define loss\n",
    "#         self.loss = K.sum(W * self.Dy) / (2 * batch_sizes['Unlabeled'])\n",
    "\n",
    "#         # create the train step update\n",
    "#         self.learning_rate = tf.Variable(0., name='spectral_net_learning_rate')\n",
    "#         self.train_step = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "# #         self.train_step = tf.train.AdamOptimizer().minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "        \n",
    "#         # initialize spectralnet variables\n",
    "#         K.get_session().run(tf.variables_initializer(self.net.trainable_weights))\n",
    "\n",
    "#     def train(self, x_train_unlabeled, x_train_labeled, x_val_unlabeled,\n",
    "#             lr, drop, patience, num_epochs):\n",
    "#         # create handler for early stopping and learning rate scheduling\n",
    "#         self.lh = LearningHandler(\n",
    "#                 lr=lr,\n",
    "#                 drop=drop,\n",
    "#                 lr_tensor=self.learning_rate,\n",
    "#                 patience=patience)\n",
    "\n",
    "#         losses = np.empty((num_epochs,))\n",
    "#         val_losses = np.empty((num_epochs,))\n",
    "\n",
    "#         # begin spectralnet training loop\n",
    "#         self.lh.on_train_begin()\n",
    "#         i = 0\n",
    "#         for i in range(num_epochs):\n",
    "#             # train spectralnet\n",
    "#             losses[i] = train.train_step(\n",
    "#                     return_var=[self.loss],\n",
    "#                     updates=self.net.updates + [self.train_step],\n",
    "#                     x_unlabeled=x_train_unlabeled,\n",
    "#                     inputs=self.inputs,\n",
    "#                     y_true=self.y_true,\n",
    "#                     batch_sizes=self.batch_sizes,\n",
    "#                     x_labeled=x_train_labeled,\n",
    "#                     y_labeled=self.y_train_labeled_onehot,\n",
    "#                     batches_per_epoch=100)[0]\n",
    "\n",
    "#             # get validation loss\n",
    "#             val_losses[i] = train.predict_sum(\n",
    "#                     self.loss,\n",
    "#                     x_unlabeled=x_val_unlabeled,\n",
    "#                     inputs=self.inputs,\n",
    "#                     y_true=self.y_true,\n",
    "#                     x_labeled=x_train_unlabeled[0:0],\n",
    "#                     y_labeled=self.y_train_labeled_onehot,\n",
    "#                     batch_sizes=self.batch_sizes)\n",
    "\n",
    "#             # do early stopping if necessary\n",
    "#             if self.lh.on_epoch_end(i, val_losses[i]):\n",
    "#                 print('STOPPING EARLY')\n",
    "#                 break\n",
    "\n",
    "#             # print training status\n",
    "#             print(\"Epoch: {}, loss={:2f}, val_loss={:2f}\".format(i, losses[i], val_losses[i]))\n",
    "\n",
    "#         return losses[:i+1], val_losses[:i+1]\n",
    "    \n",
    "#     def predict(self, x):\n",
    "#         # test inputs do not require the 'Labeled' input\n",
    "#         inputs_test = {'Unlabeled': self.inputs['Unlabeled'], 'Orthonorm': self.inputs['Orthonorm'], 'Labeled':self.inputs['Labeled']}\n",
    "#         pred_tensor = self.normalized_output if self.normalized else self.outputs['Unlabeled']\n",
    "#         return train.predict(\n",
    "#                     pred_tensor,\n",
    "#                     x_unlabeled=x,\n",
    "#                     inputs=inputs_test,\n",
    "#                     y_true=self.y_true,\n",
    "#                     x_labeled=x[0:0],\n",
    "#                     y_labeled=self.y_train_labeled_onehot[0:0],\n",
    "#                     batch_sizes=self.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_nearest_k(D, k, drop_self=True, randomize=False):\n",
    "            n_batch = tf.shape(D)[-1]\n",
    "            if drop_self:\n",
    "                _, idxs = tf.nn.top_k(-D, k=k+1)\n",
    "                idxs = idxs[:,1:]\n",
    "            else:\n",
    "                _, idxs = tf.nn.top_k(-D, k=k)\n",
    "            # create a random index \n",
    "            if randomize:\n",
    "                range_D = tf.expand_dims(tf.range(n_batch * k), -1)\n",
    "                p = tf.expand_dims(tf.random.uniform(shape=(n_batch * k,), maxval=k, dtype=tf.dtypes.int32), -1)\n",
    "                p = tf.concat([range_D, p], axis=1)\n",
    "                # draw from the top k values using this index\n",
    "                idx = tf.expand_dims(tf.gather_nd(idxs, p), -1)\n",
    "            else:\n",
    "                print(\"IMPORTANT\", idxs.shape)\n",
    "                idx = tf.reshape(idxs, (n_batch * k, 1))\n",
    "            \n",
    "            return idx\n",
    "        \n",
    "class SVG:\n",
    "    def __init__(self, inputs, spectralnet, orig_dim, remove_dim=0, \n",
    "                 pca=True, alpha=1., normalize_factor=.1, k=16, eps=1e-5, lam=1e-1,\n",
    "                 arch=[500], conv_decoder=False):\n",
    "        optimizer = 'adam'\n",
    "#         optimizer = RMSprop(lr=0.00005)\n",
    "        self.input = inputs['Unlabeled']\n",
    "        self.orig_dim = orig_dim\n",
    "        self.eps = eps\n",
    "        self.lam = lam\n",
    "        self.pca = pca\n",
    "        self.alpha = float(alpha)\n",
    "        self.k = k\n",
    "        self.remove_dim = remove_dim\n",
    "        self.conv_decoder = conv_decoder\n",
    "        self.arch = arch\n",
    "        \n",
    "        if conv_decoder:\n",
    "            print(\"USING CONVOLUTIONAL DECODER! CHECK OUTPUT SHAPE:\", self.orig_dim)\n",
    "        else:\n",
    "            print(\"USING DENSE DECODER! FLATTENING OUTPUT SHAPE IF NOT ALREADY FLAT:\", self.orig_dim, np.prod(self.orig_dim))\n",
    "            self.orig_dim = np.prod(self.orig_dim)\n",
    "        \n",
    "        self.x = x = self.copy_spectralnet(spectralnet)\n",
    "        \n",
    "        #\n",
    "        # DEFINE ALL LOSSES\n",
    "        #\n",
    "        def top_k_loss(D, k):\n",
    "            # get nearest (i.e., largest negative distance) neighbors of each point\n",
    "            vals, _ = tf.nn.top_k(-D, k=k)\n",
    "\n",
    "            # remove self as neighbor, negate to get positive distances again\n",
    "            vals = -vals\n",
    "                \n",
    "            return K.sum(vals)\n",
    "        def kl_loss(_, __):\n",
    "            log_e = 2 * self.half_log_e\n",
    "            v = tf.reshape(self.v, (-1, self.latent_dim, self.latent_dim))\n",
    "            # find local neighborhood of each point in batch\n",
    "            D = self.pairwise_distances(self.z, self.z_mu)\n",
    "            n_batch = tf.shape(D)[-1]\n",
    "            idx = pick_nearest_k(D, self.k, drop_self=True)\n",
    "            omn = z_mu_nb = tf.gather_nd(self.z_mu, idx)\n",
    "            z_mu_nb = tf.reshape(z_mu_nb, shape=(n_batch, self.k, self.latent_dim))\n",
    "            print(\"z_mu_nb\", z_mu_nb.shape)\n",
    "            \n",
    "            # obtain covariance of each local neighborhood\n",
    "            cov_nb = tf.einsum('ikj,ikl->ijl', z_mu_nb, z_mu_nb)\n",
    "            cov_nb = tf.Print(cov_nb, [tf.shape(omn), tf.shape(z_mu_nb), omn[:self.k], z_mu_nb[0,:,:]], summarize=10)\n",
    "            \n",
    "            # obtain eigendecomposition of local neighborhood\n",
    "            e_nb, v_nb = tf.linalg.eigh(cov_nb)\n",
    "            e_nb += self.lam\n",
    "            \n",
    "            # take log (used in final loss) BEFORE truncating\n",
    "            log_e_nb = tf.log(e_nb + self.eps)\n",
    "            \n",
    "            e_nb *= self.alpha\n",
    "            \n",
    "            # compute trace of Sigma_cov^{-1} Sigma_theta\n",
    "            inv_sigma_nb = tf.einsum('ijk,ilk->ijl', tf.einsum('ijk,ik->ijk', v_nb, 1 / e_nb), v_nb)\n",
    "            \n",
    "            sigma_vae = tf.einsum('ijk,ilk->ijl', tf.einsum('ijk,ik->ijk', v, self.e), v)\n",
    "            half_prod = tf.einsum('ikj,ikl->ijl', inv_sigma_nb, sigma_vae)\n",
    "            trace = tf.linalg.svd(half_prod, compute_uv=False)\n",
    "            \n",
    "            # compute KL divergence\n",
    "            self.kl_loss = tf.reduce_sum(log_e_nb - log_e - 1 + trace)\n",
    "            return self.kl_loss\n",
    "        def pca_loss(_, __):\n",
    "            if self.pca:\n",
    "                self.pca_loss = K.sum(mse(self.pca_input, self.pca_recon)) * np.prod(self.orig_dim)\n",
    "            else:\n",
    "                self.pca_loss = tf.constant(0.)\n",
    "            return self.pca_loss\n",
    "        def neighborhood_loss(_, __):\n",
    "            # involves two bursts, on-manifold burst and off-manifold burst\n",
    "            z = self.z\n",
    "            x_recon = self.x_recon\n",
    "            \n",
    "            # obtain pairwise distances (size(recon) x size(input))\n",
    "            D = self.pairwise_distances(z, self.z_mu)\n",
    "            n_batch = tf.shape(D)[-1]\n",
    "            idx = pick_nearest_k(D, self.k, drop_self=True)\n",
    "            \n",
    "            # now compute neighborhood\n",
    "            orig_dim = np.prod(self.orig_dim)\n",
    "            data_flat_shape = (-1, np.prod(self.orig_dim))\n",
    "            input_ = tf.reshape(self.input, data_flat_shape)\n",
    "            print(\"important input shape\", input_.shape)\n",
    "            input_neighborhood = tf.gather_nd(input_, idx)\n",
    "            x_recon_flattened_expanded = tf.reshape(x_recon, data_flat_shape + (1,))\n",
    "            x_recon = tf.reshape(tf.tile(x_recon_flattened_expanded, [1, self.k, 1]), data_flat_shape)\n",
    "            print(\"NEIGHBORHOOD AND RECON SHAPES:\", input_neighborhood.shape, x_recon.shape)\n",
    "            self.neighborhood_loss = tf.reduce_sum(mse(input_neighborhood, x_recon)) / self.k\n",
    "            \n",
    "            return self.neighborhood_loss\n",
    "        def vae_loss(_, __):\n",
    "            return self.loss\n",
    "        \n",
    "        #\n",
    "        # DEFINE LAYERS\n",
    "        #\n",
    "\n",
    "        # create encoder\n",
    "        self.x_enc = x_enc = self.build_encoder(x, arch=self.arch, remove_dim=remove_dim, pca=self.pca)\n",
    "        self.encoder = Model(inputs=self.input, outputs=x_enc)\n",
    "\n",
    "        # create decoder\n",
    "        self.x_recon = x_recon = self.build_decoder(x_enc, arch=self.arch)\n",
    "        self.decoder_input = Input(shape=(self.latent_dim,), name='UnlabeledInput')\n",
    "        self.decoder_output = self.build_decoder(self.decoder_input, arch=self.arch)\n",
    "        self.decoder = Model(inputs=self.decoder_input, outputs=self.decoder_output)\n",
    "        \n",
    "        # create normalized decoder\n",
    "        x_enc_norm = self.build_encoder(x, arch=self.arch, normalize_cov=normalize_factor, pca=self.pca)\n",
    "        self.x_recon_norm = self.build_decoder(x_enc_norm, arch=self.arch)\n",
    "        \n",
    "        if self.pca:\n",
    "            self.pcae = Model(inputs=self.input, outputs=self.pca_recon)\n",
    "            self.pc = Model(inputs=self.input, outputs=self.pc_embedding)\n",
    "            self.pcae.compile(optimizer=optimizer, loss=pca_loss)\n",
    "            \n",
    "        #\n",
    "        # COMPUTE LOSS\n",
    "        #\n",
    "        losses = [kl_loss, pca_loss, neighborhood_loss]\n",
    "        self.init_losses = [l(None, None) for l in losses]\n",
    "        loss_weights = [1, 0, 1]\n",
    "        # initialize losses\n",
    "        self.loss = sum([a * b if b != 0 else K.constant(0.) for a, b in zip(self.init_losses, loss_weights)])\n",
    "        \n",
    "        #\n",
    "        # ASSEMBLE NETWORK\n",
    "        #\n",
    "        self.vae = Model(inputs=self.input, outputs=self.x_recon)\n",
    "        self.vae.compile(optimizer=optimizer, loss=vae_loss)\n",
    "        \n",
    "    def pairwise_distances(self, A, B):\n",
    "        r_A, r_B = tf.reduce_sum(A*A, 1), tf.reduce_sum(B*B, 1)\n",
    "\n",
    "        # turn r into column vector\n",
    "        r_A, r_B = tf.reshape(r_A, [-1, 1]), tf.reshape(r_B, [-1, 1])\n",
    "        D = r_A - 2 * tf.matmul(A, B, transpose_b=True) + tf.transpose(r_B)\n",
    "\n",
    "        return D\n",
    "        \n",
    "    def build_decoder(self, x, arch):\n",
    "        if not hasattr(self, 'decoder_layers'):\n",
    "            if self.conv_decoder:\n",
    "                in_channels = 1\n",
    "                out_channels = 1 # int(self.input.shape[-1])\n",
    "                pix = 28 # int(self.input.shape[-2])\n",
    "                reshaped_dim = [int(pix / 4), int(pix / 4), in_channels]\n",
    "                inputs_decoder = int(np.prod(reshaped_dim))\n",
    "                keep_prob = 0.8\n",
    "                self.decoder_layers = [\n",
    "#                     Dense(inputs_decoder),\n",
    "#                     LeakyReLU(),\n",
    "#                     Dense(inputs_decoder * 2 + 1),\n",
    "#                     LeakyReLU(),\n",
    "#                     Reshape(reshaped_dim),\n",
    "#                     Conv2DTranspose(filters=64, kernel_size=4, strides=2, padding='same', activation='relu'),\n",
    "#                     Dropout(keep_prob),\n",
    "#                     Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "#                     Dropout(keep_prob),\n",
    "#                     Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "#                     Flatten(),\n",
    "#                     Dense(np.prod(self.orig_dim)),\n",
    "#                     LeakyReLU(),\n",
    "                    Dense(int(inputs_decoder / 2)),\n",
    "                    LeakyReLU(),\n",
    "                    Dense(inputs_decoder),\n",
    "                    LeakyReLU(),\n",
    "                    Reshape(reshaped_dim),\n",
    "                    Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "                    Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "                    UpSampling2D(),\n",
    "                    Conv2DTranspose(filters=64, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "                    Conv2DTranspose(filters=out_channels, kernel_size=4, strides=1, padding='same', activation='relu'),\n",
    "                    UpSampling2D(),\n",
    "                    Reshape([pix * pix * out_channels]),\n",
    "#                     Dense(np.prod(self.orig_dim)),\n",
    "#                     LeakyReLU(),\n",
    "                    \n",
    "                    ]\n",
    "            else:\n",
    "                self.decoder_layers = [Dense(a, activation='relu') for a in arch]\n",
    "                self.decoder_layers.append(Dense(self.orig_dim, activation='linear'))\n",
    "\n",
    "        xs = [x]\n",
    "        for l in self.decoder_layers:\n",
    "            xs.append(l(xs[-1]))\n",
    "#             x = l(x)\n",
    "        x = xs[-1]\n",
    "        self.decoder_xs = xs\n",
    "        return x\n",
    "        \n",
    "    def build_encoder(self, x, arch, pca=False, normalize_cov=False, no_noise=False, remove_dim=0):\n",
    "        if pca and not hasattr(self, 'pca_layers'):\n",
    "            self.pca_layers = [Dense(self.latent_dim, activation='linear'), \n",
    "                               Dense(self.spectralnet_dim, activation='linear')]\n",
    "            \n",
    "        if not hasattr(self, 'encoder_layers'):\n",
    "            self.encoder_precov_layers = [Dense(a, activation='relu') for a in arch]\n",
    "            self.encoder_precov_layers.append(Dense(self.latent_dim * self.latent_dim, activation='linear'))\n",
    "            self.encoder_eig_layers = [Dense(a, activation='relu') for a in arch]\n",
    "            self.encoder_eig_layers.append(Dense(self.latent_dim, activation='linear'))\n",
    "            \n",
    "        # assemble pca layer (a linear autoencoder) and define mu (the latent embedding of this layer)\n",
    "        if pca:\n",
    "            if not hasattr(self, 'pca_input'):\n",
    "                self.pca_input = x\n",
    "            \n",
    "            self.pc_embedding = x = self.pca_layers[0](x)\n",
    "\n",
    "            if not hasattr(self, 'pca_recon'):\n",
    "                self.pca_recon = self.pca_layers[1](x)\n",
    "\n",
    "        # define mu (the latent embedding of the pca layer)\n",
    "        mu = x\n",
    "        if not hasattr(self, 'mu'):\n",
    "            self.z_mu = mu\n",
    "        \n",
    "        x_precov = x\n",
    "        # get covariance precursor\n",
    "        for l in self.encoder_precov_layers:\n",
    "            x_precov = l(x_precov)\n",
    "            \n",
    "        x_eig = x\n",
    "        # get eigenvalues\n",
    "        for l in self.encoder_eig_layers:\n",
    "            x_eig = l(x_eig)\n",
    "        \n",
    "        # sample latent space (and normalize covariances if we're trying to do random walks)\n",
    "        if not hasattr(self, 'encoder_sampling_layer'):\n",
    "            f = partial(self.sampling, normalize_cov=normalize_cov, remove_dim=remove_dim)\n",
    "            self.encoder_sampling_layer = Lambda(f, output_shape=(self.latent_dim,), name='z')\n",
    "            \n",
    "        if no_noise:\n",
    "            cur_encoder_sampling_layer = Lambda(lambda x_: x_[0], output_shape=(self.latent_dim,))\n",
    "            \n",
    "        # get encoder embedding\n",
    "        x_enc = self.encoder_sampling_layer([mu, x_precov, x_eig])\n",
    "        \n",
    "        return x_enc\n",
    "        \n",
    "    def copy_spectralnet(self, spectralnet):\n",
    "        xs = [self.input]\n",
    "        layers = []\n",
    "        for l in spectralnet.net.layers[1:-1]:\n",
    "            l.trainable = False\n",
    "            xs.append(l(xs[-1]))\n",
    "            layers.append(l)\n",
    "\n",
    "        pre_x = xs[-1]\n",
    "        # add orthonorm layer\n",
    "        sess = K.get_session()\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            v = tf.get_variable(\"ortho_weights_store\")\n",
    "        ows = sess.run(v)\n",
    "        t_ows = K.variable(ows)\n",
    "        l = Lambda(lambda x: K.dot(x, t_ows))\n",
    "        l.trainable = False\n",
    "        xs.append(l(xs[-1]))\n",
    "        layers.append(l)\n",
    "\n",
    "        x = xs[-1]\n",
    "\n",
    "        self.sn = Model(inputs=self.input, outputs=x)\n",
    "\n",
    "        self.spectralnet_dim = int(x.get_shape()[1])\n",
    "        if self.pca:\n",
    "            print(\"PCA\")\n",
    "            self.latent_dim = self.spectralnet_dim - 1\n",
    "        else:\n",
    "            print(\"NO PCA\")\n",
    "            self.latent_dim = self.spectralnet_dim\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def sampling(self, args, normalize_cov, remove_dim):\n",
    "        # get args\n",
    "        z_mean, precov, e = args\n",
    "        \n",
    "        # reshape precov and compute cov = precov x precov.T\n",
    "        cov = tf.reshape(precov, (-1, self.latent_dim, self.latent_dim))\n",
    "\n",
    "        # perform eigendecomposition\n",
    "        v, _ = tf.linalg.qr(cov)\n",
    "        \n",
    "        if not hasattr(self, 'e'):\n",
    "            self.half_log_e, self.e, self.v = e, tf.exp(2 * e), tf.reshape(v, (-1, self.latent_dim * self.latent_dim))\n",
    "            \n",
    "        dim = self.latent_dim\n",
    "        \n",
    "        # get shapes\n",
    "        batch = K.shape(z_mean)[0]\n",
    "                \n",
    "        # sample from normal distribution\n",
    "        epsilon = K.random_normal(stddev=self.alpha, shape=(batch, K.int_shape(z_mean)[1]))\n",
    "        \n",
    "        # get sqrt covariance matrix stack\n",
    "        sqrt_sigma = tf.einsum('ijk,ilk->ijl', tf.einsum('ijk,ik->ijk', v, tf.sqrt(self.e)), v)\n",
    "        \n",
    "        # multiply covariance matrix stack with random normal vector\n",
    "        sqrt_sigma_epsilon = tf.einsum('ijk,ik->ij', sqrt_sigma, epsilon)\n",
    "        \n",
    "        if not hasattr(self, 'sqrt_sigma'):\n",
    "            self.sqrt_sigma = tf.reshape(sqrt_sigma, (-1, self.latent_dim * self.latent_dim))\n",
    "        \n",
    "        # assembled output\n",
    "        z = z_mean + sqrt_sigma_epsilon\n",
    "        \n",
    "        if not hasattr(self, 'z'):\n",
    "            self.z = z\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def generate_from_samples(self, x, return_mu_sigma=False, normalize_cov=False):\n",
    "        _x_recon = self.x_recon_norm if normalize_cov else self.x_recon\n",
    "        get_fn = K.function([self.input], [_x_recon, self.z_mu, self.v, self.e, self.x_enc])\n",
    "        x_recon, z_mu, z_sigma_v, z_sigma_lam, _x_enc = predict_with_K_fn(get_fn, x)\n",
    "        if return_mu_sigma:\n",
    "            return x_recon, z_mu, z_sigma_v, z_sigma_lam, _x_enc\n",
    "        else:\n",
    "            return x_recon\n",
    "        \n",
    "    def train_pca(self, x_train, x_val=None, epochs=1, batch_size=128, patience=5):\n",
    "        if x_val is not None:\n",
    "            val_data = list((x_val, x_val))\n",
    "        else:\n",
    "            val_data = None\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "        \n",
    "        self.pcae.fit(x=x_train, y=x_train, epochs=epochs, batch_size=batch_size, validation_data=val_data, callbacks=[earlystop], verbose=2)\n",
    "        \n",
    "    def train(self, X_train, batch_size=128, epochs=100):      \n",
    "        self.vae_loss = []\n",
    "        last_cov = np.zeros((self.latent_dim, self.latent_dim))\n",
    "        cov_x = X_train[np.random.randint(0, X_train.shape[0], 1)]\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            samples = X_train[idx]\n",
    "            vae_loss = self.vae.train_on_batch([samples], [samples])\n",
    "            self.vae_loss.append(vae_loss)\n",
    "\n",
    "            if epoch % 25 == 0:\n",
    "                # Plot the progress\n",
    "                loss_names = ['kl_loss', 'pca_loss','neighborhood_loss']\n",
    "                loss_string = \"{} [VAE loss: {}] [\" + \": {}] [\".join(loss_names) + \": {}]\"\n",
    "                losses = self.init_losses\n",
    "                loss_vals = K.get_session().run(losses, feed_dict={self.input: samples})\n",
    "                print(loss_string.format(epoch, vae_loss, *loss_vals))\n",
    "                \n",
    "                # now get variance of the covariance vectors with respect to some fixed vector\n",
    "                cov, val = K.get_session().run([self.v, self.e], feed_dict={self.input: cov_x})\n",
    "                cov = cov.reshape((self.latent_dim, self.latent_dim))\n",
    "                print('vector covariance:\\n', cov.dot(last_cov.T))\n",
    "                print(cov.T.dot(last_cov))\n",
    "                print(val)\n",
    "                last_cov = cov\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_dim = False\n",
    "pca = False\n",
    "# latent_dim += 1\n",
    "k = 2\n",
    "bsize = min(1024, len(x_train))\n",
    "\n",
    "# NOTE: currently the train and test sets are combined\n",
    "\n",
    "# split = int(len(x_train)*0.8)\n",
    "# x_train, x_val = x_train[:split], x_train[split:]\n",
    "# y_train, y_val = y_train[:split], y_train[split:]\n",
    "\n",
    "x_train = np.concatenate([x_train, x_test], axis=0)\n",
    "y_train = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "# plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\n",
    "# g = plot(x_train, y_train)\n",
    "# g = plot(x_test, y_test)\n",
    "def plot_dots(x):\n",
    "    sns.set()\n",
    "    sns.despine()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.scatter(x[:,0], x[:,1], s=100, alpha=.1)\n",
    "    major_ticks = np.arange(-2, 3, 1)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xticks(major_ticks)\n",
    "    ax.set_yticks(major_ticks)\n",
    "    plt.xlim((-2.5208333333, 2.5208333333))\n",
    "    plt.ylim((-2.5208333333, 2.5208333333))\n",
    "    \n",
    "if dataset == 'gaussian_grid':\n",
    "    g = plot_dots(x_train)\n",
    "else:\n",
    "    g = plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    n_clusters = latent_dim + 1\n",
    "else:\n",
    "    n_clusters = latent_dim\n",
    "\n",
    "batch_sizes = {\n",
    "    'Unlabeled': bsize,\n",
    "    'Labeled': bsize,\n",
    "    'Orthonorm': bsize,\n",
    "    }\n",
    "\n",
    "# input_shape = x_train.shape[1:]\n",
    "# y_true = tf.placeholder(tf.float32, shape=(None, n_clusters), name='y_true')\n",
    "# y_train_labeled_onehot = np.empty((0, len(np.unique(y_train))))\n",
    "# inputs = {\n",
    "#     'Unlabeled': Input(shape=input_shape, name='UnlabeledInput'),\n",
    "#     'Labeled': Input(shape=input_shape, name='LabeledInput'),\n",
    "#     'Orthonorm': Input(shape=input_shape, name='OrthonormInput'),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "using pretrained embeddings; sanity check, total reconstruction error: 0.008152941685746977\n",
      "using pretrained embeddings; sanity check, total reconstruction error: 0.008152941685746977\n",
      "computing k=2 nearest neighbors...\n",
      "creating pairs...\n",
      "ks 70000 2 2 2\n",
      "Iter: 0/70000\n",
      "Iter: 10000/70000\n",
      "Iter: 20000/70000\n",
      "Iter: 30000/70000\n",
      "Iter: 40000/70000\n",
      "Iter: 50000/70000\n",
      "Iter: 60000/70000\n",
      "computing k=2 nearest neighbors...\n",
      "creating pairs...\n",
      "ks 70000 2 2 2\n",
      "Iter: 0/70000\n",
      "Iter: 10000/70000\n",
      "Iter: 20000/70000\n",
      "Iter: 30000/70000\n",
      "Iter: 40000/70000\n",
      "Iter: 50000/70000\n",
      "Iter: 60000/70000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/400\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0251 - val_loss: 0.0207\n",
      "Epoch 2/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0188 - val_loss: 0.0177\n",
      "Epoch 3/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0177 - val_loss: 0.0173\n",
      "Epoch 4/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0171 - val_loss: 0.0168\n",
      "Epoch 5/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 6/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 7/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0160 - val_loss: 0.0159\n",
      "Epoch 8/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 9/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0156\n",
      "Epoch 10/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0154 - val_loss: 0.0154\n",
      "Epoch 11/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0152 - val_loss: 0.0154\n",
      "Epoch 12/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 13/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0148 - val_loss: 0.0151\n",
      "Epoch 14/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 15/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0144 - val_loss: 0.0149\n",
      "Epoch 16/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 17/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 18/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 19/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 20/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0144\n",
      "Epoch 21/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0134 - val_loss: 0.0143\n",
      "Epoch 22/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0133 - val_loss: 0.0143\n",
      "Epoch 23/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 24/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0141\n",
      "Epoch 25/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0129 - val_loss: 0.0139\n",
      "Epoch 26/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0128 - val_loss: 0.0139\n",
      "Epoch 27/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 28/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 29/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0125 - val_loss: 0.0138\n",
      "Epoch 30/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 31/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0137\n",
      "Epoch 32/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 33/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0135\n",
      "Epoch 34/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 35/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 36/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 37/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 38/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 39/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0132\n",
      "Epoch 40/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 41/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 42/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 43/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 44/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 45/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 46/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 47/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 48/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 49/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 50/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 51/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 52/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 53/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 54/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 55/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0103 - val_loss: 0.0126\n",
      "Epoch 56/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 57/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 58/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 59/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 60/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 61/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 62/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 63/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 64/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 65/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 66/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 67/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 68/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 69/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 70/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 71/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0096 - val_loss: 0.0123\n",
      "Epoch 72/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 73/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 74/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0095 - val_loss: 0.0123\n",
      "Epoch 75/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0094 - val_loss: 0.0122\n",
      "Epoch 76/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0094 - val_loss: 0.0121\n",
      "Epoch 77/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 78/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0120\n",
      "Epoch 79/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 80/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 81/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 82/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 83/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0092 - val_loss: 0.0119\n",
      "Epoch 84/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 85/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 86/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 87/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 88/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 89/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 90/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 91/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 92/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 93/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 94/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 95/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 96/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 97/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 98/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 99/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0088 - val_loss: 0.0119\n",
      "Epoch 100/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0118\n",
      "Epoch 101/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 102/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0118\n",
      "Epoch 103/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0087 - val_loss: 0.0119\n",
      "Epoch 104/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 105/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 106/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 107/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 108/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0085 - val_loss: 0.0116\n",
      "Epoch 109/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 110/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 111/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 112/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0085 - val_loss: 0.0116\n",
      "Epoch 113/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 114/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0120\n",
      "Epoch 115/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0118\n",
      "Epoch 116/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0117\n",
      "Epoch 117/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0115\n",
      "Epoch 118/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 119/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0084 - val_loss: 0.0116\n",
      "Epoch 120/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 121/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0084 - val_loss: 0.0119\n",
      "Epoch 122/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 123/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 124/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 125/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0117\n",
      "Epoch 126/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 127/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0115\n",
      "Epoch 128/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 129/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0115\n",
      "Epoch 130/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 131/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0082 - val_loss: 0.0117\n",
      "Epoch 132/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0081 - val_loss: 0.0115\n",
      "Epoch 133/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0082 - val_loss: 0.0116\n",
      "Epoch 134/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 135/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0070 - val_loss: 0.0107\n",
      "Epoch 136/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0063 - val_loss: 0.0105\n",
      "Epoch 137/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0061 - val_loss: 0.0105\n",
      "Epoch 138/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0061 - val_loss: 0.0105\n",
      "Epoch 139/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 140/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 141/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 142/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 143/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 144/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 145/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 146/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 147/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 148/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0105\n",
      "Epoch 149/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 151/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 152/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 153/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 154/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 155/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 156/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 157/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 158/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 159/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 160/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 161/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 162/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0104\n",
      "Epoch 163/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 164/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 165/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 166/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 167/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 168/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 169/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 170/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 171/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0104\n",
      "Epoch 172/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 173/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 174/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 175/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 176/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 177/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 178/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 179/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 180/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 181/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 182/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 183/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0103\n",
      "Epoch 184/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 185/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 186/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 187/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 188/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 189/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 190/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 191/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 192/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 193/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 194/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 195/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 196/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 197/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0103\n",
      "Epoch 198/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 199/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 200/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 201/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 202/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 203/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 204/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 205/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 206/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0101\n",
      "Epoch 207/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 208/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 209/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 210/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 211/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 212/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 213/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 214/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0056 - val_loss: 0.0102\n",
      "Epoch 215/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 216/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 217/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0055 - val_loss: 0.0102\n",
      "Epoch 218/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0054 - val_loss: 0.0101\n",
      "Epoch 219/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 220/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 221/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 222/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 223/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 224/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 225/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 226/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 227/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 228/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 229/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 230/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 231/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 232/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 233/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 234/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 235/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 236/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 237/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 238/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 239/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 240/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 241/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 242/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 243/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 244/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 245/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 246/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 247/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 248/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 249/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 250/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 251/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 252/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0053 - val_loss: 0.0101\n",
      "Epoch 253/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 254/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 255/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 256/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 257/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 258/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 259/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 260/400\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0101\n",
      "Epoch 261/400\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0052 - val_loss: 0.0101\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "if dataset == 'mnist':\n",
    "    # first embed data\n",
    "    x_train_ = embed_data(x_all, 'mnist')\n",
    "    x_test_ = embed_data(x_all, 'mnist')\n",
    "\n",
    "    input_shape = x_train_.shape[1:]\n",
    "    y_true = tf.placeholder(tf.float32, shape=(None, n_clusters), name='y_true')\n",
    "    y_train_labeled_onehot = np.empty((0, len(np.unique(y_train))))\n",
    "    inputs = {\n",
    "        'Unlabeled': Input(shape=input_shape, name='UnlabeledInput'),\n",
    "        'Labeled': Input(shape=input_shape, name='LabeledInput'),\n",
    "        'Orthonorm': Input(shape=input_shape, name='OrthonormInput'),\n",
    "        }\n",
    "    \n",
    "    pairs_train, dist_train = pairs.create_pairs_from_unlabeled_data(\n",
    "        x1=x_train_,\n",
    "        p=None,\n",
    "        k=2,\n",
    "        tot_pairs=600000,\n",
    "        precomputed_knn_path='',\n",
    "        use_approx=True,\n",
    "        pre_shuffled=False,\n",
    "    )\n",
    "    pairs_val, dist_val = pairs.create_pairs_from_unlabeled_data(\n",
    "        x1=x_test_,\n",
    "        p=None,\n",
    "        k=2,\n",
    "        tot_pairs=600000,\n",
    "        precomputed_knn_path='',\n",
    "        use_approx=True,\n",
    "        pre_shuffled=False,\n",
    "    )\n",
    "    siamese_net = SiameseNet(inputs=inputs, arch=arch, siam_reg=None, y_true=y_true)\n",
    "    siamese_net.train(pairs_train, dist_train, pairs_val, dist_val,\n",
    "            lr=1e-3, drop=0.1, patience=10, num_epochs=400, batch_size=1024)\n",
    "else:\n",
    "    siamese_net = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_net = SpectralNet(inputs=inputs, arch=arch,\n",
    "            spec_reg=None, y_true=y_true, y_train_labeled_onehot=y_train_labeled_onehot,\n",
    "            n_clusters=n_clusters, affinity='siamese', scale_nbr=3, n_nbrs=2, \n",
    "            batch_sizes=batch_sizes, siamese_net=siamese_net, \n",
    "            x_train=x_train_, have_labeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss=232.497263, val_loss=148.792801\n",
      "Epoch: 1, loss=46.905340, val_loss=28.008652\n",
      "Epoch: 2, loss=18.379713, val_loss=8.988704\n",
      "Epoch: 3, loss=13.124473, val_loss=7.293595\n",
      "Epoch: 4, loss=11.171564, val_loss=7.589170\n",
      "Epoch: 5, loss=10.233074, val_loss=7.253196\n",
      "Epoch: 6, loss=9.385928, val_loss=6.441764\n",
      "Epoch: 7, loss=8.692532, val_loss=5.664662\n",
      "Epoch: 8, loss=8.431933, val_loss=5.757453\n",
      "Epoch: 9, loss=7.912769, val_loss=4.794567\n",
      "Epoch: 10, loss=7.690833, val_loss=5.119548\n",
      "Epoch: 11, loss=7.250571, val_loss=4.887741\n",
      "Epoch: 12, loss=6.975413, val_loss=4.545410\n",
      "Epoch: 13, loss=6.486246, val_loss=4.569502\n",
      "Epoch: 14, loss=6.333675, val_loss=3.989215\n",
      "Epoch: 15, loss=6.416466, val_loss=4.621518\n",
      "Epoch: 16, loss=6.133170, val_loss=3.672239\n",
      "Epoch: 17, loss=6.003861, val_loss=3.772801\n",
      "Epoch: 18, loss=5.675981, val_loss=4.091124\n",
      "Epoch: 19, loss=5.700336, val_loss=3.512265\n",
      "Epoch: 20, loss=5.367491, val_loss=3.863148\n",
      "Epoch: 21, loss=5.408053, val_loss=3.764402\n",
      "Epoch: 22, loss=5.280747, val_loss=3.893248\n",
      "Epoch: 23, loss=5.332201, val_loss=3.642839\n",
      "Epoch: 24, loss=5.119382, val_loss=3.436295\n",
      "Epoch: 25, loss=5.027597, val_loss=3.606858\n",
      "Epoch: 26, loss=4.929655, val_loss=3.304681\n",
      "Epoch: 27, loss=4.932897, val_loss=3.467633\n",
      "Epoch: 28, loss=4.672482, val_loss=3.730545\n",
      "Epoch: 29, loss=4.837742, val_loss=3.437852\n",
      "Epoch: 30, loss=4.673545, val_loss=3.397407\n",
      "Epoch: 31, loss=4.691287, val_loss=3.089273\n",
      "Epoch: 32, loss=4.525652, val_loss=3.455700\n",
      "Epoch: 33, loss=4.574099, val_loss=2.999671\n",
      "Epoch: 34, loss=4.490616, val_loss=3.366997\n",
      "Epoch: 35, loss=4.540428, val_loss=3.215942\n",
      "Epoch: 36, loss=4.519388, val_loss=3.207093\n",
      "Epoch: 37, loss=4.395074, val_loss=3.429914\n",
      "Epoch: 38, loss=4.453451, val_loss=3.221801\n",
      "Epoch: 39, loss=4.398057, val_loss=2.969715\n",
      "Epoch: 40, loss=4.281209, val_loss=2.828474\n",
      "Epoch: 41, loss=4.427625, val_loss=3.272701\n",
      "Epoch: 42, loss=4.300809, val_loss=2.859065\n",
      "Epoch: 43, loss=4.134772, val_loss=2.947179\n",
      "Epoch: 44, loss=4.172517, val_loss=2.834633\n",
      "Epoch: 45, loss=4.221399, val_loss=2.916795\n",
      "Epoch: 46, loss=4.249516, val_loss=3.119518\n",
      "Epoch: 47, loss=4.039495, val_loss=2.805745\n",
      "Epoch: 48, loss=4.171506, val_loss=2.957355\n",
      "Epoch: 49, loss=4.056408, val_loss=2.645996\n",
      "Epoch: 50, loss=4.197044, val_loss=2.741939\n",
      "Epoch: 51, loss=4.060807, val_loss=2.812115\n",
      "Epoch: 52, loss=4.040340, val_loss=2.666981\n",
      "Epoch: 53, loss=3.979189, val_loss=2.724364\n",
      "Epoch: 54, loss=3.841622, val_loss=2.569330\n",
      "Epoch: 55, loss=3.987212, val_loss=2.459720\n",
      "Epoch: 56, loss=3.972311, val_loss=2.602425\n",
      "Epoch: 57, loss=3.971597, val_loss=2.629767\n",
      "Epoch: 58, loss=3.875255, val_loss=3.069987\n",
      "Epoch: 59, loss=3.835773, val_loss=2.538509\n",
      "Epoch: 60, loss=3.846653, val_loss=2.616623\n",
      "Epoch: 61, loss=3.812170, val_loss=2.419608\n",
      "Epoch: 62, loss=3.837507, val_loss=2.721373\n",
      "Epoch: 63, loss=3.799608, val_loss=2.759650\n",
      "Epoch: 64, loss=3.825269, val_loss=2.582640\n",
      "Epoch: 65, loss=3.844231, val_loss=2.825574\n",
      "Epoch: 66, loss=3.794696, val_loss=2.567961\n",
      "Epoch: 67, loss=3.826425, val_loss=2.901776\n",
      "Epoch: 68, loss=3.742583, val_loss=2.551431\n",
      "Epoch: 69, loss=3.677007, val_loss=2.632964\n",
      "Epoch: 70, loss=3.780505, val_loss=2.393286\n",
      "Epoch: 71, loss=3.754643, val_loss=2.720024\n",
      "Epoch: 72, loss=3.689372, val_loss=2.523808\n",
      "Epoch: 73, loss=3.628871, val_loss=2.750106\n",
      "Epoch: 74, loss=3.870471, val_loss=2.600557\n",
      "Epoch: 75, loss=3.829255, val_loss=2.756241\n",
      "Epoch: 76, loss=3.711299, val_loss=2.701720\n",
      "Epoch: 77, loss=3.705314, val_loss=2.701228\n",
      "Epoch: 78, loss=3.666899, val_loss=2.540496\n",
      "Epoch: 79, loss=3.626195, val_loss=2.595748\n",
      "Epoch: 80, loss=3.640292, val_loss=2.366948\n",
      "Epoch: 81, loss=3.659678, val_loss=2.525878\n",
      "Epoch: 82, loss=3.811619, val_loss=2.479758\n",
      "Epoch: 83, loss=3.765949, val_loss=2.488211\n",
      "Epoch: 84, loss=3.658244, val_loss=2.637460\n",
      "Epoch: 85, loss=3.625887, val_loss=2.551260\n",
      "Epoch: 86, loss=3.613815, val_loss=2.425037\n",
      "Epoch: 87, loss=3.528897, val_loss=2.407120\n",
      "Epoch: 88, loss=3.555669, val_loss=2.398600\n",
      "Epoch: 89, loss=3.562024, val_loss=2.581072\n",
      "Epoch: 90, loss=3.578855, val_loss=2.483417\n",
      "Epoch: 91, loss=3.586295, val_loss=2.600569\n",
      "Epoch: 92, loss=3.561953, val_loss=2.551136\n",
      "Epoch: 93, loss=3.627236, val_loss=2.636451\n",
      "Epoch: 94, loss=3.611771, val_loss=2.493701\n",
      "Epoch: 95, loss=3.617441, val_loss=2.666065\n",
      "Epoch: 96, loss=3.554569, val_loss=2.482363\n",
      "Epoch: 97, loss=3.663245, val_loss=2.452698\n",
      "Epoch: 98, loss=3.567734, val_loss=2.585663\n",
      "Epoch: 99, loss=3.570844, val_loss=2.405064\n",
      "Epoch: 100, loss=3.530303, val_loss=2.438647\n",
      "Epoch: 101, loss=3.434347, val_loss=2.691192\n",
      "Epoch: 102, loss=3.231635, val_loss=2.307178\n",
      "Epoch: 103, loss=3.142145, val_loss=2.303289\n",
      "Epoch: 104, loss=2.916330, val_loss=2.248805\n",
      "Epoch: 105, loss=3.044584, val_loss=2.104515\n",
      "Epoch: 106, loss=2.993034, val_loss=2.069984\n",
      "Epoch: 107, loss=2.908159, val_loss=2.066404\n",
      "Epoch: 108, loss=2.915390, val_loss=1.954701\n",
      "Epoch: 109, loss=2.899712, val_loss=2.055439\n",
      "Epoch: 110, loss=2.954272, val_loss=2.002864\n",
      "Epoch: 111, loss=2.925735, val_loss=2.100140\n",
      "Epoch: 112, loss=2.915998, val_loss=1.991183\n",
      "Epoch: 113, loss=2.953730, val_loss=2.162585\n",
      "Epoch: 114, loss=2.871745, val_loss=2.056680\n",
      "Epoch: 115, loss=2.910115, val_loss=2.184448\n",
      "Epoch: 116, loss=2.915116, val_loss=1.985858\n",
      "Epoch: 117, loss=2.884582, val_loss=1.924341\n",
      "Epoch: 118, loss=2.913730, val_loss=2.056868\n",
      "Epoch: 119, loss=2.821879, val_loss=2.068394\n",
      "Epoch: 120, loss=2.887120, val_loss=1.965489\n",
      "Epoch: 121, loss=2.800750, val_loss=1.990582\n",
      "Epoch: 122, loss=2.912932, val_loss=2.023225\n",
      "Epoch: 123, loss=2.818165, val_loss=2.136606\n",
      "Epoch: 124, loss=2.732923, val_loss=1.971619\n",
      "Epoch: 125, loss=2.854400, val_loss=2.083145\n",
      "Epoch: 126, loss=2.868369, val_loss=2.053381\n",
      "Epoch: 127, loss=2.849173, val_loss=1.957647\n",
      "Epoch: 128, loss=2.783035, val_loss=2.044213\n",
      "Epoch: 129, loss=2.894334, val_loss=1.986081\n",
      "Epoch: 130, loss=2.767234, val_loss=1.937652\n",
      "Epoch: 131, loss=2.842201, val_loss=2.033426\n",
      "Epoch: 132, loss=2.774912, val_loss=1.872982\n",
      "Epoch: 133, loss=2.812800, val_loss=1.957400\n",
      "Epoch: 134, loss=2.768908, val_loss=2.029812\n",
      "Epoch: 135, loss=2.773256, val_loss=2.073798\n",
      "Epoch: 136, loss=2.817521, val_loss=2.005661\n",
      "Epoch: 137, loss=2.776761, val_loss=2.147945\n",
      "Epoch: 138, loss=2.896853, val_loss=1.928946\n",
      "Epoch: 139, loss=2.797939, val_loss=1.909276\n",
      "Epoch: 140, loss=2.753522, val_loss=1.972267\n",
      "Epoch: 141, loss=2.703936, val_loss=1.953891\n",
      "Epoch: 142, loss=2.773308, val_loss=1.903112\n",
      "Epoch: 143, loss=2.766639, val_loss=1.956475\n",
      "Epoch: 144, loss=2.804249, val_loss=1.939257\n",
      "Epoch: 145, loss=2.750831, val_loss=1.973339\n",
      "Epoch: 146, loss=2.733174, val_loss=1.964614\n",
      "Epoch: 147, loss=2.697923, val_loss=1.934288\n",
      "Epoch: 148, loss=2.701928, val_loss=1.949708\n",
      "Epoch: 149, loss=2.706921, val_loss=1.846027\n",
      "Epoch: 150, loss=2.720908, val_loss=1.913674\n",
      "Epoch: 151, loss=2.679004, val_loss=1.917233\n",
      "Epoch: 152, loss=2.709056, val_loss=1.889042\n",
      "Epoch: 153, loss=2.593813, val_loss=1.944093\n",
      "Epoch: 154, loss=2.876942, val_loss=1.910395\n",
      "Epoch: 155, loss=2.786465, val_loss=1.894935\n",
      "Epoch: 156, loss=2.871092, val_loss=1.907009\n",
      "Epoch: 157, loss=2.770698, val_loss=1.835071\n",
      "Epoch: 158, loss=2.849127, val_loss=1.900363\n",
      "Epoch: 159, loss=2.794911, val_loss=1.895351\n",
      "Epoch: 160, loss=2.616971, val_loss=1.921709\n",
      "Epoch: 161, loss=2.710411, val_loss=1.944748\n",
      "Epoch: 162, loss=2.736672, val_loss=1.860509\n",
      "Epoch: 163, loss=2.771051, val_loss=1.972657\n",
      "Epoch: 164, loss=2.687284, val_loss=1.856085\n",
      "Epoch: 165, loss=2.694384, val_loss=1.826832\n",
      "Epoch: 166, loss=2.754690, val_loss=1.828428\n",
      "Epoch: 167, loss=2.668157, val_loss=1.820347\n",
      "Epoch: 168, loss=2.696152, val_loss=1.923121\n",
      "Epoch: 169, loss=2.632350, val_loss=1.970684\n",
      "Epoch: 170, loss=2.688983, val_loss=1.860589\n",
      "Epoch: 171, loss=2.626932, val_loss=1.867539\n",
      "Epoch: 172, loss=2.762871, val_loss=1.883405\n",
      "Epoch: 173, loss=2.640618, val_loss=1.883311\n",
      "Epoch: 174, loss=2.643839, val_loss=1.839839\n",
      "Epoch: 175, loss=2.464687, val_loss=1.850046\n",
      "Epoch: 176, loss=2.721850, val_loss=1.869519\n",
      "Epoch: 177, loss=2.732357, val_loss=1.916123\n",
      "Epoch: 178, loss=2.508890, val_loss=1.860288\n",
      "Epoch: 179, loss=2.639143, val_loss=1.933715\n",
      "Epoch: 180, loss=2.658203, val_loss=1.859310\n",
      "Epoch: 181, loss=2.643635, val_loss=1.835425\n",
      "Epoch: 182, loss=2.659743, val_loss=1.883660\n",
      "Epoch: 183, loss=2.674464, val_loss=1.856655\n",
      "Epoch: 184, loss=2.621854, val_loss=1.837160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 185, loss=2.629262, val_loss=1.819454\n",
      "Epoch: 186, loss=2.594876, val_loss=1.843116\n",
      "Epoch: 187, loss=2.540740, val_loss=1.829882\n",
      "Epoch: 188, loss=2.594150, val_loss=1.805146\n",
      "Epoch: 189, loss=2.662521, val_loss=1.823781\n",
      "Epoch: 190, loss=2.424323, val_loss=1.832047\n",
      "Epoch: 191, loss=2.642546, val_loss=1.769753\n",
      "Epoch: 192, loss=2.606473, val_loss=1.842072\n",
      "Epoch: 193, loss=2.560873, val_loss=1.831562\n",
      "Epoch: 194, loss=2.595107, val_loss=1.847787\n",
      "Epoch: 195, loss=2.609995, val_loss=1.814981\n",
      "Epoch: 196, loss=2.610270, val_loss=1.808368\n",
      "Epoch: 197, loss=2.599393, val_loss=1.831739\n",
      "Epoch: 198, loss=2.559069, val_loss=1.835270\n",
      "Epoch: 199, loss=2.498343, val_loss=1.826417\n",
      "Epoch: 200, loss=2.483484, val_loss=1.807237\n",
      "Epoch: 201, loss=2.473837, val_loss=1.801386\n",
      "Epoch: 202, loss=2.467882, val_loss=1.792999\n",
      "Epoch: 203, loss=2.524975, val_loss=1.788707\n",
      "Epoch: 204, loss=2.684997, val_loss=1.776266\n",
      "Epoch: 205, loss=2.570060, val_loss=1.807438\n",
      "Epoch: 206, loss=2.532618, val_loss=1.784720\n",
      "Epoch: 207, loss=2.489352, val_loss=1.780486\n",
      "Epoch: 208, loss=2.505609, val_loss=1.822940\n",
      "Epoch: 209, loss=2.491450, val_loss=1.830184\n",
      "Epoch: 210, loss=2.531663, val_loss=1.829721\n",
      "Epoch: 211, loss=2.534869, val_loss=1.820187\n",
      "Epoch: 212, loss=2.572398, val_loss=1.787294\n",
      "Epoch: 213, loss=2.522858, val_loss=1.779389\n",
      "Epoch: 214, loss=2.581833, val_loss=1.817729\n",
      "Epoch: 215, loss=2.499055, val_loss=1.755045\n",
      "Epoch: 216, loss=2.519291, val_loss=1.742917\n",
      "Epoch: 217, loss=2.434396, val_loss=1.763084\n",
      "Epoch: 218, loss=2.453459, val_loss=1.811833\n",
      "Epoch: 219, loss=2.456336, val_loss=1.707792\n",
      "Epoch: 220, loss=2.429362, val_loss=1.764337\n",
      "Epoch: 221, loss=2.497967, val_loss=1.782660\n",
      "Epoch: 222, loss=2.343144, val_loss=1.709072\n",
      "Epoch: 223, loss=2.637765, val_loss=1.742829\n",
      "Epoch: 224, loss=2.549497, val_loss=1.761084\n",
      "Epoch: 225, loss=2.417654, val_loss=1.784436\n",
      "Epoch: 226, loss=2.458778, val_loss=1.767638\n",
      "Epoch: 227, loss=2.361934, val_loss=1.719550\n",
      "Epoch: 228, loss=2.525896, val_loss=1.771528\n",
      "Epoch: 229, loss=2.520568, val_loss=1.796185\n",
      "Epoch: 230, loss=2.418556, val_loss=1.775040\n",
      "Epoch: 231, loss=2.448905, val_loss=1.830500\n",
      "Epoch: 232, loss=2.542726, val_loss=1.801073\n",
      "Epoch: 233, loss=2.543234, val_loss=1.725102\n",
      "Epoch: 234, loss=2.413226, val_loss=1.786336\n",
      "Epoch: 235, loss=2.504048, val_loss=1.776626\n",
      "Epoch: 236, loss=2.455534, val_loss=1.792040\n",
      "Epoch: 237, loss=2.463724, val_loss=1.754821\n",
      "Epoch: 238, loss=2.534524, val_loss=1.790136\n",
      "Epoch: 239, loss=2.419437, val_loss=1.762484\n",
      "Epoch: 240, loss=2.540168, val_loss=1.810401\n",
      "Epoch: 241, loss=2.462207, val_loss=1.747034\n",
      "Epoch: 242, loss=2.365092, val_loss=1.771270\n",
      "Epoch: 243, loss=2.451615, val_loss=1.730612\n",
      "Epoch: 244, loss=2.395991, val_loss=1.740344\n",
      "Epoch: 245, loss=2.432980, val_loss=1.684706\n",
      "Epoch: 246, loss=2.462561, val_loss=1.711419\n",
      "Epoch: 247, loss=2.520587, val_loss=1.741183\n",
      "Epoch: 248, loss=2.493721, val_loss=1.764454\n",
      "Epoch: 249, loss=2.521671, val_loss=1.718962\n",
      "Epoch: 250, loss=2.542707, val_loss=1.758157\n",
      "Epoch: 251, loss=2.415633, val_loss=1.722565\n",
      "Epoch: 252, loss=2.527950, val_loss=1.738892\n",
      "Epoch: 253, loss=2.567424, val_loss=1.754532\n",
      "Epoch: 254, loss=2.406653, val_loss=1.715134\n",
      "Epoch: 255, loss=2.527819, val_loss=1.737188\n",
      "Epoch: 256, loss=2.508207, val_loss=1.746336\n",
      "Epoch: 257, loss=2.538940, val_loss=1.710636\n",
      "Epoch: 258, loss=2.512969, val_loss=1.753293\n",
      "Epoch: 259, loss=2.390361, val_loss=1.776742\n",
      "Epoch: 260, loss=2.332095, val_loss=1.778044\n",
      "Epoch: 261, loss=2.464608, val_loss=1.732814\n",
      "Epoch: 262, loss=2.492523, val_loss=1.767341\n",
      "Epoch: 263, loss=2.514893, val_loss=1.808358\n",
      "Epoch: 264, loss=2.501971, val_loss=1.812725\n",
      "Epoch: 265, loss=2.500591, val_loss=1.761213\n",
      "Epoch: 266, loss=2.393501, val_loss=1.714156\n",
      "Epoch: 267, loss=2.621107, val_loss=1.789600\n",
      "Epoch: 268, loss=2.458189, val_loss=1.726034\n",
      "Epoch: 269, loss=2.496637, val_loss=1.711178\n",
      "Epoch: 270, loss=2.361042, val_loss=1.736343\n",
      "Epoch: 271, loss=2.418707, val_loss=1.758601\n",
      "Epoch: 272, loss=2.480344, val_loss=1.751496\n",
      "Epoch: 273, loss=2.477361, val_loss=1.749993\n",
      "Epoch: 274, loss=2.493036, val_loss=1.765188\n",
      "Epoch: 275, loss=2.516496, val_loss=1.755306\n",
      "Epoch: 276, loss=2.469183, val_loss=1.750877\n",
      "Epoch: 277, loss=2.381650, val_loss=1.790990\n",
      "Epoch: 278, loss=2.495354, val_loss=1.700363\n",
      "Epoch: 279, loss=2.589511, val_loss=1.777009\n",
      "Epoch: 280, loss=2.344161, val_loss=1.770906\n",
      "Epoch: 281, loss=2.404610, val_loss=1.792782\n",
      "Epoch: 282, loss=2.463552, val_loss=1.723552\n",
      "Epoch: 283, loss=2.416836, val_loss=1.726338\n",
      "Epoch: 284, loss=2.570243, val_loss=1.774275\n",
      "Epoch: 285, loss=2.347159, val_loss=1.747889\n",
      "Epoch: 286, loss=2.376439, val_loss=1.775216\n",
      "STOPPING EARLY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([232.49726295,  46.90533951,  18.37971252,  13.12447271,\n",
       "         11.17156378,  10.23307449,   9.38592751,   8.69253188,\n",
       "          8.4319333 ,   7.91276858,   7.6908334 ,   7.25057084,\n",
       "          6.97541296,   6.48624565,   6.33367463,   6.41646644,\n",
       "          6.13316975,   6.00386119,   5.67598091,   5.70033639,\n",
       "          5.36749126,   5.40805263,   5.28074717,   5.33220089,\n",
       "          5.11938192,   5.0275967 ,   4.92965519,   4.93289652,\n",
       "          4.67248194,   4.83774205,   4.67354462,   4.69128723,\n",
       "          4.52565233,   4.57409918,   4.49061608,   4.54042781,\n",
       "          4.51938824,   4.39507414,   4.45345149,   4.39805732,\n",
       "          4.28120925,   4.42762497,   4.30080914,   4.13477224,\n",
       "          4.1725167 ,   4.22139875,   4.24951575,   4.03949462,\n",
       "          4.17150625,   4.05640848,   4.19704365,   4.06080677,\n",
       "          4.04033988,   3.97918851,   3.84162162,   3.98721235,\n",
       "          3.97231119,   3.97159722,   3.87525512,   3.83577341,\n",
       "          3.84665321,   3.81217006,   3.83750666,   3.79960797,\n",
       "          3.82526859,   3.84423077,   3.79469639,   3.82642507,\n",
       "          3.74258286,   3.67700657,   3.78050461,   3.75464268,\n",
       "          3.68937182,   3.62887059,   3.87047127,   3.82925544,\n",
       "          3.71129893,   3.70531422,   3.66689884,   3.62619454,\n",
       "          3.64029159,   3.65967751,   3.81161907,   3.76594883,\n",
       "          3.65824444,   3.62588652,   3.61381514,   3.52889731,\n",
       "          3.55566865,   3.56202353,   3.57885526,   3.58629495,\n",
       "          3.56195311,   3.62723573,   3.61177083,   3.61744097,\n",
       "          3.55456869,   3.66324493,   3.56773439,   3.5708442 ,\n",
       "          3.53030322,   3.4343474 ,   3.2316354 ,   3.14214493,\n",
       "          2.91632953,   3.04458356,   2.99303393,   2.9081595 ,\n",
       "          2.91539039,   2.89971247,   2.95427182,   2.92573506,\n",
       "          2.91599799,   2.95373007,   2.87174539,   2.91011455,\n",
       "          2.915116  ,   2.88458185,   2.91372972,   2.82187877,\n",
       "          2.8871201 ,   2.80074974,   2.91293166,   2.81816547,\n",
       "          2.73292295,   2.85439974,   2.86836906,   2.84917288,\n",
       "          2.78303467,   2.89433374,   2.76723433,   2.84220085,\n",
       "          2.77491232,   2.81279969,   2.7689078 ,   2.77325646,\n",
       "          2.81752111,   2.77676077,   2.89685305,   2.79793937,\n",
       "          2.75352232,   2.70393633,   2.77330799,   2.7666394 ,\n",
       "          2.80424941,   2.7508314 ,   2.73317376,   2.69792299,\n",
       "          2.70192822,   2.70692064,   2.72090794,   2.67900398,\n",
       "          2.70905592,   2.59381313,   2.87694156,   2.78646462,\n",
       "          2.87109231,   2.77069797,   2.84912682,   2.79491055,\n",
       "          2.61697142,   2.71041111,   2.73667225,   2.77105109,\n",
       "          2.68728446,   2.69438401,   2.75468996,   2.66815679,\n",
       "          2.6961518 ,   2.63234968,   2.6889832 ,   2.62693221,\n",
       "          2.76287125,   2.64061834,   2.64383888,   2.46468691,\n",
       "          2.72184983,   2.73235729,   2.50888958,   2.63914319,\n",
       "          2.65820301,   2.64363474,   2.65974287,   2.67446415,\n",
       "          2.62185359,   2.62926216,   2.59487636,   2.5407398 ,\n",
       "          2.59415007,   2.66252081,   2.42432301,   2.64254573,\n",
       "          2.60647257,   2.56087259,   2.59510712,   2.60999489,\n",
       "          2.61026979,   2.59939254,   2.55906906,   2.49834279,\n",
       "          2.48348447,   2.47383657,   2.46788227,   2.52497466,\n",
       "          2.68499709,   2.57005985,   2.53261754,   2.48935242,\n",
       "          2.5056091 ,   2.49144994,   2.53166263,   2.53486897,\n",
       "          2.57239775,   2.52285757,   2.5818325 ,   2.49905522,\n",
       "          2.51929143,   2.43439614,   2.45345855,   2.45633625,\n",
       "          2.4293622 ,   2.49796715,   2.34314358,   2.63776534,\n",
       "          2.54949723,   2.41765396,   2.45877837,   2.36193362,\n",
       "          2.52589645,   2.52056752,   2.41855626,   2.44890502,\n",
       "          2.542726  ,   2.54323421,   2.41322649,   2.5040477 ,\n",
       "          2.45553359,   2.46372365,   2.53452386,   2.41943689,\n",
       "          2.54016774,   2.46220687,   2.36509198,   2.45161476,\n",
       "          2.39599098,   2.43297955,   2.4625605 ,   2.52058699,\n",
       "          2.49372066,   2.52167111,   2.54270699,   2.4156333 ,\n",
       "          2.52795   ,   2.56742397,   2.40665311,   2.52781936,\n",
       "          2.50820718,   2.53893965,   2.51296882,   2.39036057,\n",
       "          2.33209506,   2.46460781,   2.49252292,   2.51489324,\n",
       "          2.50197125,   2.50059062,   2.39350148,   2.62110735,\n",
       "          2.45818891,   2.49663749,   2.36104187,   2.4187067 ,\n",
       "          2.48034443,   2.4773609 ,   2.49303639,   2.5164963 ,\n",
       "          2.46918343,   2.38165017,   2.49535435,   2.58951138,\n",
       "          2.34416072,   2.4046102 ,   2.46355194,   2.41683602,\n",
       "          2.57024305,   2.34715865,   2.37643941,   2.56136936]),\n",
       " array([148.7928009 ,  28.00865173,   8.98870373,   7.29359484,\n",
       "          7.58916998,   7.25319624,   6.44176388,   5.66466188,\n",
       "          5.75745296,   4.79456663,   5.11954832,   4.88774109,\n",
       "          4.54540968,   4.56950235,   3.98921537,   4.62151766,\n",
       "          3.67223859,   3.7728014 ,   4.09112406,   3.51226521,\n",
       "          3.86314774,   3.76440191,   3.89324784,   3.64283943,\n",
       "          3.43629456,   3.60685754,   3.30468106,   3.46763253,\n",
       "          3.73054504,   3.43785167,   3.39740729,   3.08927345,\n",
       "          3.45569992,   2.99967146,   3.36699724,   3.21594191,\n",
       "          3.207093  ,   3.429914  ,   3.22180104,   2.96971512,\n",
       "          2.82847428,   3.27270079,   2.85906482,   2.94717932,\n",
       "          2.83463335,   2.91679525,   3.11951756,   2.80574512,\n",
       "          2.95735526,   2.64599633,   2.74193859,   2.81211519,\n",
       "          2.66698122,   2.72436357,   2.5693295 ,   2.45972037,\n",
       "          2.60242462,   2.62976742,   3.06998658,   2.53850889,\n",
       "          2.6166234 ,   2.41960788,   2.72137332,   2.75965047,\n",
       "          2.58264017,   2.82557392,   2.56796074,   2.9017756 ,\n",
       "          2.55143118,   2.63296437,   2.39328551,   2.72002435,\n",
       "          2.52380848,   2.75010562,   2.60055661,   2.75624084,\n",
       "          2.70172   ,   2.70122766,   2.54049635,   2.59574795,\n",
       "          2.36694837,   2.52587771,   2.47975802,   2.48821139,\n",
       "          2.63746023,   2.55126023,   2.42503715,   2.40711999,\n",
       "          2.3986001 ,   2.58107233,   2.48341656,   2.60056949,\n",
       "          2.55113649,   2.63645148,   2.4937005 ,   2.66606522,\n",
       "          2.48236299,   2.45269847,   2.58566332,   2.40506411,\n",
       "          2.43864679,   2.69119239,   2.3071785 ,   2.30328941,\n",
       "          2.24880457,   2.10451531,   2.06998444,   2.06640387,\n",
       "          1.95470083,   2.055439  ,   2.00286412,   2.10013962,\n",
       "          1.99118316,   2.16258502,   2.05668044,   2.184448  ,\n",
       "          1.9858582 ,   1.92434132,   2.0568676 ,   2.06839442,\n",
       "          1.96548867,   1.99058187,   2.02322507,   2.1366055 ,\n",
       "          1.97161889,   2.0831449 ,   2.0533812 ,   1.95764673,\n",
       "          2.04421282,   1.98608065,   1.93765211,   2.03342605,\n",
       "          1.87298203,   1.95740044,   2.02981234,   2.0737977 ,\n",
       "          2.00566149,   2.14794517,   1.92894554,   1.90927613,\n",
       "          1.97226715,   1.9538908 ,   1.9031117 ,   1.9564755 ,\n",
       "          1.93925726,   1.97333908,   1.96461439,   1.93428814,\n",
       "          1.94970751,   1.84602726,   1.91367352,   1.91723347,\n",
       "          1.88904178,   1.94409299,   1.91039526,   1.89493489,\n",
       "          1.90700948,   1.83507085,   1.90036261,   1.89535129,\n",
       "          1.92170918,   1.94474792,   1.86050868,   1.97265697,\n",
       "          1.85608459,   1.82683241,   1.82842839,   1.82034659,\n",
       "          1.92312133,   1.97068357,   1.86058903,   1.86753857,\n",
       "          1.88340545,   1.88331079,   1.83983946,   1.85004616,\n",
       "          1.86951911,   1.91612327,   1.86028814,   1.93371451,\n",
       "          1.85931015,   1.83542526,   1.88365984,   1.85665488,\n",
       "          1.83716023,   1.81945431,   1.84311569,   1.82988238,\n",
       "          1.80514562,   1.82378066,   1.83204722,   1.76975322,\n",
       "          1.84207189,   1.83156204,   1.84778666,   1.81498086,\n",
       "          1.80836761,   1.83173883,   1.8352704 ,   1.82641709,\n",
       "          1.80723727,   1.80138624,   1.79299855,   1.78870678,\n",
       "          1.7762655 ,   1.80743837,   1.78471994,   1.78048599,\n",
       "          1.82293963,   1.83018351,   1.82972145,   1.82018685,\n",
       "          1.78729379,   1.7793889 ,   1.81772912,   1.75504529,\n",
       "          1.74291742,   1.76308429,   1.8118329 ,   1.70779157,\n",
       "          1.76433742,   1.78265989,   1.70907164,   1.74282885,\n",
       "          1.76108444,   1.78443575,   1.76763844,   1.71954989,\n",
       "          1.77152824,   1.79618454,   1.77503955,   1.83049977,\n",
       "          1.80107272,   1.72510242,   1.78633559,   1.77662563,\n",
       "          1.79204047,   1.75482118,   1.79013598,   1.76248419,\n",
       "          1.81040108,   1.74703443,   1.77127004,   1.73061216,\n",
       "          1.74034429,   1.68470573,   1.71141887,   1.74118268,\n",
       "          1.76445413,   1.7189616 ,   1.75815701,   1.72256458,\n",
       "          1.7388916 ,   1.75453222,   1.71513414,   1.73718774,\n",
       "          1.74633586,   1.71063638,   1.75329316,   1.77674234,\n",
       "          1.77804434,   1.73281431,   1.76734078,   1.80835783,\n",
       "          1.81272495,   1.76121259,   1.71415591,   1.78960049,\n",
       "          1.72603428,   1.71117842,   1.73634338,   1.75860059,\n",
       "          1.75149596,   1.74999344,   1.76518834,   1.75530624,\n",
       "          1.75087738,   1.79099047,   1.7003634 ,   1.77700865,\n",
       "          1.77090645,   1.79278159,   1.72355223,   1.72633767,\n",
       "          1.7742753 ,   1.7478888 ,   1.7752161 ,   1.80767596]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_net.train(\n",
    "        x_train_, np.zeros_like(x_train_[0:0]), x_test_,\n",
    "        lr=1e-3, drop=0.1, patience=20, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"432\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 10000 elements, which is not acceptable for use with 'x' with size 70000, 'y' with size 70000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_colors_full_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (7, None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4231\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then is 'c' acceptable as PathCollection facecolors?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4232\u001b[0;31m                 \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4233\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Not in cache, or unhashable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_rgba_no_colorcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Test dimensionality to reject single floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid RGBA argument: {!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;31m# Return a tuple to prevent the cached value from being modified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 7",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-558736afb23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspectral_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print('range of y_pred values: {} - {}'.format(np.max(y_pred), np.min(y_pred)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9fa8ff958ab0>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(x, y, x2, y2, s, s2, alpha, alpha2, label1, label2, cmap1, cmap2, n_imgs, shuffle)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'3d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mpl_toolkits/mplot3d/axes3d.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, xs, ys, zs, zdir, s, c, depthshade, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2303\u001b[0m         \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_masked_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m         \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2306\u001b[0m         \u001b[0mis_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4243\u001b[0m                         \u001b[0;34m\"acceptable for use with 'x' with size {xs}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4244\u001b[0m                         \u001b[0;34m\"'y' with size {ys}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4245\u001b[0;31m                         \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4246\u001b[0m                     )\n\u001b[1;32m   4247\u001b[0m                 \u001b[0;31m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 10000 elements, which is not acceptable for use with 'x' with size 70000, 'y' with size 70000."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"432\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = spectral_net.predict(x_test_)\n",
    "g = plot(y_pred[:,:3], y_test.reshape(-1,))\n",
    "# print('range of y_pred values: {} - {}'.format(np.max(y_pred), np.min(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: \n",
      "[[   1 6843    2    9    0   31    2    2    8    5]\n",
      " [3734    1    5  105   22    4   12 3978   12    4]\n",
      " [  14   38   58 6775   10    7   50   12   22    4]\n",
      " [   9    5   46   73    8    4   55   10 6878   53]\n",
      " [  14    4    4   15 6655   39   50   42    0    1]\n",
      " [   2   33   37    6   11   88   24    3 1223 4886]\n",
      " [   7   32    6    6    4 6771    0    8    6   36]\n",
      " [  12    7    3   49   49    0 7123   42    5    3]\n",
      " [  27   26 6037   31   48   49   43   30  451   83]\n",
      " [  16   47    8    7 3082    5 3622   17  148    6]]\n",
      "spectralNet accuracy: 0.799\n",
      "NMI: 0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/cluster/supervised.py:859: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "if 'mnist' in dataset or 'cifar' in dataset:\n",
    "    from core.util import print_accuracy, get_cluster_sols, LearningHandler, make_layer_list, get_y_preds\n",
    "    from sklearn.cluster import KMeans\n",
    "    true_clusters = 10\n",
    "    # get accuracy and nmi\n",
    "    kmeans_assignments, km = get_cluster_sols(y_pred, ClusterClass=KMeans, n_clusters=true_clusters, init_args={'n_init':10})\n",
    "    y_spectralnet, _ = get_y_preds(kmeans_assignments, y_train, true_clusters)\n",
    "    print_accuracy(kmeans_assignments, y_train, true_clusters)\n",
    "    from sklearn.metrics import normalized_mutual_info_score as nmi\n",
    "    nmi_score = nmi(kmeans_assignments, y_train)\n",
    "    print('NMI: ' + str(np.round(nmi_score, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW EMBEDDINGS WITH IM_SCATTER\n",
    "# _ = imscatter(v[:,1], v[:,2], x_all)\n",
    "if 'mnist' in dataset or 'cifar' in dataset:\n",
    "    if 'mnist' in dataset:\n",
    "        img_shape = (28, 28)\n",
    "    elif 'cifar' in dataset:\n",
    "        img_shape = (32, 32, 3)\n",
    "    %matplotlib inline\n",
    "    _ = imscatter(y_pred[:,1], y_pred[:,3], x_test, shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now plot all the dimensions of spectralnet\n",
    "y_pred_embedded = TSNE().fit_transform(y_pred)\n",
    "g = plot(y_pred_embedded[:,:2], y=y_test)\n",
    "\n",
    "if 'mnist' in dataset or 'cifar' in dataset:\n",
    "    %matplotlib inline\n",
    "    if 'mnist' in dataset:\n",
    "        img_shape = (28, 28)\n",
    "    elif 'cifar' in dataset:\n",
    "        img_shape = (32, 32, 3)\n",
    "    _ = imscatter(y_pred_embedded[:,0], y_pred_embedded[:,1], x_test, shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide k by the difference in batch size\n",
    "svg_bsize = 1024\n",
    "svg_k = 1\n",
    "# svg_k = int(latent_dim / 2)\n",
    "conv_decoder = True\n",
    "svg = SVG(inputs, spectralnet=spectral_net, orig_dim=x_train.shape[1:], remove_dim=remove_dim, pca=pca, k=svg_k, alpha=1., arch=[x['size'] for x in arch], conv_decoder=conv_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(x_test))[:100]\n",
    "y_pred_svg = tf_get([svg.input], [svg.x], x_test[p])[0]\n",
    "y_pred_svg_embedded = TSNE().fit_transform(y_pred_svg)\n",
    "\n",
    "if 'mnist' in dataset:\n",
    "    %matplotlib inline\n",
    "    _ = imscatter(y_pred_svg_embedded[:,0], y_pred_svg_embedded[:,1], x_test[p], shape=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = spectral_net.predict(x_test[p])\n",
    "# now plot all the dimensions of spectralnet\n",
    "y_pred_embedded = TSNE().fit_transform(y_pred)\n",
    "# g = plot(y_pred_embedded[:,:2], y=y_test)\n",
    "\n",
    "if 'mnist' in dataset:\n",
    "    %matplotlib inline\n",
    "    _ = imscatter(y_pred_embedded[:,0], y_pred_embedded[:,1], x_test[p], shape=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    svg.train_pca(x_train, epochs=600)\n",
    "    svg.pca_layers[0].trainable = False\n",
    "    svg.pca_layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    y_pred = svg.pc.predict(x_test)\n",
    "    plt.axis('equal')\n",
    "    g = plot(y_pred[:,:3], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf_get([svg.input], [svg.loss], x_test[:10])\n",
    "# tf_get([svg.input], [svg.decoder_xs[-2]], x_test[:10])[0].shape\n",
    "svg.train(x_train, epochs=5000, batch_size=svg_bsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick subset size\n",
    "n_p = min(1000, len(x_test))\n",
    "p = np.random.permutation(len(x_test))[:n_p]\n",
    "x_test_p = x_test[p]\n",
    "y_test_p = y_test[p]\n",
    "\n",
    "# plot generated points\n",
    "x_gen = svg.generate_from_samples(x_train[:10000], normalize_cov=True)\n",
    "g = plot(x_gen, y_train, x2=x_train, s2=0)\n",
    "p_train = np.random.permutation(len(x_train))[:n_p]\n",
    "# if dataset == 'gaussian_grid':\n",
    "#     g = plot_dots(x_gen)\n",
    "# else:\n",
    "#     g = plot(x_gen[p], y_train[p_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "for i, image in enumerate(x_gen):\n",
    "    imageio.imwrite('/projects/mnist_imgs/vdae_test/{:05d}.png'.format(i), np.array(image).reshape(28,28).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.randint(len(x_gen))\n",
    "plt.imshow(x_gen[p].reshape(100,80,3))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM WALK TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(svg.generate_from_samples, return_mu_sigma=True) #, normalize_cov=0.5)\n",
    "y_test_sz = np.mean(f(x_all)[3], axis=1)\n",
    "sz_max = np.max(y_test_sz)\n",
    "sz_min = np.min(y_test_sz)\n",
    "y_test_sz = (y_test_sz - sz_min)/(sz_max - sz_min) * 5\n",
    "print(np.min(y_test_sz), np.max(y_test_sz))\n",
    "y_test_sz = np.exp(0.5 * y_test_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "\n",
    "# which space do we want to plot in?\n",
    "plot_latent = False\n",
    "plot_idx = 1 if plot_latent else 0\n",
    "\n",
    "x_arr = np.random.permutation(x_test)[:100]\n",
    "x__ = f(x_all)[plot_idx]\n",
    "x_ = f(x_arr)[plot_idx]\n",
    "x_tot = np.concatenate([x_, x__], axis=0)\n",
    "y_tot = np.concatenate([np.zeros(shape=(len(x_arr),)), np.ones(shape=(len(x__),))*2], axis=0)\n",
    "y_sz = np.concatenate([np.ones(shape=(len(x_arr),))*5, y_test_sz], axis=0)\n",
    "\n",
    "def update_graph(num):\n",
    "    global x_arr\n",
    "    global x__\n",
    "    global y_tot\n",
    "    x_arr, z_mu, z_sigma_v, z_sigma_lam, _x_enc = f(x_arr)\n",
    "    # plot in latent or original space\n",
    "    x_ = z_mu if plot_latent else x_arr\n",
    "    \n",
    "    x_ = np.concatenate([x_, x__], axis=0)\n",
    "    \n",
    "    if x_.shape[1] == 3:\n",
    "        graph._offsets3d = (x_[:,0], x_[:,1], x_[:,2])\n",
    "        ax.view_init(elev=10, azim=num*4)\n",
    "    elif x_.shape[1] == 2:\n",
    "        graph.set_offsets(np.c_[x_[:,0], x_[:,1]])\n",
    "        \n",
    "    title.set_text('Walk, time={}'.format(num))\n",
    "\n",
    "fig = plt.figure(figsize=(12.8, 7.2))\n",
    "projection = '3d' if x_.shape[1] == 3 else None\n",
    "ax = fig.add_subplot(111, projection=projection)\n",
    "title = ax.set_title('Walk, time=0')\n",
    "\n",
    "if x_.shape[1] == 3:\n",
    "    graph = ax.scatter(x_tot[:,0], x_tot[:,1], x_tot[:,2], c=y_tot, s=y_sz, alpha=.1)\n",
    "elif x_.shape[1] == 2:\n",
    "    graph = ax.scatter(x_tot[:,0], x_tot[:,1], c=y_tot, s=y_sz, alpha=0.4)\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, 180, \n",
    "                               interval=200, blit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "print(\"saving animation\")\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "print(\"...\")\n",
    "ani.save('im_{}_inv.mp4'.format(dataset), writer=writer)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(svg.generate_from_samples, return_mu_sigma=True)#, normalize_cov=0.)\n",
    "def walk(f, x_arr, branch_factor=20, n_steps=10, max_size=5000):\n",
    "    p = np.random.permutation(len(x_arr))[:1000]\n",
    "    x_arr = x_arr[p]\n",
    "    orig_shape = (-1,) + (x_arr.shape[1:])\n",
    "    for i in range(n_steps):\n",
    "        x_arr = np.array([x_arr] * branch_factor).reshape(orig_shape)\n",
    "        (x_arr, z_mu, z_sigma_v, z_sigma_lam, _x_enc) = f(x_arr)\n",
    "        p = np.random.permutation(len(x_arr))[:1000]\n",
    "        x_arr, z_mu, z_sigma_v, z_sigma_lam = x_arr[p], z_mu[p], z_sigma_v[p], z_sigma_lam[p]\n",
    "        x_arr = x_arr.reshape(orig_shape)\n",
    "    \n",
    "    p = np.random.permutation(len(x_arr))[:1000]\n",
    "    x_arr = x_arr[p]\n",
    "        \n",
    "    return x_arr, z_mu, z_sigma_v, z_sigma_lam, _x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(x_test))[:1]\n",
    "x_test_sample = x_test[p]\n",
    "print('random walking on {}'.format(y_test[p]))\n",
    "# x_test_sample = x_train[y_train == 5]\n",
    "x_arr, z_mu, z_sigma_v, z_sigma_lam, _x_enc = walk(f, x_test_sample, n_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(x_arr))\n",
    "x_true_n_gen = np.concatenate([x_test_sample, x_arr[p[:15]]], axis=0)\n",
    "g = plot(x_true_n_gen, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.random.permutation(len(p))[:1000]\n",
    "g, ax = plot(x_arr, x2=x_test[p], label1='predicted', label2='true', alpha2=0.2)\n",
    "# ax.scatter(x_test_sample[:,0], x_test_sample[:,1], x_test_sample[:,2], s=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = plot(z_mu, x2=f(x_test_sample)[1])\n",
    "g = plot(z_mu, x2=f(x_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_arr, x2=x_test_sample, s2=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE BILIP CONSTANT\n",
    "import annoy\n",
    "# for each point in x, determine neighborhood in x, and then compute upper and lower constants\n",
    "def bilip(x, y, k, eps=1e-7):\n",
    "    # find nearest neighbors\n",
    "    a = annoy.AnnoyIndex(x.shape[1], 'euclidean')\n",
    "    for i, x_ in enumerate(x):\n",
    "        a.add_item(i, x_)\n",
    "        \n",
    "    # build nn tree\n",
    "    a.build(-1)\n",
    "    \n",
    "    # compute K\n",
    "    maxs = []\n",
    "    for i in range(len(x)):\n",
    "        x_neighbs, dists = a.get_nns_by_item(i, k+1, include_distances=True)\n",
    "        x_neighbs, dists = x_neighbs[1:], dists[1:]\n",
    "        ratio1 = [np.linalg.norm(x[j] - x[i])/np.linalg.norm(y[j] - y[i]) for j in x_neighbs]\n",
    "        ratio2 = [np.linalg.norm(y[j] - y[i])/np.linalg.norm(x[j] - x[i]) for j in x_neighbs]\n",
    "        max1, max2 = np.max(ratio1), np.max(ratio2)\n",
    "        max_ = max(max1, max2) + eps\n",
    "#         print(ratio1 <= max_, ratio1, max_)\n",
    "#         print(ratio2 >= 1/max_, ratio2, 1/max_)\n",
    "        assert np.all(ratio1 <= max_)\n",
    "        assert np.all(ratio2 >= 1/max_)\n",
    "        maxs.append(max_)\n",
    "        \n",
    "    return maxs\n",
    "\n",
    "# p = np.random.permutation(len(x_train))[:100]\n",
    "x_recon, z_mu, z_sigma_v, z_sigma_lam, _x_enc = svg.generate_from_samples(x_train, return_mu_sigma=True)\n",
    "Ks = bilip(_x_enc, x_recon, 100)\n",
    "print(np.mean(Ks), np.std(Ks), np.max(Ks), np.min(Ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_recon, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
