{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../core')))\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Lambda, Subtract, Dense\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.activations import relu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse\n",
    "\n",
    "import train\n",
    "import costs\n",
    "from data import predict_with_K_fn\n",
    "from layer import stack_layers\n",
    "from util import LearningHandler, make_layer_list, train_gen, get_scale\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET AND USEFUL FUNCTION DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_K_fn(K_fn, x, bs=1000):\n",
    "    '''\n",
    "    Convenience function: evaluates x by K_fn(x), where K_fn is\n",
    "    a Keras function, by batches of size 1000.\n",
    "    '''\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    num_outs = len(K_fn.outputs)\n",
    "    shapes = [list(output_.get_shape()) for output_ in K_fn.outputs]\n",
    "    shapes = [[len(x[0])] + s[1:] for s in shapes]\n",
    "    y = [np.empty(s) for s in shapes]\n",
    "    recon_means = []\n",
    "    for i in range(int((x[0].shape[0]-1)/bs + 1)):\n",
    "        x_batch = []\n",
    "        for x_ in x:\n",
    "            x_batch.append(x_[i*bs:(i+1)*bs])\n",
    "        temp = K_fn(x_batch)\n",
    "        for j in range(num_outs):\n",
    "            y[j][i*bs:(i+1)*bs] = temp[j]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "from matplotlib.colors import ListedColormap\n",
    "# cmap1 = ListedColormap(sns.color_palette().as_hex())\n",
    "# cmap2 = ListedColormap(sns.color_palette('bright').as_hex())\n",
    "def plot(x, y=None, x2=None, y2=None, s=10, s2=None, alpha=0.5, label1=None, label2=None, cmap1=None, cmap2=None):\n",
    "    s2 = s if s2 is None else s2\n",
    "    n = x.shape[1]\n",
    "    if n == 1:\n",
    "        g = plt.figure()\n",
    "        plt.scatter(np.zeros((n,)), x[:,1], c=y, s=s, alpha=alpha, label=label1, cmap=cmap1)\n",
    "        if x2 is not None:\n",
    "            plt.scatter(np.zeros((n,)), x2[:,1], c=y2, s=s2, alpha=alpha, label=label2, cmap=cmap2)\n",
    "    if n == 3:\n",
    "        %matplotlib notebook\n",
    "        g = plt.figure()\n",
    "        ax = g.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x[:,0], x[:,1], x[:,2], c=y, s=s, alpha=alpha, label=label1)\n",
    "        if x2 is not None:\n",
    "            ax.scatter(x2[:,0], x2[:,1], x2[:,2], c=y2, s=s2, alpha=alpha, label=label2)\n",
    "    elif n == 784:\n",
    "        %matplotlib inline\n",
    "        n_imgs = 10\n",
    "        # num = 7\n",
    "        # sub = y == num\n",
    "        sub = y == y\n",
    "        for i in range(n_imgs):\n",
    "            idx = np.random.randint(len(x[sub]))\n",
    "            if x2 is not None:\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(x2[sub][idx].reshape(28, 28))\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(x[sub][idx].reshape(28, 28))\n",
    "            g = plt.figure()\n",
    "    else:\n",
    "        g = plt.figure()\n",
    "        plt.scatter(x[:,0], x[:,1], c=y, s=s, alpha=alpha, label=label1, cmap=cmap1)\n",
    "        if x2 is not None:\n",
    "            plt.scatter(x2[:,0], x2[:,1], c=y2, s=s2, alpha=alpha, label=label2, cmap=cmap2)\n",
    "            \n",
    "    if label1 is not None or label2 is not None:\n",
    "        plt.legend()\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loop(n=1200, train_set_fraction=.8):\n",
    "    t = np.linspace(0, 2*np.pi, num=n)\n",
    "    \n",
    "    # generate all three coordinates\n",
    "    x = np.empty((n, 3))\n",
    "    x[:,0] = np.cos(t)\n",
    "    x[:,1] = np.sin(2*t)\n",
    "    x[:,2] = np.sin(3*t)\n",
    "    \n",
    "    # y is just t\n",
    "    y = t\n",
    "    \n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_circle(n=1000, train_set_fraction=.8, alpha=4):\n",
    "    t = np.linspace(0, 2*np.pi, num=n)\n",
    "#     t = np.log(np.linspace(1, alpha, num=n))\n",
    "    t = t / np.max(t) * 2 * np.pi\n",
    "    \n",
    "    # generate all three coordinates\n",
    "    x = np.empty((n, 2))\n",
    "    x[:,0] = np.cos(t)\n",
    "    x[:,1] = np.sin(t)\n",
    "    \n",
    "    # y is just t\n",
    "    y = t\n",
    "    \n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_line(n=1200, train_set_fraction=.8):\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    x1 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x2 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x = np.concatenate([x1, x2], axis=1)\n",
    "    \n",
    "    # generate labels\n",
    "#     y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "    y = x1\n",
    "    \n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_gaussians(n=1200, n_clusters=2, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / n_clusters)\n",
    "    r = 1\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    for x in np.linspace(0, 1, num=n_clusters):\n",
    "        clusters.append(np.random.normal(x, noise_sigma, size=(pts_per_cluster, 2)))\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate(clusters, axis=0)\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_cc(n=1200, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    r = 1\n",
    "\n",
    "    # generate clusters\n",
    "    theta1 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "    theta2 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "\n",
    "    cluster1 = np.concatenate((np.cos(theta1) * r, np.sin(theta1) * r), axis=1)\n",
    "    cluster2 = np.concatenate((np.cos(theta2) * r, np.sin(theta2) * r), axis=1)\n",
    "\n",
    "    # shift and reverse cluster 2\n",
    "    cluster2[:, 0] = -cluster2[:, 0] + 0.5\n",
    "    cluster2[:, 1] = -cluster2[:, 1] - 1\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate((cluster1, cluster2), axis=0)\n",
    "\n",
    "    # add noise to x\n",
    "    x = x + np.random.randn(x.shape[0], 2) * noise_sigma\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: max 1.0, min -1.0\n"
     ]
    }
   ],
   "source": [
    "dataset = 'loop'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "#     (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#     x_train, x_test = x_train.reshape((-1, 784)), x_test.reshape((-1, 784))\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = x_train.reshape(len(x_train), -1) / 255\n",
    "    x_test = x_test.reshape(len(x_test), -1) / 255\n",
    "    latent_dim = 9\n",
    "elif dataset == 'gaussians':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_gaussians(n=2000, n_clusters=1, train_set_fraction=0.85)\n",
    "    latent_dim = 6\n",
    "elif dataset == 'line':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_line(n=2000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'loop':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_loop(n=10000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'cc':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_cc(n=2000, noise_sigma=0.1, train_set_fraction=0.85)\n",
    "    latent_dim = 3\n",
    "elif dataset == 'circle':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_circle(n=1024, train_set_fraction=0.85, alpha=30)\n",
    "    latent_dim = 2\n",
    "\n",
    "x_all = np.concatenate([x_train, x_test], axis=0)\n",
    "    \n",
    "# normalize to between -1 and 1\n",
    "if dataset != 'mnist':\n",
    "    m, M = np.min(x_train), np.max(x_train)\n",
    "    a = (M + m) / 2\n",
    "    b = (M - m) / 2\n",
    "    x_train, x_test = (x_train - a) / b, (x_test - a) / b\n",
    "print('IMPORTANT: max {}, min {}'.format(np.max(x_train), np.min(x_train)))\n",
    "\n",
    "arch = [\n",
    "    {'type': 'relu', 'size': 128},\n",
    "    {'type': 'relu', 'size': 128},\n",
    "    {'type': 'relu', 'size': 512},\n",
    "    {'type': 'linear', 'size': 16},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNet:\n",
    "    def __init__(self, inputs, arch, spec_reg, y_true, y_train_labeled_onehot,\n",
    "            n_clusters, affinity, scale_nbr, n_nbrs, batch_sizes, normalized=False,\n",
    "            siamese_net=None, x_train=None, have_labeled=False):\n",
    "        self.y_true = y_true\n",
    "        self.y_train_labeled_onehot = y_train_labeled_onehot\n",
    "        self.inputs = inputs\n",
    "        self.batch_sizes = batch_sizes\n",
    "        self.normalized = normalized\n",
    "        # generate layers\n",
    "        self.layers = make_layer_list(arch[:-1], 'spectral', spec_reg)\n",
    "        self.layers += [\n",
    "                  {'type': 'tanh',\n",
    "                   'size': n_clusters,\n",
    "                   'l2_reg': spec_reg,\n",
    "                   'name': 'spectral_{}'.format(len(arch)-1)},\n",
    "                  {'type': 'Orthonorm', 'name':'orthonorm'}\n",
    "                  ]\n",
    "\n",
    "        # create spectralnet\n",
    "        self.outputs = stack_layers(self.inputs, self.layers)\n",
    "        self.net = Model(inputs=self.inputs['Unlabeled'], outputs=self.outputs['Unlabeled'])\n",
    "\n",
    "        # DEFINE LOSS\n",
    "\n",
    "        # generate affinity matrix W according to params\n",
    "        if affinity == 'siamese':\n",
    "            input_affinity = tf.concat([siamese_net.outputs['A'], siamese_net.outputs['Labeled']], axis=0)\n",
    "            x_affinity = siamese_net.predict(x_train, batch_sizes)\n",
    "        elif affinity in ['knn', 'full']:\n",
    "            input_affinity = tf.concat([self.inputs['Unlabeled'], self.inputs['Labeled']], axis=0)\n",
    "            x_affinity = x_train\n",
    "\n",
    "        # calculate scale for affinity matrix\n",
    "        scale = get_scale(x_affinity, self.batch_sizes['Unlabeled'], scale_nbr)\n",
    "\n",
    "        # create affinity matrix\n",
    "        if affinity == 'full':\n",
    "            W = costs.full_affinity(input_affinity, scale=scale)\n",
    "        elif affinity in ['knn', 'siamese']:\n",
    "            W = costs.knn_affinity(input_affinity, n_nbrs, scale=scale, scale_nbr=scale_nbr)\n",
    "\n",
    "        # if we have labels, use them\n",
    "        if have_labeled:\n",
    "            # get true affinities (from labeled data)\n",
    "            W_true = tf.cast(tf.equal(costs.squared_distance(y_true), 0),dtype='float32')\n",
    "\n",
    "            # replace lower right corner of W with W_true\n",
    "            unlabeled_end = tf.shape(self.inputs['Unlabeled'])[0]\n",
    "            W_u = W[:unlabeled_end, :]                  # upper half\n",
    "            W_ll = W[unlabeled_end:, :unlabeled_end]    # lower left\n",
    "            W_l = tf.concat((W_ll, W_true), axis=1)      # lower half\n",
    "            W = tf.concat((W_u, W_l), axis=0)\n",
    "\n",
    "            # create pairwise batch distance matrix self.Dy\n",
    "            y_ = tf.concat([self.outputs['Unlabeled'], self.outputs['Labeled']], axis=0)\n",
    "        else:\n",
    "            y_ = self.outputs['Unlabeled']\n",
    "            \n",
    "        if self.normalized:\n",
    "            y_old = y_\n",
    "            y_ = y_ / tf.expand_dims(tf.reduce_sum(W, axis=1), axis=-1)\n",
    "        \n",
    "        self.Dy = costs.squared_distance(y_)\n",
    "\n",
    "        # define loss\n",
    "        self.loss = K.sum(W * self.Dy) / (2 * batch_sizes['Unlabeled'])\n",
    "\n",
    "        # create the train step update\n",
    "        self.learning_rate = tf.Variable(0., name='spectral_net_learning_rate')\n",
    "        self.train_step = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "#         self.train_step = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "        \n",
    "        # initialize spectralnet variables\n",
    "        K.get_session().run(tf.variables_initializer(self.net.trainable_weights))\n",
    "\n",
    "    def train(self, x_train_unlabeled, x_train_labeled, x_val_unlabeled,\n",
    "            lr, drop, patience, num_epochs):\n",
    "        # create handler for early stopping and learning rate scheduling\n",
    "        self.lh = LearningHandler(\n",
    "                lr=lr,\n",
    "                drop=drop,\n",
    "                lr_tensor=self.learning_rate,\n",
    "                patience=patience)\n",
    "\n",
    "        losses = np.empty((num_epochs,))\n",
    "        val_losses = np.empty((num_epochs,))\n",
    "\n",
    "        # begin spectralnet training loop\n",
    "        self.lh.on_train_begin()\n",
    "        i = 0\n",
    "        for i in range(num_epochs):\n",
    "            # train spectralnet\n",
    "            losses[i] = train.train_step(\n",
    "                    return_var=[self.loss],\n",
    "                    updates=self.net.updates + [self.train_step],\n",
    "                    x_unlabeled=x_train_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    batch_sizes=self.batch_sizes,\n",
    "                    x_labeled=x_train_labeled,\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batches_per_epoch=100)[0]\n",
    "\n",
    "            # get validation loss\n",
    "            val_losses[i] = train.predict_sum(\n",
    "                    self.loss,\n",
    "                    x_unlabeled=x_val_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x_train_unlabeled[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batch_sizes=self.batch_sizes)\n",
    "\n",
    "            # do early stopping if necessary\n",
    "            if self.lh.on_epoch_end(i, val_losses[i]):\n",
    "                print('STOPPING EARLY')\n",
    "                break\n",
    "\n",
    "            # print training status\n",
    "            print(\"Epoch: {}, loss={:2f}, val_loss={:2f}\".format(i, losses[i], val_losses[i]))\n",
    "\n",
    "        return losses[:i+1], val_losses[:i+1]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # test inputs do not require the 'Labeled' input\n",
    "        inputs_test = {'Unlabeled': self.inputs['Unlabeled'], 'Orthonorm': self.inputs['Orthonorm']}\n",
    "        return train.predict(\n",
    "                    self.outputs['Unlabeled'],\n",
    "                    x_unlabeled=x,\n",
    "                    inputs=inputs_test,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot[0:0],\n",
    "                    batch_sizes=self.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVG:\n",
    "    def __init__(self, inputs, spectralnet, orig_dim, remove_dim=False, pca=True, normalize_factor=.1, eps=1e-6):\n",
    "        optimizer = 'adam'\n",
    "#         optimizer = RMSprop(lr=0.00005)\n",
    "        self.input = inputs['Unlabeled']\n",
    "        self.orig_dim = orig_dim\n",
    "        self.eps = eps\n",
    "        self.pca = pca\n",
    "        \n",
    "        x = self.copy_spectralnet(spectralnet)\n",
    "        \n",
    "        #\n",
    "        # DEFINE ALL LOSSES\n",
    "        #\n",
    "        def mu_loss(_, __):\n",
    "            self.mu_loss = K.sum(mse(self.input, self.mu_recon)) * self.orig_dim\n",
    "            return self.mu_loss\n",
    "        def kl_loss(_, __):\n",
    "            alpha = .01\n",
    "            e_log = K.log(self.z_cov_values)\n",
    "            kl_loss = -1 + K.log(alpha) - e_log + self.z_cov_values/alpha\n",
    "            self.kl_loss = K.sum(kl_loss) * 0.5\n",
    "            return self.kl_loss\n",
    "        def pca_loss(_, __):\n",
    "            if self.pca:\n",
    "                self.pca_loss = K.sum(mse(self.pca_input, self.pca_recon)) * self.orig_dim\n",
    "            else:\n",
    "                self.pca_loss = tf.constant(0.)\n",
    "            return self.pca_loss\n",
    "        def neighbor_loss(_, __):\n",
    "            k = 8\n",
    "            # obtain pairwise distances (size(recon) x size(input))\n",
    "            D = self.pairwise_distances(self.x_enc, self.mu)\n",
    "\n",
    "            # get nearest (i.e., largest negative distance) neighbors of each point\n",
    "            vals, _ = tf.nn.top_k(-D, k=k)\n",
    "\n",
    "            # remove self as neighbor, negate to get positive distances again\n",
    "            vals = -vals[:, 1:]\n",
    "\n",
    "            # pick sigma\n",
    "            # sigma = tf.reduce_max(vals[:, 0])\n",
    "            sigma = vals[:, :1] + self.eps\n",
    "            sq_vals = vals ** 2\n",
    "            \n",
    "            loss = sq_vals * tf.exp(-sq_vals / sigma)\n",
    "            self.neighbor_loss = K.sum(loss)\n",
    "\n",
    "            return self.neighbor_loss\n",
    "        # currently unused\n",
    "        def reconstruction_loss(_, __):\n",
    "            self.reconstruction_loss = K.sum(mse(self.input, self.x_recon)) * self.orig_dim\n",
    "            return self.reconstruction_loss\n",
    "        \n",
    "        def vae_loss(_, __):\n",
    "            return self.loss\n",
    "        \n",
    "        #\n",
    "        # DEFINE LAYERS\n",
    "        #\n",
    "\n",
    "        # create encoder\n",
    "        self.x_enc = x_enc = self.build_encoder(x, remove_dim=remove_dim, pca=self.pca)\n",
    "        self.encoder = Model(inputs=self.input, outputs=x_enc)\n",
    "\n",
    "        # create decoder\n",
    "        x_recon = self.build_decoder(x_enc)\n",
    "        self.decoder = Model(inputs=self.input, outputs=x_recon)\n",
    "        self.mu_recon = self.build_decoder(self.build_encoder(x, no_noise=True))\n",
    "        self.x_recon = x_recon\n",
    "        \n",
    "        # create normalized decoder\n",
    "        x_enc_norm = self.build_encoder(x, normalize_cov=normalize_factor)\n",
    "        self.x_recon_norm = self.build_decoder(x_enc_norm)\n",
    "        \n",
    "        if self.pca:\n",
    "            self.pcae = Model(inputs=self.input, outputs=self.pca_recon)\n",
    "            self.pc = Model(inputs=self.input, outputs=self.pc_embedding)\n",
    "            self.pcae.compile(optimizer=optimizer, loss=pca_loss)\n",
    "            \n",
    "        #\n",
    "        # COMPUTE LOSS\n",
    "        #\n",
    "        losses = [reconstruction_loss, mu_loss, kl_loss, pca_loss, neighbor_loss]\n",
    "        self.init_losses = [l(None, None) for l in losses]\n",
    "        loss_weights = [0, 1, 1, 0, 1]\n",
    "        # initialize losses\n",
    "        self.loss = sum([a * b for a, b in zip(self.init_losses, loss_weights)])\n",
    "        \n",
    "        #\n",
    "        # ASSEMBLE NETWORK\n",
    "        #\n",
    "        self.vae = Model(inputs=self.input, outputs=self.x_recon)\n",
    "        self.vae.compile(optimizer=optimizer, loss=vae_loss)\n",
    "        \n",
    "    def pairwise_distances(self, A, B):\n",
    "        r_A, r_B = tf.reduce_sum(A*A, 1), tf.reduce_sum(B*B, 1)\n",
    "\n",
    "        # turn r into column vector\n",
    "        r_A, r_B = tf.reshape(r_A, [-1, 1]), tf.reshape(r_B, [-1, 1])\n",
    "        D = r_A - 2 * tf.matmul(A, B, transpose_b=True) + tf.transpose(r_B)\n",
    "\n",
    "        return D\n",
    "        \n",
    "    def build_decoder(self, x, arch=[1024, 256, 256]):\n",
    "        if not hasattr(self, 'decoder_layers'):\n",
    "            self.decoder_layers = [Dense(a, activation='relu') for a in arch]\n",
    "            self.decoder_layers.append(Dense(self.orig_dim, activation='linear'))\n",
    "\n",
    "        for l in self.decoder_layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def build_encoder(self, x, arch=[256, 256, 1024], pca=True, normalize_cov=False, no_noise=False, remove_dim=False):\n",
    "        if pca and not hasattr(self, 'pca_layers'):\n",
    "            self.pca_layers = [Dense(self.latent_dim, activation='linear'), Dense(self.spectralnet_dim, activation='linear')]\n",
    "            \n",
    "        if not hasattr(self, 'encoder_layers'):\n",
    "            self.encoder_precov_layers = [Dense(a, activation='relu') for a in arch]\n",
    "            self.encoder_precov_layers.append(Dense(self.latent_dim * self.latent_dim, activation='linear'))\n",
    "            \n",
    "        # assemble pca layer (a linear autoencoder) and define mu (the latent embedding of this layer)\n",
    "        if pca:\n",
    "            if not hasattr(self, 'pca_input'):\n",
    "                self.pca_input = x\n",
    "\n",
    "            self.pc_embedding = x = self.pca_layers[0](x)\n",
    "\n",
    "            if not hasattr(self, 'pca_recon'):\n",
    "                self.pca_recon = self.pca_layers[1](x)\n",
    "\n",
    "        # define mu (the latent embedding of the pca layer)\n",
    "        mu = x\n",
    "        if not hasattr(self, 'mu'):\n",
    "            self.mu = mu\n",
    "        \n",
    "        # get covariance precursor\n",
    "        for l in self.encoder_precov_layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        # sample latent space (and normalize covariances if we're trying to do random walks)\n",
    "        if not hasattr(self, 'encoder_sampling_layer'):\n",
    "            f = partial(self.sampling, normalize_cov=normalize_cov, remove_dim=remove_dim)\n",
    "            self.encoder_sampling_layer = Lambda(f, output_shape=(self.latent_dim,), name='z')\n",
    "            \n",
    "        if no_noise:\n",
    "            cur_encoder_sampling_layer = Lambda(lambda x_: x_[0], output_shape=(self.latent_dim,))\n",
    "            \n",
    "        # get encoder embedding\n",
    "        x_enc = self.encoder_sampling_layer([mu, x])\n",
    "        \n",
    "        return x_enc\n",
    "        \n",
    "    def copy_spectralnet(self, spectralnet):\n",
    "        xs = [self.input]\n",
    "        layers = []\n",
    "        for l in spectralnet.net.layers[1:-1]:\n",
    "            w = l.get_weights()\n",
    "            n, m = w[0].shape\n",
    "            if hasattr(l, 'activation'):\n",
    "                act = l.activation\n",
    "            new_l = Dense(m, activation=act, input_shape=(n,), weights=w)\n",
    "            new_l.trainable = False\n",
    "            xs.append(new_l(xs[-1]))\n",
    "            layers.append(new_l)\n",
    "\n",
    "        pre_x = xs[-1]\n",
    "        # add orthonorm layer\n",
    "        sess = K.get_session()\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            v = tf.get_variable(\"ortho_weights_store\")\n",
    "        ows = sess.run(v)\n",
    "        t_ows = K.variable(ows)\n",
    "        l = Lambda(lambda x: K.dot(x, t_ows))\n",
    "        l.trainable = False\n",
    "        xs.append(l(xs[-1]))\n",
    "        layers.append(l)\n",
    "\n",
    "        x = xs[-1]\n",
    "\n",
    "        self.sn = Model(inputs=self.input, outputs=x)\n",
    "\n",
    "        self.spectralnet_dim = int(x.get_shape()[1])\n",
    "        if self.pca:\n",
    "            self.latent_dim = self.spectralnet_dim - 1\n",
    "        else:\n",
    "            self.latent_dim = self.spectralnet_dim\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def sampling(self, args, normalize_cov, remove_dim=False):\n",
    "        # get args\n",
    "        z_mean, precov = args\n",
    "        \n",
    "        # reshape precov and compute cov = precov x precov.T\n",
    "        precov = tf.reshape(precov, (-1, self.latent_dim, self.latent_dim))\n",
    "        self.cov = cov = tf.einsum('ijk,ilk->ijl', precov, precov)\n",
    "\n",
    "        # perform eigendecomposition\n",
    "        e, v = tf.linalg.eigh(cov)\n",
    "\n",
    "        # eigenvectors/values are sorted in increasing order; let's reverse them\n",
    "        e, v = e[:, ::-1], v[:, :, ::-1]\n",
    "            \n",
    "        dim = self.latent_dim\n",
    "        # remove one dimension if remove_dim is true (to enforce singular covariance matrix)\n",
    "        if remove_dim:\n",
    "            dim = self.latent_dim - 1\n",
    "            e, v = e[:, :dim], v[:, :, :dim]\n",
    "        \n",
    "        if not hasattr(self, 'z_cov_vectors'):\n",
    "            self.z_cov_vectors = tf.reshape(v, (-1, self.latent_dim * dim))\n",
    "            self.z_cov_values = e\n",
    "        \n",
    "        # get shapes\n",
    "        batch = K.shape(z_mean)[0]\n",
    "                \n",
    "        # sample from normal distribution\n",
    "        epsilon = K.random_normal(shape=(batch, K.int_shape(z_mean)[1]))\n",
    "        \n",
    "        # self.z_cov_vectors.shape = (n_batches, n_dim, n_dim); epsilon.shape = (n_batches, n_dim)\n",
    "        if normalize_cov:\n",
    "            e = e * normalize_cov\n",
    "        \n",
    "        # get sqrt covariance matrix stack\n",
    "        left_mid_z_sqrt_var = tf.einsum('ijk,ik->ijk', v, tf.sqrt(e))\n",
    "        z_sqrt_var = tf.einsum('ijk,ilk->ijl', left_mid_z_sqrt_var, v)\n",
    "        \n",
    "        # multiply covariance matrix stack with random normal vector\n",
    "        z_sqrt_var_epsilon = tf.einsum('ijk,ik->ij', z_sqrt_var, epsilon)\n",
    "        \n",
    "        if not hasattr(self, 'z_sqrt_var'):\n",
    "            self.z_sqrt_var = tf.reshape(z_sqrt_var, (-1, self.latent_dim * self.latent_dim))\n",
    "        \n",
    "        # assembled output\n",
    "        output = z_mean + z_sqrt_var_epsilon\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def generate_from_samples(self, x, return_mu_sigma=False, normalize_cov=False):\n",
    "        _x_recon = self.x_recon_norm if normalize_cov else self.x_recon\n",
    "        get_fn = K.function([self.input], [_x_recon, self.mu, self.z_cov_vectors, self.z_cov_values])\n",
    "        x_recon, x_mu, x_sigma_v, x_sigma_lam = predict_with_K_fn(get_fn, x)\n",
    "        if return_mu_sigma:\n",
    "            return x_recon, x_mu, x_sigma_v, x_sigma_lam\n",
    "        else:\n",
    "            return x_recon\n",
    "        \n",
    "    def train_pca(self, x_train, x_val=None, epochs=1, batch_size=128, patience=5):\n",
    "        if x_val is not None:\n",
    "            val_data = list((x_val, x_val))\n",
    "        else:\n",
    "            val_data = None\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "\n",
    "        self.pcae.fit(x=x_train,\n",
    "                y=x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=val_data,\n",
    "                callbacks=[earlystop],\n",
    "                verbose=2)\n",
    "        \n",
    "    def train(self, X_train, batch_size=128, epochs=100):      \n",
    "        self.vae_loss = []\n",
    "        for epoch in range(epochs):\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            samples = [X_train[idx]]\n",
    "            vae_loss = self.vae.train_on_batch(samples, samples)\n",
    "            self.vae_loss.append(vae_loss)\n",
    "\n",
    "            if epoch % 25 == 0:\n",
    "                # Plot the progress\n",
    "                loss_names = ['reconstruction_loss', 'mu_loss', 'kl_loss', 'pca_loss', 'neighbor_loss']\n",
    "                loss_string = \"{} [VAE loss: {}] [\" + \": {}] [\".join(loss_names) + \": {}]\"\n",
    "                loss_vals = K.get_session().run(self.init_losses, feed_dict={self.input: X_train})\n",
    "                print(loss_string.format(epoch, vae_loss, *loss_vals))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='2663ef7b-4736-4b9e-a59d-9a14fb27f1b1'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_dim = True\n",
    "pca = True\n",
    "\n",
    "# NOTE: currently the train and test sets are combined\n",
    "\n",
    "# split = int(len(x_train)*0.8)\n",
    "# x_train, x_val = x_train[:split], x_train[split:]\n",
    "# y_train, y_val = y_train[:split], y_train[split:]\n",
    "\n",
    "x_train = np.concatenate([x_train, x_test], axis=0)\n",
    "y_train = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "# plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\n",
    "# g = plot(x_train, y_train)\n",
    "g = plot(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "if pca:\n",
    "    n_clusters = latent_dim + 1\n",
    "else:\n",
    "    n_clusters = latent_dim\n",
    "\n",
    "bsize = 512\n",
    "\n",
    "batch_sizes = {\n",
    "    'Unlabeled': bsize,\n",
    "    'Labeled': bsize,\n",
    "    'Orthonorm': bsize,\n",
    "    }\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "y_true = tf.placeholder(tf.float32, shape=(None, n_clusters), name='y_true')\n",
    "y_train_labeled_onehot = np.empty((0, len(np.unique(y_train))))\n",
    "inputs = {\n",
    "    'Unlabeled': Input(shape=input_shape, name='UnlabeledInput'),\n",
    "    'Labeled': Input(shape=input_shape, name='LabeledInput'),\n",
    "    'Orthonorm': Input(shape=input_shape, name='OrthonormInput'),\n",
    "    }\n",
    "k = 3\n",
    "spectral_net = SpectralNet(inputs, arch,\n",
    "            None, y_true, y_train_labeled_onehot,\n",
    "            n_clusters, affinity='full', scale_nbr=k, n_nbrs=k, \n",
    "            batch_sizes=batch_sizes, siamese_net=None, \n",
    "            x_train=x_train, have_labeled=len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss=0.179712, val_loss=0.004566\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-87779d645ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m spectral_net.train(\n\u001b[1;32m      2\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         lr=5e-5, drop=0.1, patience=30, num_epochs=100)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1d8af9ec9333>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train_unlabeled, x_train_labeled, x_val_unlabeled, lr, drop, patience, num_epochs)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mx_labeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_labeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0my_labeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train_labeled_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     batches_per_epoch=100)[0]\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# get validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projects/SpectralVAEGAN/src/core/train.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(return_var, updates, x_unlabeled, inputs, y_true, batch_sizes, x_labeled, y_labeled, batches_per_epoch)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Unlabeled'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_unlabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mbatch_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_unlabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_unlabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "spectral_net.train(\n",
    "        x_train, np.zeros_like(x_train[0:0]), x_test,\n",
    "        lr=5e-5, drop=0.1, patience=30, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = spectral_net.predict(x_test)\n",
    "g = plot(y_pred[:,:3], y_test)\n",
    "print('range of y_pred values: {} - {}'.format(np.max(y_pred), np.min(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now plot all the dimensions of spectralnet\n",
    "y_pred_embedded = TSNE().fit_transform(y_pred)\n",
    "g = plot(y_pred_embedded[:,:2], y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = SVG(inputs, spectralnet=spectral_net, orig_dim=x_train.shape[-1], remove_dim=remove_dim, pca=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pca:\n",
    "    svg.train_pca(x_train, epochs=75)\n",
    "    svg.pca_layers[0].trainable = False\n",
    "    svg.pca_layers[1].trainable = False\n",
    "    \n",
    "    y_pred = svg.pc.predict(x_test)\n",
    "    plt.axis('equal')\n",
    "    g = plot(y_pred[:,:3], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svg.train(x_train, epochs=1000, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot generated points\n",
    "x_gen = svg.generate_from_samples(x_train)\n",
    "# g = plot(x_gen, y_train, x2=x_train, s2=0)\n",
    "g = plot(x_gen, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dim = latent_dim - 1 if remove_dim else latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of neighbors within one standard deviation of each element in x_test\n",
    "_, _mu, _sigma_v, _sigma_lam = svg.generate_from_samples(x_test, return_mu_sigma=True)\n",
    "_sigma_v = _sigma_v.reshape(-1, latent_dim, cov_dim)\n",
    "\n",
    "num_close = []\n",
    "for i in range(len(_mu)):\n",
    "    l, v, m = np.exp(0.5 * -_sigma_lam[i,:]), _sigma_v[i,:], _mu[i,:]\n",
    "    left_cov = np.einsum('ij,j->ij', v, l)\n",
    "    cov = np.einsum('ij,kj->ik', left_cov, v)\n",
    "    scaled_dists = np.einsum('jk,ik->ij', cov, _mu - m)\n",
    "    # consider as neighbors all points within the variance of x_i\n",
    "    less_than_std = np.abs(scaled_dists) < 1\n",
    "    less_than_std = np.logical_and(less_than_std[:,0], less_than_std[:,1])\n",
    "    # split neighbors into those of the same class and those of a different class\n",
    "    same, diff = (y_test[less_than_std] == y_test[i]), (y_test[less_than_std] != y_test[i])\n",
    "    num_close.append((np.sum(same), np.sum(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered = (_sigma_v - np.mean(_sigma_v, axis=0)).reshape(_sigma_v.shape[:-1])\n",
    "_cov = centered.T.dot(centered) / len(_sigma_v)\n",
    "print('MEAN VALUE\\n', np.mean(np.sqrt(_sigma_lam), axis=0))\n",
    "print('MEAN VECTOR\\n', np.mean(_sigma_v, axis=0))\n",
    "print('COVARIANCE\\n', _cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVARIANCE TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fn1 = K.function([svg.input], [svg.z_sqrt_var])\n",
    "get_fn2 = K.function([svg.input], [svg.x_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = np.random.normal(size=_mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compute sigmas\n",
    "_, _mu, _sigma_v, _sigma_lam = svg.generate_from_samples(x_test, return_mu_sigma=True)\n",
    "_sigma_v = _sigma_v.reshape(-1, latent_dim, cov_dim)\n",
    "# _sigma_v = np.einsum('ijk->ikj', _sigma_v)\n",
    "# _sigma_lam = np.flip(_sigma_lam, axis=1)\n",
    "_sigma = np.einsum('ijk,ilk->ijl', np.einsum('ijk,ik->ijk', _sigma_v, np.exp(0.5 * _sigma_lam[:,:1])), _sigma_v)\n",
    "\n",
    "# verify sigmas\n",
    "_z_sqrt_var = predict_with_K_fn(get_fn1, x_test)[0].reshape((-1, latent_dim, latent_dim))\n",
    "\n",
    "# verify encoding\n",
    "_x_enc = predict_with_K_fn(get_fn2, x_test)[0]\n",
    "\n",
    "print(\"ALSO\", _sigma.shape, _z_sqrt_var.shape)\n",
    "print('ERROR', np.linalg.norm(_sigma - _z_sqrt_var))\n",
    "\n",
    "# epsilon = np.random.normal(size=_mu.shape)\n",
    "perturbations = np.einsum('ijk,ik->ij', _sigma, epsilon)\n",
    "# perturbations = epsilon\n",
    "\n",
    "single_perturbed_x = np.array([_mu[0,:]] * len(_mu)) + np.einsum('jk,ik->ij', _sigma[0,:], epsilon)\n",
    "perturbed_x = _mu + perturbations\n",
    "# g = plot(x=_mu, y=y_test)\n",
    "# g = plot(x=perturbed_x, y=y_test, x2=_mu, s2=100)\n",
    "g = plot(perturbed_x, y=y_test)#, x2=_mu, s2=100)\n",
    "# plt.figure()\n",
    "\n",
    "idxs = np.random.permutation(len(_mu))\n",
    "for i in idxs:\n",
    "    idx = np.argmin(_sigma_lam[i])\n",
    "    delta = _sigma_v[i, idx] * np.exp(0.5 * _sigma_lam[i, idx])\n",
    "    start = _mu[i] + delta\n",
    "    end = _mu[i] - delta\n",
    "    plt.plot([start[0], end[0]], [start[1], end[1]], 'k-', lw=2, alpha=0.01)\n",
    "    \n",
    "plt.axis('equal')\n",
    "\n",
    "# plt.scatter(_mu[idxs, 0], _mu[idxs, 1], s=200)\n",
    "# plt.plot([0, 1], [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sigmas\n",
    "_, _mu, _sigma_v, _sigma_lam = svg.generate_from_samples(x_test, return_mu_sigma=True)\n",
    "_sigma_v = _sigma_v.reshape(-1, latent_dim, cov_dim)\n",
    "# _sigma_v = np.einsum('ijk->ikj', _sigma_v)\n",
    "# _sigma_lam = np.flip(_sigma_lam, axis=1)\n",
    "_sigma = np.einsum('ijk,ilk->ijl', np.einsum('ijk,ik->ijk', _sigma_v, np.exp(0.5 * _sigma_lam)), _sigma_v)\n",
    "\n",
    "epsilon = np.random.normal(size=_mu.shape)\n",
    "perturbations = np.einsum('ijk,ik->ij', _sigma, epsilon)\n",
    "\n",
    "single_perturbed_x = np.array([_mu[0,:]] * len(_mu)) + np.einsum('jk,ik->ij', _sigma[0,:], epsilon)\n",
    "perturbed_x = _mu + perturbations\n",
    "g = plot(_mu, x2=perturbed_x, s2=20)\n",
    "plt.axis('equal')\n",
    "\n",
    "idxs = np.random.permutation(len(_mu))\n",
    "for i in idxs:\n",
    "    idx = np.argmax(_sigma_lam[i])\n",
    "    delta = _sigma_v[i, idx] * _sigma_lam[i, idx] / 8\n",
    "    start = _mu[i] + delta\n",
    "    end = _mu[i] - delta\n",
    "    plt.plot([start[0], end[0]], [start[1], end[1]], 'k-', lw=2, alpha=0.1)\n",
    "    \n",
    "for i in idxs:\n",
    "    idx = np.argmin(_sigma_lam[i])\n",
    "    delta = _sigma_v[i, idx] * np.exp(0.5 * _sigma_lam[i, idx])\n",
    "    start = _mu[i] + delta\n",
    "    end = _mu[i] - delta\n",
    "    plt.plot([start[0], end[0]], [start[1], end[1]], 'k-', lw=2, alpha=0.1)\n",
    "#     plt.plot([_mu[i,0], _mu[i,0]], [_mu[i,1] + .1, _mu[i,1]])\n",
    "\n",
    "# plt.scatter(_mu[idxs, 0], _mu[idxs, 1], s=200)\n",
    "# plt.plot([0, 1], [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_ = np.random.randint(0, len(_mu))\n",
    "# i_ = 0\n",
    "# print(_sigma[i_].dot(_sigma_v[i_]))\n",
    "# print(np.exp(0.5 * _sigma_lam[i_]))\n",
    "# print(_sigma_v[i_])\n",
    "# print(epsilon[i_])\n",
    "# print(_sigma[i_].dot(epsilon[i_]))\n",
    "# print(perturbed_x[i_])\n",
    "# print(_mu[i_])\n",
    "\n",
    "tmp = np.expand_dims(_sigma[i_].dot(epsilon[i_]), axis=0)\n",
    "tmp2 = perturbed_x[i_-1:i_]\n",
    "tmp3 = np.expand_dims(np.einsum('ij,j->j', _sigma[i_], epsilon[i_]), axis=0)\n",
    "tmp4 = np.expand_dims(np.einsum('ij,j->i', _sigma[i_], epsilon[i_]), axis=0)\n",
    "print('tmp', tmp)\n",
    "print('tmp2', tmp2)\n",
    "print('tmp3', tmp3, np.linalg.norm(tmp3/_mu[i_]))\n",
    "print('tmp4', tmp4, np.linalg.norm(tmp4/_mu[i_]))\n",
    "g = plot(_mu[i_:i_+1], x2=_mu[i_] + tmp, s=1000, s2=300)\n",
    "plt.scatter(_mu[:,0], _mu[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BILIPSCHITZ TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiate decoder with respect to inputs to compute another jacobian, and then evaluate it on the same point\n",
    "_jacobian = [tf.expand_dims(tf.gradients(svg.x_recon[:,i], svg.x_enc)[0], 1) for i in range(svg.x_recon.shape[1])]\n",
    "jacobian = tf.reduce_sum(tf.concat(_jacobian, axis=1), axis=0)\n",
    "v = tf.reshape(svg.z_cov_vectors, (-1, latent_dim, cov_dim))\n",
    "v = tf.Print(v, [tf.shape(v), tf.shape(svg.z_cov_values)], 'PRINT')\n",
    "temp = tf.einsum('ijk,ik->ijk', v, tf.sqrt(svg.z_cov_values[:,:1]))\n",
    "print(v.get_shape(), svg.z_cov_values.get_shape(), temp.get_shape())\n",
    "B = tf.einsum('ijk,ilk->ijl', temp, v)\n",
    "B = tf.reduce_mean(B, axis=0)\n",
    "cov = tf.matmul(jacobian, tf.matmul(B, jacobian, transpose_b=True))\n",
    "cov = tf.reshape(cov, (x_test[0].shape[0], x_test[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create burst from a point and compute covariance matrix\n",
    "burst_size = 1000\n",
    "rand_idx = np.random.randint(len(x_test))\n",
    "x_ = x_test[rand_idx]\n",
    "# x_ = np.array((np.cos(.25), np.sin(.25)))\n",
    "x_arr = np.array([x_] * burst_size)\n",
    "x_rec, x_mu, x_sigma_v, x_sigma_lam = svg.generate_from_samples(x_arr, return_mu_sigma=True)\n",
    "\n",
    "cov_burst = np.cov((x_rec - np.mean(x_rec, axis=0)).T)\n",
    "\n",
    "# run gradient burst\"\n",
    "# cov_grad = K.get_session().run([svg.x_recon, cov, B, jacobian], feed_dict={svg.input: np.array([x_]*1)})\n",
    "cov_grad = K.get_session().run([cov], feed_dict={svg.input: np.array([x_]*1)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_burst, _ = np.linalg.eig(cov_burst)\n",
    "l_grad, _ = np.linalg.eig(cov_grad)\n",
    "l_burst = np.sort(l_burst)[::-1]\n",
    "l_grad = np.sort(l_grad)[::-1]\n",
    "print('l_burst:', l_burst, l_burst/l_burst[0])\n",
    "print('l_grad:', l_grad, l_grad/l_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_rec, x2=x_test, label1='true', label2='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x__ = np.expand_dims(x_, axis=0)\n",
    "g = plot(x__, x2=x_test, alpha=.1, label1='true', label2='predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM WALK TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM WALK\n",
    "def walk(f, x_arr, branch_factor=5, n_steps=20, max_size=1000):\n",
    "    p = np.random.permutation(len(x_arr))[:1000]\n",
    "    x_arr = x_arr[p]\n",
    "    for i in range(n_steps):\n",
    "        x_arr = np.array([x_arr] * branch_factor).reshape([-1, x_.shape[0]])\n",
    "        (x_arr, x_mu, x_sigma) = f(x_arr)\n",
    "        p = np.random.permutation(len(x_arr))[:1000]\n",
    "        x_arr, x_mu, x_sigma = x_arr[p], x_mu[p], x_sigma[p]\n",
    "        \n",
    "    return x_arr, x_mu, x_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(svg.generate_from_samples, return_mu_sigma=True, normalize_cov=0.1)\n",
    "y_test_sz = np.mean(f(x_all)[3], axis=1)\n",
    "sz_max = np.max(y_test_sz)\n",
    "sz_min = np.min(y_test_sz)\n",
    "y_test_sz = (y_test_sz - sz_min)/(sz_max - sz_min) * 5\n",
    "print(np.min(y_test_sz), np.max(y_test_sz))\n",
    "y_test_sz = np.exp(0.5 * y_test_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "\n",
    "# which space do we want to plot in?\n",
    "plot_latent = False\n",
    "plot_idx = 1 if plot_latent else 0\n",
    "\n",
    "x_arr = np.random.permutation(x_test)[:100]\n",
    "x__ = f(x_all)[plot_idx]\n",
    "x_ = f(x_arr)[plot_idx]\n",
    "x_tot = np.concatenate([x_, x__], axis=0)\n",
    "y_tot = np.concatenate([np.zeros(shape=(len(x_arr),)), np.ones(shape=(len(x__),))*2], axis=0)\n",
    "y_sz = np.concatenate([np.ones(shape=(len(x_arr),))*5, y_test_sz], axis=0)\n",
    "\n",
    "def update_graph(num):\n",
    "    global x_arr\n",
    "    global x__\n",
    "    global y_tot\n",
    "    x_arr, x_mu, x_sigma_v, x_sigma_lam = f(x_arr)\n",
    "    # plot in latent or original space\n",
    "    x_ = x_mu if plot_latent else x_arr\n",
    "    \n",
    "    x_ = np.concatenate([x_, x__], axis=0)\n",
    "    graph._offsets3d = (x_[:,0], x_[:,1], x_[:,2])\n",
    "    ax.view_init(elev=10, azim=num*4)\n",
    "    title.set_text('Walk, time={}'.format(num))\n",
    "\n",
    "fig = plt.figure(figsize=(12.8, 7.2))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "title = ax.set_title('Walk, time=0')\n",
    "\n",
    "# NOTE: ONLY RUNS WITH 3D DATASETS\n",
    "graph = ax.scatter(x_tot[:,0], x_tot[:,1], x_tot[:,2], c=y_tot, s=y_sz, alpha=0.4)\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, update_graph, 180, \n",
    "                               interval=50, blit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(ani.to_html5_video(embed_limit=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(svg.generate_from_samples, return_mu_sigma=True, normalize_cov=False)\n",
    "def walk(f, x_arr, branch_factor=5, n_steps=20, max_size=1000):\n",
    "    p = np.random.permutation(len(x_arr))[:1000]\n",
    "    x_arr = x_arr[p]\n",
    "    for i in range(n_steps):\n",
    "        print(x_arr.shape, branch_factor)\n",
    "        x_arr = np.array([x_arr] * branch_factor).reshape([-1, x_.shape[1]])\n",
    "        (x_arr, x_mu, x_sigma_v, x_sigma_lam) = f(x_arr)\n",
    "        p = np.random.permutation(len(x_arr))[:1000]\n",
    "        x_arr, x_mu, x_sigma_v, x_sigma_lam = x_arr[p], x_mu[p], x_sigma_v[p], x_sigma_lam[p]\n",
    "        \n",
    "    return x_arr, x_mu, x_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(svg.generate_from_samples, return_mu_sigma=True)\n",
    "\n",
    "x_test_sample = np.random.permutation(x_test)[:10]\n",
    "x_arr, x_sigma, x_mu = walk(f, x_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_arr, x2=x_test, label1='predicted', label2='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = plot(x_mu, x2=f(x_test_sample)[1])\n",
    "g = plot(x_mu, x2=f(x_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"samar was here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
