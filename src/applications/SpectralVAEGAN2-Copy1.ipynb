{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/henry/henry/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..')))\n",
    "sys.path.insert(0, '/home/henry/projects/SpectralVAEGAN/src/core/')\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('/home/henry/projects/SpectralVAEGAN/src/applications'),'..')))\n",
    "import numpy as np\n",
    "import pickle\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Lambda, Subtract, Dense\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.activations import relu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import train\n",
    "import costs\n",
    "from data import predict_with_K_fn\n",
    "from layer import stack_layers\n",
    "from util import LearningHandler, make_layer_list, train_gen, get_scale\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_K_fn(K_fn, x, bs=1000):\n",
    "    '''\n",
    "    Convenience function: evaluates x by K_fn(x), where K_fn is\n",
    "    a Keras function, by batches of size 1000.\n",
    "    '''\n",
    "    if not isinstance(x, list):\n",
    "        x = [x]\n",
    "    num_outs = len(K_fn.outputs)\n",
    "    y = [np.empty((len(x[0]), output_.get_shape()[1])) for output_ in K_fn.outputs]\n",
    "    recon_means = []\n",
    "    for i in range(int(x[0].shape[0]/bs + 1)):\n",
    "        x_batch = []\n",
    "        for x_ in x:\n",
    "            x_batch.append(x_[i*bs:(i+1)*bs])\n",
    "        temp = K_fn(x_batch)\n",
    "        for j in range(num_outs):\n",
    "            y[j][i*bs:(i+1)*bs] = temp[j]\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loop(n=1200, train_set_fraction=.8):\n",
    "    t = np.linspace(0, 2*np.pi, num=n)\n",
    "    \n",
    "    # generate all three coordinates\n",
    "    x = np.empty((n, 3))\n",
    "    x[:,0] = np.cos(t)\n",
    "    x[:,1] = np.sin(2*t)\n",
    "    x[:,2] = np.sin(3*t)\n",
    "    \n",
    "    # y is just t\n",
    "    y = t\n",
    "    \n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_line(n=1200, train_set_fraction=.8):\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    x1 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x2 = np.linspace(0, 1, num=n).reshape((-1, 1))\n",
    "    x = np.concatenate([x1, x2], axis=1)\n",
    "    \n",
    "    # generate labels\n",
    "#     y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "    y = x1\n",
    "    \n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_gaussians(n=1200, n_clusters=2, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / n_clusters)\n",
    "    r = 1\n",
    "    \n",
    "    clusters = []\n",
    "    \n",
    "    for x in np.linspace(0, 1, num=n_clusters):\n",
    "        clusters.append(np.random.normal(x, noise_sigma, size=(pts_per_cluster, 2)))\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate(clusters, axis=0)\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def generate_cc(n=1200, noise_sigma=0.1, train_set_fraction=1.):\n",
    "    '''\n",
    "    Generates and returns the nested 'C' example dataset (as seen in the leftmost\n",
    "    graph in Fig. 1)\n",
    "    '''\n",
    "    pts_per_cluster = int(n / 2)\n",
    "    r = 1\n",
    "\n",
    "    # generate clusters\n",
    "    theta1 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "    theta2 = (np.random.uniform(0, 1, pts_per_cluster) * r * np.pi - np.pi / 2).reshape(pts_per_cluster, 1)\n",
    "\n",
    "    cluster1 = np.concatenate((np.cos(theta1) * r, np.sin(theta1) * r), axis=1)\n",
    "    cluster2 = np.concatenate((np.cos(theta2) * r, np.sin(theta2) * r), axis=1)\n",
    "\n",
    "    # shift and reverse cluster 2\n",
    "    cluster2[:, 0] = -cluster2[:, 0] + 0.5\n",
    "    cluster2[:, 1] = -cluster2[:, 1] - 1\n",
    "\n",
    "    # combine clusters\n",
    "    x = np.concatenate((cluster1, cluster2), axis=0)\n",
    "\n",
    "    # add noise to x\n",
    "    x = x + np.random.randn(x.shape[0], 2) * noise_sigma\n",
    "    print(np.max(x), np.min(x))\n",
    "    x /= (np.max(x) - np.min(x))\n",
    "    print(np.max(x), np.min(x))\n",
    "    x -= np.min(x)\n",
    "    print(np.max(x), np.min(x))\n",
    "\n",
    "    # generate labels\n",
    "    y = np.concatenate((np.zeros(shape=(pts_per_cluster, 1)), np.ones(shape=(pts_per_cluster, 1))), axis=0)\n",
    "\n",
    "    # shuffle\n",
    "    p = np.random.permutation(n)\n",
    "    y = y[p]\n",
    "    x = x[p]\n",
    "\n",
    "    # make train and test splits\n",
    "    n_train = int(n * train_set_fraction)\n",
    "    x_train, x_test = x[:n_train], x[n_train:]\n",
    "    y_train, y_test = y[:n_train].flatten(), y[n_train:].flatten()\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, y=None, x2=None, y2=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    %matplotlib inline\n",
    "    n = x.shape[1]\n",
    "    if n == 1:\n",
    "        plt.scatter(np.zeros((n,)), x[:,1], c=y, marker='x')\n",
    "        if x2 is not None:\n",
    "            plt.scatter(np.zeros((n,)), x2[:,1], c=y2, s=10)\n",
    "    if n == 3:\n",
    "        %matplotlib notebook\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x[:,0], x[:,1], x[:,2], c=y, marker='x')\n",
    "        if x2 is not None:\n",
    "            ax.scatter(x2[:,0], x2[:,1], x2[:,2], c=y2, s=10)\n",
    "    elif n == 784:\n",
    "        n_imgs = 10\n",
    "        # num = 7\n",
    "        # sub = y == num\n",
    "        sub = y == y\n",
    "        for i in range(n_imgs):\n",
    "            idx = np.random.randint(len(x[sub]))\n",
    "            if x2 is not None:\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(x2[sub][idx].reshape(28, 28))\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(x[sub][idx].reshape(28, 28))\n",
    "            plt.figure()\n",
    "    else:\n",
    "        plt.scatter(x[:,0], x[:,1], c=y, marker='x')\n",
    "        if x2 is not None:\n",
    "            plt.scatter(x2[:,0], x2[:,1], c=y2, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: max 1.0, min 0.0005002501250625312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = 'line'\n",
    "\n",
    "if dataset == 'mnist':\n",
    "#     (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#     x_train, x_test = x_train.reshape((-1, 784)), x_test.reshape((-1, 784))\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # reshape and standardize x arrays\n",
    "    x_train = x_train.reshape(len(x_train), -1) / 255\n",
    "    x_test = x_test.reshape(len(x_test), -1) / 255\n",
    "    latent_dim = 10\n",
    "elif dataset == 'gaussians':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_gaussians(n=2000, n_clusters=2, train_set_fraction=0.85)\n",
    "    latent_dim = 4\n",
    "elif dataset == 'line':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_line(n=2000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "elif dataset == 'loop':\n",
    "    (x_train, y_train), (x_test, y_test) = generate_loop(n=2000, train_set_fraction=0.85)\n",
    "    latent_dim = 2\n",
    "\n",
    "# normalize to between -1 and 1\n",
    "# m, M = np.min(x_train), np.max(x_train)\n",
    "# x_train, x_test = x_train / (M - m) * 2 - 1, x_test / (M - m) * 2 - 1\n",
    "print('IMPORTANT: max {}, min {}'.format(np.max(x_train), np.min(x_train)))\n",
    "\n",
    "arch = [\n",
    "    {'type': 'relu', 'size': 1024},\n",
    "    {'type': 'relu', 'size': 1024},\n",
    "    {'type': 'relu', 'size': 512},\n",
    "    {'type': 'linear', 'size': latent_dim},\n",
    "    ]\n",
    "\n",
    "plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNet:\n",
    "    def __init__(self, inputs, arch, spec_reg, y_true, y_train_labeled_onehot,\n",
    "            n_clusters, affinity, scale_nbr, n_nbrs, batch_sizes,\n",
    "            siamese_net=None, x_train=None, have_labeled=False):\n",
    "        self.y_true = y_true\n",
    "        self.y_train_labeled_onehot = y_train_labeled_onehot\n",
    "        self.inputs = inputs\n",
    "        self.batch_sizes = batch_sizes\n",
    "        # generate layers\n",
    "        self.layers = make_layer_list(arch[:-1], 'spectral', spec_reg)\n",
    "        self.layers += [\n",
    "                  {'type': 'tanh',\n",
    "                   'size': n_clusters,\n",
    "                   'l2_reg': spec_reg,\n",
    "                   'name': 'spectral_{}'.format(len(arch)-1)},\n",
    "                  {'type': 'Orthonorm', 'name':'orthonorm'}\n",
    "                  ]\n",
    "\n",
    "        # create spectralnet\n",
    "        self.outputs = stack_layers(self.inputs, self.layers)\n",
    "        self.net = Model(inputs=self.inputs['Unlabeled'], outputs=self.outputs['Unlabeled'])\n",
    "\n",
    "        # DEFINE LOSS\n",
    "\n",
    "        # generate affinity matrix W according to params\n",
    "        if affinity == 'siamese':\n",
    "            input_affinity = tf.concat([siamese_net.outputs['A'], siamese_net.outputs['Labeled']], axis=0)\n",
    "            x_affinity = siamese_net.predict(x_train, batch_sizes)\n",
    "        elif affinity in ['knn', 'full']:\n",
    "            input_affinity = tf.concat([self.inputs['Unlabeled'], self.inputs['Labeled']], axis=0)\n",
    "            x_affinity = x_train\n",
    "\n",
    "        # calculate scale for affinity matrix\n",
    "        scale = get_scale(x_affinity, self.batch_sizes['Unlabeled'], scale_nbr)\n",
    "\n",
    "        # create affinity matrix\n",
    "        if affinity == 'full':\n",
    "            W = costs.full_affinity(input_affinity, scale=scale)\n",
    "        elif affinity in ['knn', 'siamese']:\n",
    "            W = costs.knn_affinity(input_affinity, n_nbrs, scale=scale, scale_nbr=scale_nbr)\n",
    "\n",
    "        # if we have labels, use them\n",
    "        if have_labeled:\n",
    "            # get true affinities (from labeled data)\n",
    "            W_true = tf.cast(tf.equal(costs.squared_distance(y_true), 0),dtype='float32')\n",
    "\n",
    "            # replace lower right corner of W with W_true\n",
    "            unlabeled_end = tf.shape(self.inputs['Unlabeled'])[0]\n",
    "            W_u = W[:unlabeled_end, :]                  # upper half\n",
    "            W_ll = W[unlabeled_end:, :unlabeled_end]    # lower left\n",
    "            W_l = tf.concat((W_ll, W_true), axis=1)      # lower half\n",
    "            W = tf.concat((W_u, W_l), axis=0)\n",
    "\n",
    "            # create pairwise batch distance matrix self.Dy\n",
    "            self.Dy = costs.squared_distance(tf.concat([self.outputs['Unlabeled'], self.outputs['Labeled']], axis=0))\n",
    "        else:\n",
    "            self.Dy = costs.squared_distance(self.outputs['Unlabeled'])\n",
    "\n",
    "        # define loss\n",
    "        self.loss = K.sum(W * self.Dy) / (2 * batch_sizes['Unlabeled'])\n",
    "\n",
    "        # create the train step update\n",
    "        self.learning_rate = tf.Variable(0., name='spectral_net_learning_rate')\n",
    "        self.train_step = tf.train.RMSPropOptimizer(learning_rate=self.learning_rate).minimize(self.loss, var_list=self.net.trainable_weights)\n",
    "\n",
    "        # initialize spectralnet variables\n",
    "        K.get_session().run(tf.variables_initializer(self.net.trainable_weights))\n",
    "\n",
    "    def train(self, x_train_unlabeled, x_train_labeled, x_val_unlabeled,\n",
    "            lr, drop, patience, num_epochs):\n",
    "        # create handler for early stopping and learning rate scheduling\n",
    "        self.lh = LearningHandler(\n",
    "                lr=lr,\n",
    "                drop=drop,\n",
    "                lr_tensor=self.learning_rate,\n",
    "                patience=patience)\n",
    "\n",
    "        losses = np.empty((num_epochs,))\n",
    "        val_losses = np.empty((num_epochs,))\n",
    "\n",
    "        # begin spectralnet training loop\n",
    "        self.lh.on_train_begin()\n",
    "        i = 0\n",
    "        for i in range(num_epochs):\n",
    "            # train spectralnet\n",
    "            losses[i] = train.train_step(\n",
    "                    return_var=[self.loss],\n",
    "                    updates=self.net.updates + [self.train_step],\n",
    "                    x_unlabeled=x_train_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    batch_sizes=self.batch_sizes,\n",
    "                    x_labeled=x_train_labeled,\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batches_per_epoch=100)[0]\n",
    "\n",
    "            # get validation loss\n",
    "            val_losses[i] = train.predict_sum(\n",
    "                    self.loss,\n",
    "                    x_unlabeled=x_val_unlabeled,\n",
    "                    inputs=self.inputs,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x_train_unlabeled[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot,\n",
    "                    batch_sizes=self.batch_sizes)\n",
    "\n",
    "            # do early stopping if necessary\n",
    "            if self.lh.on_epoch_end(i, val_losses[i]):\n",
    "                print('STOPPING EARLY')\n",
    "                break\n",
    "\n",
    "            # print training status\n",
    "            print(\"Epoch: {}, loss={:2f}, val_loss={:2f}\".format(i, losses[i], val_losses[i]))\n",
    "\n",
    "        return losses[:i+1], val_losses[:i+1]\n",
    "\n",
    "    def predict(self, x):\n",
    "        # test inputs do not require the 'Labeled' input\n",
    "        inputs_test = {'Unlabeled': self.inputs['Unlabeled'], 'Orthonorm': self.inputs['Orthonorm']}\n",
    "        return train.predict(\n",
    "                    self.outputs['Unlabeled'],\n",
    "                    x_unlabeled=x,\n",
    "                    inputs=inputs_test,\n",
    "                    y_true=self.y_true,\n",
    "                    x_labeled=x[0:0],\n",
    "                    y_labeled=self.y_train_labeled_onehot[0:0],\n",
    "                    batch_sizes=self.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class SVG:\n",
    "    def __init__(self, inputs, spectralnet, orig_dim, latent_dim=2):\n",
    "        from keras.layers import Input, Dense\n",
    "        optimizer = 'adam' #RMSprop(lr=0.00005)\n",
    "        self.input = inputs['Unlabeled']\n",
    "        self.orig_dim = orig_dim\n",
    "        \n",
    "        # initialize losses:\n",
    "        self.gen_loss = []\n",
    "        self.disc_loss = []\n",
    "        self.vae_loss = []\n",
    "        \n",
    "        if spectralnet is not None:\n",
    "            x = self.copy_spectralnet(spectralnet)\n",
    "        else:\n",
    "            self.latent_dim = latent_dim\n",
    "            x = self.input\n",
    "\n",
    "        # create encoder\n",
    "        x_enc = self.build_encoder(x)\n",
    "        self.encoder = Model(inputs=self.input, outputs=x_enc)\n",
    "\n",
    "        # create decoder\n",
    "        x_recon = self.build_decoder(x_enc)\n",
    "        self.decoder = Model(inputs=self.input, outputs=x_recon)\n",
    "        self.x_recon = x_recon\n",
    "        \n",
    "        # create critic\n",
    "        x_critic, x_critic_interm, x_critic_input = self.build_critic(input_shape=(orig_dim,))\n",
    "        self.critic, self.critic_interm = Model(x_critic_input, x_critic), Model(x_critic_input, x_critic_interm)\n",
    "        \n",
    "        ######################################\n",
    "        #                                        \n",
    "        # build computation graph for critic\n",
    "        #                                        \n",
    "        ######################################\n",
    "        self.encoder.trainable = False\n",
    "        self.decoder.trainable = False\n",
    "        self.critic.trainable = True\n",
    "        \n",
    "        # fake example\n",
    "        fake_sample = x_recon\n",
    "        \n",
    "        fake = self.critic(fake_sample)\n",
    "        valid = self.critic(self.input)\n",
    "        \n",
    "        # construct weighted average between real and fake images\n",
    "        interpolated_sample = RandomWeightedAverage()([self.input, fake_sample])\n",
    "        # determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_sample)\n",
    "\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_sample)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=self.input,\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        \n",
    "        #######################################\n",
    "        #                                        \n",
    "        # build computation graph for generator\n",
    "        #                                        \n",
    "        #######################################\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.encoder.trainable = False\n",
    "        self.decoder.trainable = True\n",
    "        self.critic.trainable = False\n",
    "\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(x_recon)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(self.input, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "        #######################################\n",
    "        #                                        \n",
    "        # build computation graph for VAE\n",
    "        #                                        \n",
    "        #######################################\n",
    "        \n",
    "        # For the VAE we freeze the critic's layers\n",
    "        self.encoder.trainable = True\n",
    "        self.decoder.trainable = True\n",
    "        self.critic.trainable = False\n",
    "        \n",
    "#         x_interm = self.critic_interm(x_recon)\n",
    "#         x_interm_orig = self.critic_interm(self.input)\n",
    "        x_interm = x_recon\n",
    "        x_interm_orig = self.input\n",
    "        \n",
    "        from keras.losses import mse\n",
    "        def vae_loss(_, __):\n",
    "            # alpha is what we want the variances to be (usually 1, but we want it smaller)\n",
    "            alpha = 0.5\n",
    "            alpha = float(alpha)\n",
    "            reconstruction_loss = K.sum(mse(x_interm, x_interm_orig), axis=-1) * self.orig_dim\n",
    "            kl_loss = -1 + np.log(alpha) - self.sigma + K.exp(self.sigma)/alpha\n",
    "            kl_loss = K.sum(kl_loss, axis=-1) * 0.5\n",
    "            vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "            return vae_loss\n",
    "        \n",
    "        self.vae = Model(inputs=self.input, outputs=x_interm)\n",
    "        self.vae.compile(optimizer=optimizer, loss=vae_loss)\n",
    "        \n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "        \n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "        \n",
    "    def build_critic(self, input_shape):\n",
    "        x = x_input = Input(shape=input_shape)\n",
    "        x = Dense(256, input_shape=input_shape, activation='relu')(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = x_interm = Dense(32, name='interm_layer', activation='relu')(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        \n",
    "        return x, x_interm, x_input\n",
    "        \n",
    "    def build_decoder(self, x):\n",
    "        if not hasattr(self, 'decoder_layers'):\n",
    "            self.decoder_layers = []\n",
    "            self.decoder_layers.append(Dense(1024, activation='relu'))\n",
    "            self.decoder_layers.append(Dense(256, activation='relu'))\n",
    "            self.decoder_layers.append(Dense(256, activation='relu'))\n",
    "            # last layer of decoder / generator is always tanh (LINEAR because of WASSERSTEIN LOSS)\n",
    "            self.decoder_layers.append(Dense(self.orig_dim, activation='linear'))\n",
    "            \n",
    "        for l in self.decoder_layers:\n",
    "            x = l(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def build_encoder(self, x_input):\n",
    "        if not hasattr(self, 'encoder_layers'):\n",
    "            self.encoder_layers = []\n",
    "            self.encoder_layers.append(Dense(256, activation='relu'))\n",
    "            self.encoder_layers.append(Dense(256, activation='relu'))\n",
    "            self.encoder_layers.append(Dense(1024, activation='relu'))\n",
    "            self.encoder_layers.append(Dense(self.latent_dim, activation='linear'))\n",
    "        \n",
    "        x = x_input\n",
    "        for l in self.encoder_layers:\n",
    "            x = l(x)\n",
    "\n",
    "        # option 1\n",
    "        self.sigma = sigma = x\n",
    "        self.mu = mu = x_input\n",
    "        self.x_enc = Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([mu, sigma])\n",
    "        self.encoder = Model(self.input, [self.x_enc])\n",
    "        self.log_variances = Model(self.input, sigma)\n",
    "        \n",
    "        return self.x_enc\n",
    "        \n",
    "    def copy_spectralnet(self, spectralnet):\n",
    "        xs = [self.input]\n",
    "        layers = []\n",
    "        for l in spectralnet.net.layers[1:-1]:\n",
    "            w = l.get_weights()\n",
    "            n, m = w[0].shape\n",
    "            if hasattr(l, 'activation'):\n",
    "                act = l.activation\n",
    "            new_l = Dense(m, activation=act, input_shape=(n,), weights=w)\n",
    "            new_l.trainable = False\n",
    "            xs.append(new_l(xs[-1]))\n",
    "            layers.append(new_l)\n",
    "\n",
    "        pre_x = xs[-1]\n",
    "        # add orthonorm layer\n",
    "        sess = K.get_session()\n",
    "        with tf.variable_scope('', reuse=True):\n",
    "            v = tf.get_variable(\"ortho_weights_store\")\n",
    "        ows = sess.run(v)\n",
    "        t_ows = K.variable(ows)\n",
    "        l = Lambda(lambda x: K.dot(x, t_ows))\n",
    "        l.trainable = False\n",
    "        xs.append(l(xs[-1]))\n",
    "        layers.append(l)\n",
    "\n",
    "        x = xs[-1]\n",
    "\n",
    "        self.sn = Model(inputs=self.input, outputs=x)\n",
    "\n",
    "        self.latent_dim = int(x.get_shape()[1])\n",
    "        if self.latent_dim != latent_dim:\n",
    "            print(\"\"\"warning, spectralnet's latent_dim={} \n",
    "            and provided latent_dim={} do not match, \n",
    "            defaulting to spectralnet's!\"\"\".format(self.latent_dim, latent_dim))\n",
    "            \n",
    "        return x\n",
    "\n",
    "    def sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        output = z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "        return output\n",
    "\n",
    "    def generate_from_samples(self, x):\n",
    "        get_fn = K.function([self.input], [self.x_recon])\n",
    "        x_recon = predict_with_K_fn(get_fn, x)[0]\n",
    "        return x_recon\n",
    "#         return self.decoder.predict(x)\n",
    "\n",
    "    def train(self, xy_train, xy_val, epochs=1, batch_size=128, patience=5):\n",
    "        x_train, y_train = xy_train\n",
    "        x_val, y_val = xy_val\n",
    "        earlystop = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "        val_data = list((x_val, x_val))\n",
    "\n",
    "        self.vae.fit(x=x_train,\n",
    "                y=x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=val_data,\n",
    "                # callbacks=[earlystop, pe],\n",
    "                callbacks=[earlystop],\n",
    "                verbose=2)\n",
    "        \n",
    "    def train_gan(self, X_train, batch_size=128, epochs=10, n_critic=5, n_vae=5, sample_interval=1):\n",
    "        # Adversarial ground truths\n",
    "            valid = -np.ones((batch_size, 1))\n",
    "            fake =  np.ones((batch_size, 1))\n",
    "            dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "            d_loss = g_loss = vae_loss = 0\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "#                 for _ in range(n_critic):\n",
    "\n",
    "#                     # ---------------------\n",
    "#                     #  Train Discriminator\n",
    "#                     # ---------------------\n",
    "\n",
    "#                     # Select a random batch of samples\n",
    "#                     idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "#                     samples = X_train[idx]\n",
    "#                     # Train the critic\n",
    "#                     d_loss = self.critic_model.train_on_batch(samples,\n",
    "#                                                                     [valid, fake, dummy])\n",
    "#                     self.disc_loss.append(d_loss)\n",
    "                    \n",
    "#                 # ---------------------\n",
    "#                 #  Train Generator\n",
    "#                 # ---------------------\n",
    "#                 idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "#                 samples = X_train[idx]\n",
    "#                 g_loss = self.generator_model.train_on_batch(samples, valid)\n",
    "#                 self.gen_loss.append(g_loss)\n",
    "                \n",
    "                \n",
    "                #######################\n",
    "                #\n",
    "                # Train VAE\n",
    "                #\n",
    "                #######################\n",
    "                \n",
    "                for _ in range(n_vae):\n",
    "\n",
    "                    # ---------------------\n",
    "                    #  Train Discriminator\n",
    "                    # ---------------------\n",
    "\n",
    "                    # Select a random batch of samples\n",
    "                    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                    samples = X_train[idx]\n",
    "                    vae_loss = self.vae.train_on_batch(samples, samples)\n",
    "                    self.vae_loss.append(vae_loss)\n",
    "\n",
    "                # Plot the progress\n",
    "                print (\"{} [D loss: {}] [G loss: {}] [VAE loss: {}]\".format(epoch, d_loss, g_loss, vae_loss))\n",
    "                \n",
    "    def generate(self, num_gen=10):\n",
    "        noise = np.random.normal(0, 1, (num_gen, self.latent_dim))\n",
    "        return self.decoder.predict(noise)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "split = int(len(x_train)*0.8)\n",
    "x_train, x_val = x_train[:split], x_train[split:]\n",
    "y_train, y_val = y_train[:split], y_train[split:]\n",
    "\n",
    "# plt.scatter(x_test[:,0], x_test[:,1], c=y_test)\n",
    "plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/henry/henry/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "Epoch: 0, loss=0.000030, val_loss=0.000000\n",
      "Epoch: 1, loss=0.000063, val_loss=0.000000\n",
      "Epoch: 2, loss=0.000058, val_loss=0.000000\n",
      "Epoch: 3, loss=0.000055, val_loss=0.000000\n",
      "Epoch: 4, loss=0.000055, val_loss=0.000000\n",
      "Epoch: 5, loss=0.000054, val_loss=0.000000\n",
      "Epoch: 6, loss=0.000053, val_loss=0.000000\n",
      "Epoch: 7, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 8, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 9, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 10, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 11, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 12, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 13, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 14, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 15, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 16, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 17, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 18, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 19, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 20, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 21, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 22, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 23, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 24, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 25, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 26, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 27, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 28, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 29, loss=0.000052, val_loss=0.000000\n",
      "Epoch: 30, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 31, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 32, loss=0.000051, val_loss=0.000000\n",
      "Epoch: 33, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 34, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 35, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 36, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 37, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 38, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 39, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 40, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 41, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 42, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 43, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 44, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 45, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 46, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 47, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 48, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 49, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 50, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 51, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 52, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 53, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 54, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 55, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 56, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 57, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 58, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 59, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 60, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 61, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 62, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 63, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 64, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 65, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 66, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 67, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 68, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 69, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 70, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 71, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 72, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 73, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 74, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 75, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 76, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 77, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 78, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 79, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 80, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 81, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 82, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 83, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 84, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 85, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 86, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 87, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 88, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 89, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 90, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 91, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 92, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 93, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 94, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 95, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 96, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 97, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 98, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 99, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 100, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 101, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 102, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 103, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 104, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 105, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 106, loss=0.000048, val_loss=0.000000\n",
      "Epoch: 107, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 108, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 109, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 110, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 111, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 112, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 113, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 114, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 115, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 116, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 117, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 118, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 119, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 120, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 121, loss=0.000050, val_loss=0.000000\n",
      "Epoch: 122, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 123, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 124, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 125, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 126, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 127, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 128, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 129, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 130, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 131, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 132, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 133, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 134, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 135, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 136, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 137, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 138, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 139, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 140, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 141, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 142, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 143, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 144, loss=0.000048, val_loss=0.000000\n",
      "Epoch: 145, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 146, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 147, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 148, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 149, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 150, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 151, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 152, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 153, loss=0.000049, val_loss=0.000000\n",
      "Epoch: 154, loss=0.000049, val_loss=0.000000\n",
      "STOPPING EARLY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2.97301699e-05, 6.31645516e-05, 5.77896141e-05, 5.48837365e-05,\n",
       "        5.48700810e-05, 5.37860843e-05, 5.29865197e-05, 5.20718822e-05,\n",
       "        5.22511229e-05, 5.19556217e-05, 5.19447393e-05, 5.19544102e-05,\n",
       "        5.16607636e-05, 5.22893016e-05, 5.16793773e-05, 5.11328529e-05,\n",
       "        5.09341511e-05, 5.12162997e-05, 5.14779015e-05, 5.12534728e-05,\n",
       "        5.20578853e-05, 5.20926466e-05, 5.20673094e-05, 5.12041515e-05,\n",
       "        5.13638653e-05, 5.06917200e-05, 5.12480592e-05, 5.16475523e-05,\n",
       "        5.10778985e-05, 5.18907252e-05, 5.12799056e-05, 5.11374767e-05,\n",
       "        5.07288898e-05, 4.97293913e-05, 4.92472124e-05, 4.90244859e-05,\n",
       "        4.94647248e-05, 4.99096031e-05, 4.99871886e-05, 4.98818110e-05,\n",
       "        4.99219626e-05, 4.96776438e-05, 4.96897981e-05, 4.96952246e-05,\n",
       "        4.95828714e-05, 4.96489012e-05, 4.94868991e-05, 4.99446913e-05,\n",
       "        4.94097739e-05, 4.91754340e-05, 4.97526567e-05, 5.01302853e-05,\n",
       "        4.96025465e-05, 4.95831272e-05, 4.95610819e-05, 4.97152544e-05,\n",
       "        4.98934767e-05, 4.97209012e-05, 4.94839869e-05, 5.00371541e-05,\n",
       "        4.99160512e-05, 5.00353328e-05, 4.98472342e-05, 4.91848052e-05,\n",
       "        4.87308644e-05, 4.93016575e-05, 4.93208090e-05, 4.90860572e-05,\n",
       "        4.92693009e-05, 4.90319266e-05, 4.98666082e-05, 4.93728809e-05,\n",
       "        4.92296763e-05, 4.92984949e-05, 4.97726857e-05, 4.94495965e-05,\n",
       "        4.89202230e-05, 4.95434635e-05, 4.88015473e-05, 4.89968209e-05,\n",
       "        4.93400485e-05, 4.90114122e-05, 4.91234803e-05, 4.97652962e-05,\n",
       "        4.94281547e-05, 4.91863420e-05, 4.93585356e-05, 4.87177886e-05,\n",
       "        4.91434500e-05, 4.96231282e-05, 4.88977254e-05, 4.90320258e-05,\n",
       "        4.90811609e-05, 4.92767440e-05, 4.91797504e-05, 4.90935597e-05,\n",
       "        4.93281763e-05, 4.90211516e-05, 4.90876963e-05, 4.90475461e-05,\n",
       "        4.93106871e-05, 4.86549176e-05, 4.91598238e-05, 4.91976439e-05,\n",
       "        4.89404235e-05, 4.88831851e-05, 4.84424644e-05, 4.92590659e-05,\n",
       "        4.92560886e-05, 4.91704594e-05, 4.87929408e-05, 4.89881111e-05,\n",
       "        4.92949877e-05, 4.90550615e-05, 4.92702504e-05, 4.90018605e-05,\n",
       "        4.88299255e-05, 4.91696190e-05, 4.95811622e-05, 4.89032650e-05,\n",
       "        4.87503769e-05, 4.95749376e-05, 4.87369934e-05, 4.91963648e-05,\n",
       "        4.88726727e-05, 4.91376341e-05, 4.87583162e-05, 4.89437981e-05,\n",
       "        4.91975725e-05, 4.92338970e-05, 4.89808830e-05, 4.89493622e-05,\n",
       "        4.90195543e-05, 4.90952832e-05, 4.92740413e-05, 4.91973800e-05,\n",
       "        4.90585572e-05, 4.87484130e-05, 4.90470219e-05, 4.91062206e-05,\n",
       "        4.89742179e-05, 4.85750857e-05, 4.89555506e-05, 4.91443207e-05,\n",
       "        4.83106205e-05, 4.88481505e-05, 4.91214906e-05, 4.89983242e-05,\n",
       "        4.85944798e-05, 4.88850983e-05, 4.92411181e-05, 4.89424645e-05,\n",
       "        4.91152199e-05, 4.92379665e-05, 4.90447961e-05, 4.90814812e-05]),\n",
       " array([8.60869562e-08, 2.21403326e-07, 2.24159280e-07, 1.78233378e-07,\n",
       "        2.57375973e-07, 2.15792525e-07, 2.11355584e-07, 2.03301255e-07,\n",
       "        2.26077375e-07, 2.18494847e-07, 2.16632102e-07, 2.13002920e-07,\n",
       "        1.98423379e-07, 1.86302429e-07, 2.14985647e-07, 1.81472132e-07,\n",
       "        2.29186242e-07, 2.22861956e-07, 1.94264530e-07, 2.42908698e-07,\n",
       "        1.94177048e-07, 2.25025929e-07, 1.96788235e-07, 2.10544428e-07,\n",
       "        1.94747656e-07, 2.22602580e-07, 2.07604955e-07, 2.18131277e-07,\n",
       "        2.11888675e-07, 2.30520584e-07, 1.97605928e-07, 2.10874092e-07,\n",
       "        2.02343656e-07, 2.14928235e-07, 2.22175998e-07, 2.14802228e-07,\n",
       "        2.15825537e-07, 2.08827913e-07, 2.24056834e-07, 2.18253945e-07,\n",
       "        2.14956827e-07, 2.14406043e-07, 2.01012341e-07, 2.12902847e-07,\n",
       "        2.14836007e-07, 2.13634024e-07, 2.20205536e-07, 2.11385753e-07,\n",
       "        2.19368289e-07, 2.20952458e-07, 2.12858936e-07, 2.13778122e-07,\n",
       "        2.13575902e-07, 2.07081428e-07, 2.04201228e-07, 2.12614935e-07,\n",
       "        2.06969361e-07, 2.13301817e-07, 2.13787928e-07, 2.25988188e-07,\n",
       "        2.30926673e-07, 2.24117883e-07, 2.08224563e-07, 2.17271094e-07,\n",
       "        2.21758768e-07, 2.11573322e-07, 2.12438323e-07, 2.20443638e-07,\n",
       "        2.13825530e-07, 2.17475815e-07, 2.18991971e-07, 2.15184201e-07,\n",
       "        2.17351584e-07, 2.17939132e-07, 2.23533860e-07, 2.15469981e-07,\n",
       "        2.22695377e-07, 2.07812377e-07, 2.19921048e-07, 2.17637790e-07,\n",
       "        2.23395432e-07, 2.21185616e-07, 2.26109648e-07, 2.15705128e-07,\n",
       "        2.14789566e-07, 2.12457252e-07, 2.19860681e-07, 2.17896911e-07,\n",
       "        2.17218940e-07, 2.12389580e-07, 2.20102152e-07, 2.19931849e-07,\n",
       "        2.26869417e-07, 2.16038870e-07, 2.16319251e-07, 2.25418617e-07,\n",
       "        2.30138042e-07, 2.19175035e-07, 2.28112810e-07, 2.15170786e-07,\n",
       "        2.32051718e-07, 2.13324995e-07, 2.24749812e-07, 2.22570691e-07,\n",
       "        2.25198448e-07, 2.20721205e-07, 2.10819593e-07, 2.24965660e-07,\n",
       "        2.28993045e-07, 2.18647429e-07, 2.22918004e-07, 2.24086804e-07,\n",
       "        2.20954774e-07, 2.25807668e-07, 2.18194486e-07, 2.20037620e-07,\n",
       "        2.18678906e-07, 2.19620759e-07, 2.23122555e-07, 2.28210396e-07,\n",
       "        2.20738002e-07, 2.20679851e-07, 2.16123340e-07, 2.23374627e-07,\n",
       "        2.17885827e-07, 2.20272085e-07, 2.16484864e-07, 2.21183655e-07,\n",
       "        2.31107023e-07, 2.19620219e-07, 2.17881990e-07, 2.22144777e-07,\n",
       "        2.17606129e-07, 2.20252204e-07, 2.22387982e-07, 2.17582908e-07,\n",
       "        2.21553023e-07, 2.25053412e-07, 2.33890063e-07, 2.15979270e-07,\n",
       "        2.18150973e-07, 2.19634046e-07, 2.22704927e-07, 2.20020056e-07,\n",
       "        2.25680225e-07, 2.18125578e-07, 2.25275429e-07, 2.14737753e-07,\n",
       "        2.15962629e-07, 2.19104336e-07, 2.22945147e-07, 2.17285418e-07,\n",
       "        2.19771394e-07, 2.21463949e-07, 2.22746209e-07, 2.27792299e-07]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = latent_dim\n",
    "\n",
    "batch_sizes = {\n",
    "    'Unlabeled': 512,\n",
    "    'Labeled': 512,\n",
    "    'Orthonorm': 512,\n",
    "    }\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "y_true = tf.placeholder(tf.float32, shape=(None, n_clusters), name='y_true')\n",
    "y_train_labeled_onehot = np.empty((0, len(np.unique(y_train))))\n",
    "inputs = {\n",
    "    'Unlabeled': Input(shape=input_shape,name='UnlabeledInput'),\n",
    "    'Labeled': Input(shape=input_shape,name='LabeledInput'),\n",
    "    'Orthonorm': Input(shape=input_shape,name='OrthonormInput'),\n",
    "    }\n",
    "spectral_net = SpectralNet(inputs, arch,\n",
    "            None, y_true, y_train_labeled_onehot,\n",
    "            n_clusters, 'knn', 2, 2, batch_sizes, None, x_train, len(x_train))\n",
    "\n",
    "spectral_net.train(\n",
    "        x_train, np.zeros_like(x_train[0:0]), x_test,\n",
    "        lr=1e-4, drop=0.1, patience=30, num_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range of y_pred values: 1.5903455018997192 - -1.2092550992965698\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd4lFX2wPHveaekFyAJJIQE6UVBEFFEReyAgggqNhQL6tpXdlddd9fVn23Xuu6uCi4WVFTETlEpiqIgoQpShNBCDaT3mfe9vz9mGIIiRAiZhJzP8+RxysvMuQbO3Dm3iTEGpZRSjYsV7gCUUkrVPU3+SinVCGnyV0qpRkiTv1JKNUKa/JVSqhHS5K+UUo2QJn+llGqENPkrpVQjpMlfKaUaIXe4A/g1SUlJpnXr1uEOQymlGpSFCxfuMsYkH+y6epv8W7duTVZWVrjDUEqpBkVENtbkOi37KKVUI6TJXymlGiFN/kop1Qhp8ldKqUZIk79SSjVCR3Xy91V8h+OU/+yxuThOZZgiUkqp+qHeTvU8XBX5D+IrH48LD5EtlmNZUZTnXo3f9xUuoolOWxXuEJVSKmyO2p6/sTKwMVRRRcm2ThTuGIzP9xU2hmKnmM3bB1NesTrcYSqlVFgctck/KuE6cA8CwBEHYy/GwVDpOJQah2JfFtm5Z7Jx919wHF+Yo1VKqbp11CZ/gMSUF7FICt0XhCLHodxYGATbwPaS11mQczLbi98LY6RKKVW3jurkX557NbA7dN9gSHJ5EYFKRygzLvzGRZVTwNrdf2XVrgfw2YXhC1gpperIUZv8K/L+gM/3VajUU2j7ARBxSLFclBkvlY6HEhOBY1xgNWFbyRS+3HQO3229Gr9dFeYWKKXUkVMryV9ExovIThFZ/ivPnyEihSKyJPjz19p43wPy9tmnxl+KsMO2AShzbOKtKirxYuOi1Hgo9RdSaRx8lJFfuZjpm/qwJu9VjDFHPFSllKprtdXzfxU4/yDXfG2MOT7481Atve+vioy9GE/cs1TQlAoEg1BphJ98hhJjcGFIkhIsHBDBD9gm8OHgNxZ+x2F5/rNM2XAheeU6K0gpdXSpleRvjJkD5NXGa9WmmLhhtEpbQkzEAGzjoty4qDJedjtRFDteHIEoKhEcREAEymwPJU4EPsdgG4sSewefbxnJ5OwBVPgKwt0kpZSqFXVZ8+8jIktFZJqIdK2rN7UsF5kp/6Nr+mqax92CwQO48FtpFJtmVOHBIKHrvVZgbMCHF59xYQAHQ4Wdxzsbzmd90ay6Cl0ppY6Yukr+i4BMY0x34Hngw/1dJCKjRSRLRLJyc3NrNQCXFUXrpvdxQssZtE78E7bxUWUMPtyA4BgDxuAWQ5xVAWKwceEYC2MEG3CMxeztf2XO9sdqNTallKprdZL8jTFFxpiS4O2pgEdEkvZz3VhjTC9jTK/k5IOeQnZIojytaJV4PSe1nILX1RwI1viNlwrjwjZgYXAZB5cYRMDnQIXjCXwQAEmRnSj157GmaJYOCCulGqQ6Sf4i0kJEJHi7d/B9dx/4Tx1Zke5k+md8Tqcm9yFE4mCwjZtSJ4ISJwJbXKFrq/BSabyUGi+9km4lM7YfH266hxnb/sHkTb+n6mebxymlVH1XKxu7ichE4AwgSURygL8BHgBjzIvAcOAWEfED5cAIU0+6zG0SryQjbjhf5lzDbl82BoODYIwQqPZbxFhV+GwLP27m7ZrEvNyJ+E0VNgafqWRH+RqySxdwevL1BD/jlFKqXpN6koN/oVevXqauD3DPKf6Sr3fch2McbMA2LgyCR2zEGAqcaGwsCA4Qx7lb0L/5nUzZ+jheK5q06O60izuF9rEn4rI8dRq7UkoBiMhCY0yvg1131K7wPRTpcWcwvPWXNPV2xzEuDIE9gLo3uZtoV5vgaoG9tlTk8/rGh3GMh6TIjiwrmMX7m5/m6dWj2FG+IVzNUEqpgzpq9/M/VB53BAMyx1LlL2PmtvvJjOtHZmw/fiiaDkRi8IeujXVVUmRHkecvI69gPh4rCr+posr28WXu2zSPaE/3xNNpEnFkBq+VUupQac//V3jd0Qxo9SxdEoeyouATCqu2YWNIiezARen/wMLCwhDnCqwfRgSf48MxQsuoTlTZNtN3vMVTa+5gTdGS0OphpZSqD7TnXwMnNruaOHcqPxZ9Ru9mI/ko5yG8VgpR7jh2Va4NXiUYoNzxsrFsK1X2WixLsB2b97e8QkZMe05PGkR69DHhbIpSSgGa/GtExKJz4rl0SjiHHwqm4bWiSYrsyKqib4E4YM+OoeAWm3K7Cgc3lmNIimhOvm8X/mLDgrxvODN5COenDsejA8JKqTDSss9vICJ0azKQq455nlJ/IRCNz/gxCGmR7bCw8Fp+vBI4GcxB2FW5kyhJYFfVToyBr3I/509LR7OrYmd4G6OUatQ0+R+CaHciV7R+jJ5NzsNjRdEqujNRrqaUORZ+x8Ijduh/rINQaAf2vHNLFJVOFX7j49GV97OjYmv4GqGUatQ0+R8il7g5P+1Gbmv/X85IvoIfixcDgm28RLjTsUQC20UHOUaodKoQBD+GdnGdSfQ048Mtk9haviV8DVFKNUqa/A9TvKcZbeO6cXmru0n2tiTRm0aRv4AEdwqOscAYwAT2CcLgx9Aqqi3Xtb6V1zaMZeq2T3hmzRPs1DKQUqoO6QrfWmSMYXHBXL7Onc760sAsIJdE4TflocVhtiOUGzexrjhK7RIsLC5qeQlTtn1Cn2Z9GdpyGNHu6PA1QinVoOkK3zAQEXo2OZXL0m8h1h2HW6Kpcqowxk2V2bs+OFIcSuwSHCMcn3gSU7Z9QoQrktm5XzJx00SWFvwQ5pYopY52mvyPgBbRLXno2JfoHN8NFy78GI6N78Xjx40n2h0PgAsHx1jMy1uAY4RCXzGtojLILt3If9e+QLGvOMytUEodzXSe/xFiicX1be6ioCqPmTuncUHqcF7bMJZ8XzmCi6SIZLZX7MYYodSuxGCRV1VEqb+EOzvcjgHuWnIvI1oN5+RmB/0Gp5RSv4n2/I+wRG9ThqVfSV7VLhblL0SwuKjlZRT6Sol2ReESGyGwPrjAV8CpSafT1NOMPy77K7mVu1lcsIxSfxml/rJwN0UpdRTRAd86tLZ4DTsqdjBx85tEuCIp9BWT5GnGbl8hVU7w7GDHwjYWLnE4uVkvrmt9FY+s/Bdey8ODXe/R8wKUUgekA771ULu4DpySdCqDUi+k0vbRKioDlxWJY6BbQhcEcIuDSxxsx8P6kp38ffkzbCzLYXDauUzKmcoDPzxNua8i3E1RSjVwmvzrmIgwIHUQf+z0J9rHdWRHxQ7u6nA7N7YZjVuiMQQ+APwYNpVvY13ZVvo06c260s28s3kKq4uzuXvJo3yxbW64m6KUasC07BNGfsfP5vIcmnkDNf5ifwknNunJcQldeGndRGwjIIIJ7BiNhYXfOGAsHAxXZw5heKtzw90MpVQ9omWfBsBtuTkmpjVldjmVdiUnNe3FDceMZMaOb3FbFl7LhBI/gM/Zm/gFITVSD4lRSh0anepZD7SITOE/PZ8i0orgkVX/YmNZDvd0uJlVxet5f8tnoetEwDGBxH9Ph1H0Te6xz+vYxsYlrroOXynVAGnyryei3VEAXNZqMMX+EtaVbOb9LZ+FSj0CWAJg8Eg0k7d8RUZ0GpmxqQC8u3kGC/NWcke7y2gZkxK2diilGgat+ddTj/74XxYX/Fitxu8Ekz/4HcFv3BgDA1qcQrOIeN7cNJ3W0alsKN3OyMyBXJTejyh3RHgboZSqczWt+Wvyr8eW5K/kiVXjKLMrEYQxHa6j0F/EuOz3sA34zd4ST0pEU7ZX5IERolzRuMTikeNupFNCZhhboJSqa5r8jxI7y3fz5JrxDEk7O1Tj31i6led/eoMCXxVbynMB8NmCADHuaEr85VhiYYzwbI/b6JrYOnwNUErVKZ3tc5RIiWrGP7r/YZ/B3cyYNHo368mW8lxc4sIYcFsGBErtcgQL2xjSo1JoFZPC0vx15JTmhrEVSqn6Rgd8G6DJObN4Zf0ntI5OJbt0G8YEBoNdYrANVDoQ647muRNuY13xVv645GUQi+GtTuWmdgPDHb5Sqh6olZ6/iIwXkZ0isvxXnhcR+ZeIrBWRZSLSszbet7FqG5NOl/hjyC7dBkaIdsVgO+CYwMFhHsuhxF/OPYvGMmbxOPzGwefYvLvpa7aU7WJreV64m6CUCrPaKvu8Cpx/gOcHAO2DP6OBF2rpfRul45t04K9dbiAjqgUx7hhK/OWIuLGNCyFQ+/dYDiuLtlLhBL4NuMTikW7X8OzqT7hu3r/4JOf7cDdDKRVGtZL8jTFzgAN1J4cAr5uAeUCiiKTWxns3VgneWMb1vo9BqX2IdEVgG0NGVAsmn/oIx8W3wTggEhjMtw30TTqWtzbM4dtdqyjxVzBlaxa2Y5NbURTmliilwqGuav4tgc3V7ucEH9tW/SIRGU3gmwEZGRl1FFrDdn3bCzinxYlM2DCD2zsMZV3xVpYXbsHBg4hBjIPBYsb2ZThGsAS6JKbzzx6jeGrlJ3yUs4DLMvtyRycdC1CqMalXs32MMWONMb2MMb2Sk3XfmprKiGnOn7teSbQrgidWvhtYGIbgETe3th+0z7WOEaKtaJ5fNZXJm+dj4/DWxrlsKcujzF8ZngYopepcXSX/LUCravfTg4+pWuS2XDzafRStYlJCNf5F+RsAQcRgiQPAvF0/8UHOnjUUFg93u4wVhTkM/eop1pfsDFf4Sqk6VFfJ/2NgZHDWz8lAoTFm28H+kPrt2sSm8tpJ9/DKSXfz7a7VfLtrFYLQJT6DR7tfhbvaQWCOgRvbnoUxhr8seYfMmCSaRyYAUF8X/ymlaket1PxFZCJwBpAkIjnA3wAPgDHmRWAqMBBYC5QBo2rjfdX+iQgZMSlc3bo/PxVvxW9snu5xPS+s+Qyfs+dsgEDyf/GnGQCkRzfj2V7XEO2OoNxfxV0L32Jweg8Gtewe3sYopY6IWkn+xpjLD/K8AW6tjfdSNZccGc/zJ4ym0vHz5oY5TN48P3gGsHBjuzMZt3YWTrCDv6EknylblnJBy+O5I+sNFu7ewOD0Hgd8faVUw1WvBnxV7XNbLmLcEQxI7UETbwyBGv8IMmJSMCawJgDAaxkeXf4xfT57mKzd63mw20WhXn9eZSnPrfwCv2OHrR1Kqdql2zs0Eq1ikpja/35WFW1ld2UJYxZO4PgmmTx1wtX8kL+JJ378mC1l+fiNhWOE6VtXEOOOokfTDG747hU2l+ZxVosu5FeVcVrz9uFujlLqMGnyb0QsseiSkE5+ZQmDW/Xi7k4DiXZH0KPpMSR6E9hcVgAExgS+2bmGOdt/wmu5AYfnT7qS8Wu/4fOtP3JGi07c0vF0uia2DG+DlFKHTMs+jVCTiFj+fOzQwOCuXcUdWW/wQ34OD3e/lO/Pf5DTUzpiWYEVwpWOTaUDL66ew+dbfyQ5Mo4vt6/mxm/foFTXBSjVYGnyb+Q84iIlMp6Hjx/GoJbd8brc3H/shUS7IhABwQCGRXmbiHJ5ya0oAeD+4wYQ447A59gsycsJbyOUUr+ZJv9Gzm25eOT44fsM7v5u/gR8tsMLJ42kU0KL4AeAUGb7MECHuBacndYZn2Pz++/fY+TXr/Lg4k/x6YCwUg2G1vzVPpblb2ZrWQHPnng5kzcuYlXhDmLdURRXK/GsLNjO0FljiXK5WVm4nZTIOD7YuIx+LTpQbvsYmN41jC1QStWE9vzVPs5o0YlpZ93N9vKiUI2/xF+JAK2iEwGD5YINJbmsLNyOYJFfUc5DPQfxf0un85dFn3DD3Dcp81eFuylKqQPQ5K9+oUlEDEMzevBAt0EUVFUA8HjPi/n0rNu5vt2pQGBGEBhs4+CyLP6ycAq5ZUX4jWFzaQHTc1Yy5vsPdG2AUvWUln3UflliMeKY3pyS3I61xTs5M7UTPsdmfXEejgPxnigKqyoQoNTvAyOAIS0yltHt+3L/wk9wjGHx7hze6DeS1OiEcDdJKVWN9vzVAWXENuXM1E4AvLZ2HjO2rSIlMp4Kv83DPS7AbVmhGUEgbCsrDiV+r+XC59g6EKxUPaTJX9XYyLYn8buO/Sj2VfFQz0G8uHoubly4LQuCZaA9HwMAbnEx/tQryYhtCsCOsiKeWDoTv+OEqQVKqT00+asa87rc3N7lDGaedwc/FeWSV1mKESE9pin3dzt3z0BASImvikGfjWXxrhx2lBUx4LOXGLf6O0744ClW5+u5AUqFk9TXfdt79eplsrKyDn6hCgvbOHy6eTmv/jSPq9r05s+LPsUxBrdYwZPEgtfZgLGwRDDiYAy4sfAb6JOSyRtnXhm+Rih1FBKRhcaYXge7Tnv+6pC4xGJIRjcmn3kj3+/aGKrxJ0XGMO3cW+iUkBK4zgVgcAwYB1xY+IMdjs0lBfxx3qesyt+hh8coVcd0to86LJYIj/cazCkpx/Dmuiz+2fsiMmOb8uHZoxm/5jue/GEWthgwBrCwDRgjtIiKo118Eu9lLyO3vITUmHhu7dqXljE6K0ipuqBlH1VrjDHBw2II1fiLfBUYI8FR4MAXTeMEZgYZA31bZPLtjo20jI7HAGNPv4ROTVKwfjZ+oJSqGS37qDon1RL248tmUuSrxBjBjUVgOlBwLpBIcF4QzN2+kaTIGLaUFTEgoxOXffEGjyycwUodEFbqiNLkr46IJ3sP4byWnYiyPMEav9AyKp5ETyRI8BuCBCYI7aoopWNCChN/WkpiRBRTN67mlq8m88Ly77B1WqhSR4Qmf3VEuCyL//QdzreD7yQpIpb06ATaJ6SQX1lJr6atAl8Aql2/qmAnZf4qCioqKPVXEuX28uTiOZz36f+YtHaZDggrVcu05q+OOGMMW8uKuO7Ld0iJimXu9g20jI5nS1kRHrGoCvbujQEcwcLCwZAYEUmRrxLLQFpMAtMvvJ5ojye8jVGqntOav6o3RISWMQl8fP51nJPegfYJSWwpK+L6Tr3xWB5iPd7gdQAGh8CHQUFFBcYGvzHsLCth6LQJjF3+vX4LUKoW6FRPVWciXG5GduhF/9S2zNy6lqeXfk2TiCj8tgMOIEIJVRib4OygwMCwRyxSouPILtrNowtns7O8hMs7dKdtQrPwNkipBkx7/qrOtYprwrUdT+TvJ55L69gmlNlVpMc2oazKT6TlrjYYEJgZ5DOGraVF+GyHk5q3YvyPC3hq8df4HJvCyopwNkWpBkuTvwqbocccy7OnDuH2Y/vyU8Eu4rwRVNoOlpF9R4MBv+PgERfzt2/mhJR0HulzLnd8+QmXTZvIgh2bw9MApRowTf4qrJpFRnNDl5N459yrAruDBitAkZab5OjYfa71OX4w0L1ZKvd98xnTNq4hKSqaS6ZOZN72TTg6FqBUjdVK8heR80VktYisFZF79/P8tSKSKyJLgj831Mb7qqPHCSkt+WboLQzI7Ei0y0NKdBwFleVgIN7tZU8JCIFxyxcwbcNPdEpM4putG7m8QzfaJTRj6CdvMCdnfbibolSDcNjJX0RcwH+AAUAX4HIR6bKfS98xxhwf/Hn5cN9XHX0i3R7+0+8i5g77HclR0aEaf4mviuOatKB5dOw+5aCVebtI9ETSI6klV057l5V5uZT4Krlm+nt8vWVD2NqhVENQGz3/3sBaY0y2MaYKeBsYUguvqxqpJpFRTB5wNWP7D2VXeSknpKTz+nmX0qNpGjjgsvaOCeRXVPCHr6exJn8XT556Pk9mfcOXOeu5bdYnPL/oOz1FTKlfURvJvyVQfcQtJ/jYzw0TkWUi8p6ItNrfC4nIaBHJEpGs3NzcWghNNWTnZnRg4nmX88rZw3kiaw7TN/3EqWmtcQyckX4Mbmvv1wDHMdw+ewrrCvOJcrkpqKhg+oY1DJz8GjvLSsLYCqXqp7oa8P0EaG2M6QZ8Aby2v4uMMWONMb2MMb2Sk5PrKDRVn6VExxLrieDqTj24omP3UI3/qdMGkhYTv7cMJHu/DZT7/RzbLIVVebkkRkQSE1xEppTaqzaS/xagek8+PfhYiDFmtzGmMnj3ZeCEWnhf1Yh0bdac/+tzLs+ePogxPU/nymnvsqOslH+fcSHJUTG/uH7F7p20iktg/PnDQsnfdhzeWfWDrhBWitpJ/guA9iJyjIh4gRHAx9UvEJHUancHAytr4X1VI2OJcFHbrsR4PLSKS+DZfgN5ZtFccsvLiHS5gT2HxgQWCG8oKODcd15hbs5GbMfhmqmT+dOXn3HJRxNZtH1rWNuiVLjVysZuIjIQeBZwAeONMY+IyENAljHmYxF5jEDS9wN5wC3GmFUHek3d2E0dzNqC3Qz84DUsJFTq+TFvJ07wr7QYAosGEDo1TWJV3i4iXS4qbJtot5vvrr6ZhIjIMLZAqdpX043ddFdP1aBtKy3m+UXfsSx3OyvzdtIzJY2H+57NY/Pn8O22jdiOwbED5wl4LAtfcAfRh049i5HH9ghv8EodAbqrp2oUUmPieOTUc3jyjAGc17o9rw4YTqdmKbw6YBjvDBpB08io0LU+xwkuGovgonadQo8/NvcrTn9jHGVVVeFoglJhoT1/dVTaU+P/JmdjqNQDhE6StBDeHDycLzdu4KWlCwDIiEvg5YFD6dAsKXyBK3WYatrz1y2d1VHptRWLf5H44yMiKKoMTDpzjOHyjyaFro/zeNlVVkZxVeD54qpK4rwRdR+4UnVEyz7qqDTq2J6M6Hwce77XPnTqWSy+5lbOzDyG0DnzQuhc+Uq/zSsXXswJqS35YPWP9J/wPz5f95NOC1VHLS37qKPaj7t2siZvFxd12Lvd1N1fTOGDn6rNNg6Wgk5v1ZohHTrzh5nT6dQsmbW7dzPmlFMZ3fPEug9cqUOkA75KAV2SUvZJ/I/N/SqU+OPc3kDiD34DmLN5A2NmTKdpZBSrd+XSMSmJy7och99x+Oe3X1OkB8eoo4gmf9WoLM3dBgQSv20Mk4aOoFVcwj7X7C4vxzEwrGMXoj0erv5wEv9d+D09x/6X2dnZWgpSRwUt+6hGZ8aGtfzr+3n89bT+9EptyQerVvD7GdNwW67AecJ7vg0YcIlgYwK3CawZS49LYObIUXhcrvA2RKn90Nk+Sv2Ks1u346zMtogIn2ev5Z4Z0+ncLIW1u3fTsWkztpWVUFReCUIo8VsEFwsbIbe0lFnZ2dgYBrbvEObWKHVoNPmrRkmCU356paYxtGMXPlmzio5JSbxx0SWUVFVx/luvUeLbu+jLcUAQ3Jbwj7PP449ffE6z6CgSIiKIi4igW/MW4WqKUodEk79q1JpGRfPUOQPol9mafhnHEOP1cvPUjwKJf09FVAALjG3w2zDms+k0j4vlzpNPYdQH7+N3DH/vfyaXHXccXi0FqQZCB3yVAgZ36ExCZCQz169j3pacUI1fIFDvCX4AgMHnOOwqKWXM9Kn4HYNLhNW5uVw4YQJZW7Yc4F2Uqj80+StVzXlt23NNt+OJ9XhCNf5Il5sTW1Q7nM5Ahd/GdgKfCZd1PZaJP/zA+vx8nvzmG50NpBoETf5K/cyD/c5i8U23cWxycyLdbv5x9nmszt1Nemw8ybExwb2iA4yBiT/8gEuE1omJ/PvCC0PjCcYYHP0gUPWUJn+l9sNtWXx8+VUsuPFmvtm8kcTISMb0PY38snJg75GRe3aKsB3DMYlN9x4mYwxPfTOXP3/+BXllZWFpg1IHovP8lToIn22zq6yMIW+9ya6yMlwiDO/chXdWrAgl/z1bRHgsizcvu4TZ2et5Yf739ExLZUNePpOvuoKMxMQwtkI1FjrPX6la4nG5SI2LY9zgIdw1bSqnZbbmzaVLcYvQPDaWcp+P/IrA1g8+x+HSie8A0DMtlUVbtnF+h/akxsWFswlK/YImf6VqqHtqKrOvu54FOTlMX7OGJlFRvHnppSRFR/PxypX8ZeZMSiuqQjNE9yT+Zy8YqKuBVb2jNX+lfqMT09OZfu21ocQPcGGnTlzcuQs/L6Je0LEj177zPlNXrg49tjG/gCvefJfZa7PrMGql9qU9f6UOQdOoqH3uPz33W15fvCRU6kmLj2NrcTF3TZmCOPD9phwqfH56pqdx5VuT2F1axpjc6cz53Q1EezyhGUJK1RXt+StVC1rGx9GnVatQqWfWDddx68knEeXx4HG7EIE/Tfmcc158ldziUixLeHbwQLYWFnHB/yYweekKXR+g6pTO9lGqluwuLePlBVn8/rS+oRr/1qJi3lqylFbx8TwwbWZoy4hYr4dXLh/Gje9+SEllJZZYpCfE8fENVxPh1i/k6tDVdLaPJn+ljrA9Nf6dJaXBrUH3EoLbRhuDx2Xx8qUXkVdewaAuHcMSq2r49CQvpeqBPYl/d2kZHpfF7884JXSGcPUFYh6Xxb8vvpA/T5nB36fPoqhCTw1TR5Ymf6WOIJ9tU+n3Y1nCS8OGcHb7tkR7vfteJHBOh3b8ZeoMiior+d+IocRHRgKwYtsO3SJCHRGa/JU6gtolNWPWzdcz4fLhtIiL5Yo3JlHp8+EW2Wda6NQf17CzpJRjm6fQuUUKADNWr+Oy8W/z8rda/lS1r1aSv4icLyKrRWStiNy7n+cjROSd4PPzRaR1bbyvUg1BfGQEJ6S3JMbrDez3b8A2Bq/L4oFz+u1z7bfrN3PP+1P5bOVP3PXep3RJTeHyE7qFKXJ1NDvs5C8iLuA/wACgC3C5iHT52WXXA/nGmHbAM8ATh/u+SjU0aQnxzLplFOd2bIfX5eLfF1/Iq/MXE+f10i2tBZYlYMG0lT9xx3uf0qF5Ev+74mLiIiPCHbo6CtVGz783sNYYk22MqQLeBob87JohwGvB2+8BZ4mualGNUITHw3MXX8D8u24ma/MWiiorefWKYbw36nK+u/Mmuqe1AAnMCG0SHUWU18OHS34kO3f3Pq/zTtYythUWh6cR6qhQGxOKWwKbq93PAU76tWuMMX4RKQSaAbuqXyQio4HRABkZGbUQmlL1U0yEl9+f0ZdLjz+OzKaB3T4Xbt7Kj1t30DklibM7tuPfc+Zx69sfMWfNBrxuFx/cdCVtkpvxwlfzeW72t6QnxjPjruvD3BLVUNWr1SRJI7QqAAAZlklEQVTGmLHAWAjM8w9zOEodUS7LCiX+bYXF3DV5Cl1Tm4dKPbERXh7/Yg6nts1k7rqNDH3pTS4+visTs5bhtiyeHj4wzC1QDVltJP8tQKtq99ODj+3vmhwRcQMJwG6UUgCkJsTxzMUDObl1q1CNf9TJJ9A8Lpb+HdowYd4Snp75DROzlgHw+EXn0iW1+T6vsWp7Lh1SkgJjB0odRG3U/BcA7UXkGBHxAiOAj392zcfANcHbw4FZpr4uLVYqTM7p1O4Xg7sDu3YkyuPBdqotDTbwwIczuGfSVJZu2gbAl6uzufSlifx71res2pZbl2GrBqpWtncQkYHAs4ALGG+MeUREHgKyjDEfi0gkMAHoAeQBI4wxB9zPVrd3UCpgT43fbVkM6d6ZyYtX4BbB9hssERIjIyiqqqJtclOq/Da7S8poHhfD+7dehVvPEWh06vQkL2PMVGDqzx77a7XbFcAltfFeSjUmO4pK+Fcw8b913aV0S08ls2kTnp75DbFRXkrLq8grq0AEKn1+thQU4fM7FJdX8ua8JVzT94RwN0HVU/VqwFcpta/m8bE8MfR8WjdLpFt6KgCjTzuRxOhI/H6Hhz+dFZoaumF3AZjAnkHndW3PyFN6hjV2Vb9p8leqnhvcvfMvHkuJjeGOtz+lY4skNuzKp9Jvh547q0tbnh4xSA+IUQeke/so1cBsKyzmznc+pU1SE6r8dmDjN0PorIC5P21ke0Exf3h7KnklZaE/t6OwhD++PY3iisrwBK7qFe35K9XApCbE8fjF5zH9hzXMXp2Nz+8gQKfUZNbs2EW5z8+g517F+A3LNm2jT9sMrj29F7977UN2lZRxbFZzdhWXcts5ffDqwTGNlv7mlWqABhzbkZPbZJA97l3W5eZxXtf2PD1iEDsKSxj+wpvklZZzee/uvPvdUiYtWM57C5YT6XVzy1kn89TUrzEYCsrKeXDoOYigJaJGSE/yUqoBM8Ywe1U2/Tu1CSVw23aYs2Y9/Tu35YOFK3hg0ucAWCIYYxAgOT6WV0YP5z9fzCPa6+Gu8/uSGBN1gHdSDUWdTvVUSoWHiHBm57b7POZyWfTv3JYdhSWMm/196HHHCYwNGOCGfifyny/mMWXxKiLcLj5ftoZxNw6ja3pzVOOgA75KHYV2FJYwatwkdpWUcc+A07BEAnNAg9WdRz6aHUr8tuPgtwM/qvHQ5K/UUWhHUQkVPj839z+J5z6biwgkxkThdllQ7XOgym/jEmHcjcPonhlYR7Atv4jJ838Ia/zqyNPkr9RRqFurFkz/wyh2l5QCkBQbw1u3XMZZXdrCz4b5qnwOc1dtAAKJf9QLk3jq06/ZXVyGOnppzV+po5TX7WbMwNPpkZlG+xbJ/OeL7/hs2U9EuF34bQc7OPiLBf/9Yh7bCopZsG4zRWWVjLvpYprFRYe7CeoI0p6/UkcxEeHsY9uTmZRIZrNE4iMjsB2HSI+bN393Gf27tglcaMEHC1awJa+IcTddTJf05vx8JmB9nRmoDo0mf6UaiVvP7cOzIy+ka8vmjLtxGMe3TuP5a4bw0PCz8Vh7U8GXK7J5eNJM/jV1bijh+22He9+YxviZC8IVvqplOs9fqUbGGBNaE7Cnxl9YWsHYm4Yxad4yPpi/gq4tU/hx8046pCUxpFcXlm/ewbTFq7l94Clkb8+jd/tWXHRSV10cVg/pPH+l1H5VT9ifLlpFUVklL988jK6tWoTm+X+5fB3ndu/A50vX8M+P5wAwsl9PlmRv5ZuVG/h88Wpen72QsbcMIzkxNiztUIdHe/5KNWLGGLblF5PWND70mOMYdhQWkxQfwwlj/hW8MPAjBiyXBBaMARFuF8+NHkKfjplhiF7tT017/lrzV6oRE5F9Ej+AZQnJ8bE88NZn1S4M/McAjr23wxgT6eV3//2Ar5ZnU1ZZVQcRq9qiyV8ptQ/bcfjzW9OZtihQ4z+1Y2Yg61cv7xtIiIogr7icPp0y2Zybz7BHXmd7fnG4wla/kSZ/pdQ+LBGaJ8Ry+8BTWJK9lbmrNmLtZ1y3sKySHm3SOKVjBk++P4eO6cmhtQH1tZys9tIBX6XUPkSE3w8+nfyScl6btRBLAjV+gUDvv1peX7xuK0vWbSUjKZFHrxmAx+2iuLySK594i2F9j+Oqs3risrSPWR/pb0UptV9NYqP49IFR9G6fHqr4NI0NbPsc4Qn2G4PnB2/aWcAVj79JfnEZw//vdTbnFvDm7EX8bcLnocFhVb9o8ldK/arEmChe+t1wHhs5gA5pSeQVl9O3c2tuH9QHDLiCu4UaCzbsLODMe19iZ0EJzeKiyS0sJT0pAWt/NSMVdlr2UUod1IATOnFej468+81SPG6LhyfOpP9xbXjsmoGMn7GASV8vpaCkAmMClaHdxWXcNPBkbh7UJ9yhq1+hPX+lVI1YljDi9OPp06k1l57WnX9edwFRER5GnnkCrv2kkuvP6x2GKFVNafJXSv0maU3juf/SM0ODu8P/73XyistIio3eZzboJY+8js9vhy1OdWCa/JVSh8y2HSqqfDSLjw6VeqY8dB1et4uNOwv40/gpOI7ho2+WM+GzrH2mgE6cuZh3Zy8NY/SN22HV/EWkKfAO0BrYAFxqjMnfz3U2sOdooE3GmMGH875KqfohMTaKzx65kelZq9mRX8xNwRr/7H/czEffrsA2BoPh7VlLWJOTyw/Z27jnsn7MXLSWp979Cgw0jYuie7s03SOojh3W3j4i8g8gzxjzuIjcCzQxxvxpP9eVGGN+029W9/ZR6uhRXFbJxX95lbyiUkLnSBroe1xrjG3IWr2Zl8ZcQrd2aeEOtcGrq719hgCvBW+/Blx0mK+nlDoKxUVH8P7D18Keg+SBjulJGNvw3YoNWCJ4Pa5whtjoHO5Uz+bGmG3B29uB5r9yXaSIZAF+4HFjzIf7u0hERgOjATIyMg4zNKVUffLJtyv2ub96cy5CLhEeN/+79zI6Zf5a+lBHwkGTv4jMAFrs56k/V79jjDEi8ms1pExjzBYRaQPMEpEfjDHrfn6RMWYsMBYCZZ+DRq+UahDemrEoVOM/uWsG3/+4CUfAGLjq3BM08YfBQZO/MebsX3tORHaISKoxZpuIpAI7f+U1tgT/my0iXwI9gF8kf6XU0cd2HKZ/v2qfGr/jBFeDCfxvynzatGzGeb07UVBSTmJwC4k99veYOnyHW/P/GLgmePsa4KOfXyAiTUQkIng7CegL/HiY76uUaiBclsXYMZfwwMizSYiO5LsVG4j0uBk35lKuOrsHlggPjJ3KR1//wLA//I/fPT6JwpJyABatymHIPS8z5tkPKSvX8wJq0+Em/8eBc0TkJ+Ds4H1EpJeIvBy8pjOQJSJLgdkEav6a/JVqRCK9HoaedhwjzjyejOaJ/O/ey+jZMZ27L+vPv38/jFbNm9A5sznNm8WTtXIzF949jq8XZ3Pnk5Px+Wy+XpzNn57/ONzNOKroMY5KqTpV/QD5nz9W5fNz8R/GszO/BAhMDsJAlNfDC/ddwszv1+CyLK676GQivLo12f7oMY5KqXrp54m/+mNej5u/3HBe6HFjwNjwz7sGM/P7NUz4NItJXyzh/8Z9hl+3jjgsmvyVUvXGolU5jHn2Q1yuaqlJ4NbHJjPh0yxiIj1YIpx9ckeuuPc1Zs5bhd92whdwA6bJXylVL6zL2cWdT07GdgyO7RDldZMQGxnIUsEvC2UVPgb368ozr88mv7CMsZO+5d5nPuLbJevDGntDpMlfKVUvZKY2pVeXDGzHIcrr4cX7LuWCU7qAw97D4x3DW58uJHdXMU3ioti6s4DvFmVzzxPv89K73+ipYb+BDvgqpeqVmd+vIS0pPlTjj4nyYts2TeKj2ZZbhDiAATEg1t4jhbu2a0FSQiz333we8bGR4WxCWOmAr1KqQTqrdwc6HdMcv+0QHx2BJcJDtw7COIEZQSa4OIw9id9A5zbNWbFmO7vySrj41nFMmrYovI1oALTnr5Sql4wxzF2SjRjhn6/NpLSskiZxUeTsLMCx91aC8BvEQGZ6EzZtK8Q4hp5d0yksKuPBOwfRNjMlnM2oc9rzV0o1aCLCqT3a0uvYDI5rn0pSYgzbcgsRp1riN4ALjMDGnHyM7dC9Yxo/rtlG9qbdjLzndb74eiX1tZMbTpr8lVL1WoTXzcO3XcC1F52Ex+1mz5hu5zbNg3UfCX0AYGDZqi1UVvlDf376Vyu45OZx5BWUhSP8ekuTv1KqQTivbxee+P0QYqMj6NymOSvX7qBr2xaIIZD5TXBFcDUnd2/N/EUb2J5bxNNjZ4Ql7vpKk79SqsE48bhMpr10CyMH96ZHp5asXLcDHDi+fRoe18/SmW2Yv3A9GEN6aiL3jD6Ltet38vqk77QMxOEf5qKUUnXK7XZxxkkd6N4pnevve4MWzeJZtW47dnCl754ZQGIFtobwuiwevGsQu/NLufOv7xAZ4aFvr3YkJESR1LTxnhusPX+lVIPUJCGat5+7jv592u9T4+99bCahY6Us8Fc5jL7nDW76wxtERnj42+8v4N7/e59Lr3+JOd+tCU/w9YBO9VRKNXgffbGE/06Yw7Ht05i/eAMA8XFeisuqcCoNVvDsmLQW8dgO7MgtAgNej4uzT+vEvXcPDGv8tUmneiqlGo0h5xzP9Ndup2liDADpqYm8+dz1jH/iajyevWlu6/YiduwMJH6XJfiqbKbNXM5rE+eGK/Sw0Z6/UuqosvTHzWSkNd2nxj9iSC+eHzsbqL5GwIT2hmjTOpmuHdP4/W3nYlm/3HK6IdGev1KqUerepRVNEmPIWroxVON/98OF1bJ+gPEbsA1tWieTvT6X3N3FvP3efDbn7A5P4HVMe/5KqaNWUXE59/xtEqvX7giVemzbAWOQamfBnHxSW9JTmzD5wyy8Xjcfv3sHkZGe8AV+GLTnr5Rq9OLjorhq+MlYluCyBMc2wZlAwQ3iAIxh5/YCJn8Y6Gwef1w6Q4Y/x9RpS8MVdp3Q5K+UOqr1O6UD779yM1GRnkCdH2jbOjm0HFhEWL8xUOrpfUJrFny/nqpKP089M41Vq7aFLe4jTZO/Uuqo17RJLO+9ejOnndI+VOPvc2IbLhjQbZ/rvp+XDQSHBwy88soc5s49OtcCaPJXSjUK0VERPHz/RQwe0J0+J7YhPbUJU6YtA8ASAt8K3BI4NwDo0T2DrAXZrFu3E4CyssrwBX8EaPJXSjUaIsLQC3py5y3nhGr8vU9oHZj5s2e7ULdgbMPiRRu5emRfrr66L5Penc/VV7zAlE8WhzH62qV7+yilGp3UFglcNaIPa9ftYP68dQBYSOAM4OB5AcYYVi/fwqR35/PSC7MQ4Jknp+Kr8jPk4l7Iz7cQbWC056+UapRuuPZ0hgzqwZ5TIQXo1T0T157Z7yLMX7iel/47ExwH4xhaNE/g3898zqgRL1BZ6Qtf8LVAk79SqtHqc3I7Hn7wYpKTYunRPSNU6rnrngF7V/o6IDakpMSxfWshYgxbNucx+uqx2H4nvA04DIeV/EXkEhFZISKOiPzqogIROV9EVovIWhG593DeUymlalPfvh147ZWbiIzwcPXIvlxzzWlUlFbi+J3ArB8r8K0gd2sRUm1LiGO7pzP2+c9ZHxwQbmgOa4WviHQGHOAlYIwx5hdLckXEBawBzgFygAXA5caYHw/02rrCVylVl2zbwbKEqVOW8PST0wJ1f8eQ2CSagrxSLAewA/ny3Au7UVZcydzZq3C5LC6/ti8jR/cPa/x71HSF72EN+BpjVgbf7ECX9QbWGmOyg9e+DQwBDpj8lVKqLrmCJ4H1PKE1CfFRFBaUkdoige1bCwO9fbN3RtDMT5bhODYYwTYOb778Nf4qm2tu7o/L7QpjK2quLmr+LYHN1e7nBB/7BREZLSJZIpKVm5tbB6EppdS+UlOb8OobN3HW2V1DNX4rdFB8oKNrOwZjJLBK2BiMYzPtgywu7vcYq37MCWv8NXXQ5C8iM0Rk+X5+htR2MMaYscaYXsaYXsnJybX98kopVSPx8dHc95chtO/QPFTjP3fQcZxyWvvQGIAEEz+2TUJCFEUF5VSUV3HnFWP5sgHsC3TQso8x5uzDfI8tQKtq99ODjymlVL0lIrww/gaefPQTLIHiwnK++2pNoPRTvdQtQlFeaeAxO7A6+Om/fYAx0H9g97DFfzB1UfZZALQXkWNExAuMAD6ug/dVSqnDNub+C7ny2tNYvCAbHLNPjx8Ay8I4Bnx2cDaQwUJ48v73GH3hc9TXbfMPd6rnUBHJAfoAU0Tks+DjaSIyFcAY4wduAz4DVgLvGmNWHF7YSilVd5qnJvLMi9cSFRMRPAHMISExCpzgPH8RxO+Az8bjtaiq9GFX2Wxau51LTnqI8rKK8DZgP/QwF6WUqqHi4gr+9egnLFmQTVF+WWCw1w58GFh+BzFggofF4HYF1gk4DpYIfx97Lb1O73TEY9TDXJRSqpbFxUVy/6PD6du/c7D0Y7AI7AuEJRhjEBOo+4vjBL4ZOAbHdvjLdS9z41mPYdv2wd6mTmjyV0qp30BEuOvPg7n+jnNwu11gDJGRHiyXhbEssIJp1TEYfzDROw7YDjlrdzC4/Ri+/Cj8VQ1N/kopdQguvfY0Jky/h47HtqSq0ofjcxBjMJZAcMGYWFZgYLjKt/dbgM/hidsmcP/l/6akuDRs8WvyV0qpQ9Q0OY7HXx4VOiJyT7nH2NU2fNszLdR2gruDBp5b/NUqLunwR0b1foDtG3fVeeya/JVS6jBERUfy9jf3k9wiIdS73zPQCwTKQF4PAKaiEsorcMrLg4PFNtvW7uDa4+/lpfvfrNO4NfkrpdRh8ng8TJh9L73P7Bx4YM9gb1UVVFYFev9uF7hdgXn/Pj9OUTH47dCHwOSnpzI87cY6i1mTv1JK1ZK/v3At9z17RaDSE/wWgDGBDwDbQbxecLsD6wK83lDiN1VVYAyFOwopyC2ok1g1+SulVC06fdDxTF72COkdmu/7hG2DbSNu1747IQcTv/H7GXHvRSQmJ9ZJnJr8lVKqlkVFRzDui/u474VriI6NCCT+YIKnsgoInBFsjIGIwKrhEfdexPWPXFFnMWryV0qpI+T0C3ry3o9PcMsjl+Byyz41flNRESj3iCBRUUx6dmqdxqbJXymljiARYfCofnyy6XmS05vuU+M3lZVYYsDvx/E7DGk6qs7i0uSvlFJ1QESYsOwJXpz3UGC+f7DGPy1/PKMeGgaOoaywtM4GfA/rGEellFK/zTFdWvHMVw+yZNZyrvzzMABG3DOEjI5p7Ny4q84GfHVXT6WUOororp5KKaV+lSZ/pZRqhDT5K6VUI6TJXymlGiFN/kop1Qhp8ldKqUao3k71FJFcYGOYw0gC6v6UhdqlbagfGnobGnr80HjakGmMST7YC9Xb5F8fiEhWTebL1mfahvqhobehoccP2oaf07KPUko1Qpr8lVKqEdLkf2Bjwx1ALdA21A8NvQ0NPX7QNuxDa/5KKdUIac9fKaUaIU3+gIicLyKrRWStiNy7n+efEZElwZ81IlI3G27/BjVoQ4aIzBaRxSKyTEQGhiPOA6lBGzJFZGYw/i9FJD0ccf4aERkvIjtFZPmvPC8i8q9g+5aJSM+6jvFgatCGTiLynYhUisiYuo7vYGoQ/5XB//c/iMi3ItK9rmM8mBq0YUiwDUtEJEtETj2kN9pzjmRj/QFcwDqgDeAFlgJdDnD97cD4cMf9W9tAoFZ4S/B2F2BDuOM+hDZMAq4J3j4TmBDuuH8W3+lAT2D5rzw/EJgGCHAyMD/cMR9CG1KAE4FHgDHhjvcQ4j8FaBK8PaCB/g5i2Vuy7wasOpT30Z4/9AbWGmOyjTFVwNvAkANcfzkwsU4iq7matMEA8cHbCcDWOoyvJmrShi7ArODt2ft5PqyMMXOAvANcMgR43QTMAxJFJLVuoquZg7XBGLPTGLMA8NVdVDVXg/i/NcbkB+/OA+rVt0eoURtKTDDzAzEE/m3/Zpr8oSWwudr9nOBjvyAimcAx7E1A9UVN2vAgcJWI5ABTCXyDqU9q0oalwMXB20OBOBFpVgex1ZYa/11TdeJ6At/EGhwRGSoiq4ApwHWH8hqa/H+bEcB7xhg73IEcgsuBV40x6QTKDxNEpKH9/scA/URkMdAP2AI0xN+FCjMR6U8g+f8p3LEcCmPMB8aYTsBFwMOH8hp6hm8ggbSqdj89+Nj+jABuPeIR/XY1acP1wPkAxpjvRCSSwD4hO+skwoM7aBuMMVsJ9vxFJBYYZoypd4PvB/Bb/q6pI0REugEvAwOMMbvDHc/hMMbMEZE2IpJkjPlN+xY1tJ7fkbAAaC8ix4iIl0CC//jnF4lIJ6AJ8F0dx1cTNWnDJuAsABHpDEQCuXUa5YEdtA0iklTt28p9wPg6jvFwfQyMDM76ORkoNMZsC3dQjYmIZADvA1cbY9aEO55DISLtRESCt3sCEcBv/hBr9D1/Y4xfRG4DPiMw42S8MWaFiDwEZBlj9iSgEcDb1QZa6o0atuEeYJyI3E1ggOja+tSWGrbhDOAxETHAHOrZtzARmUggxqTg2MrfAA+AMeZFAmMtA4G1QBkwKjyR/rqDtUFEWgBZBCYPOCJyF4FZWUVhCnkfNfgd/BVoBvw3mD/9pp5t9laDNgwj0InwAeXAZYfyb1lX+CqlVCOkZR+llGqENPkrpVQjpMlfKaUaIU3+SinVCGnyV0qpRkiTv1JKNUKa/JVSqhHS5K+UUo3Q/wP78sa0XsV1OAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = spectral_net.predict(x_test)\n",
    "plot(y_pred, y_test)\n",
    "print('range of y_pred values: {} - {}'.format(np.max(y_pred), np.min(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7d940326a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # now plot all the dimensions of spectralnet\n",
    "y_pred_embedded = TSNE().fit_transform(y_pred)\n",
    "plt.scatter(y_pred_embedded[:,0], y_pred_embedded[:,1], c=y_test, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0] [G loss: 0] [VAE loss: 5.669891357421875]\n",
      "1 [D loss: 0] [G loss: 0] [VAE loss: 3.557072401046753]\n",
      "2 [D loss: 0] [G loss: 0] [VAE loss: 2.364872932434082]\n",
      "3 [D loss: 0] [G loss: 0] [VAE loss: 2.0501158237457275]\n",
      "4 [D loss: 0] [G loss: 0] [VAE loss: 1.9000051021575928]\n",
      "5 [D loss: 0] [G loss: 0] [VAE loss: 1.7930970191955566]\n",
      "6 [D loss: 0] [G loss: 0] [VAE loss: 1.7726120948791504]\n",
      "7 [D loss: 0] [G loss: 0] [VAE loss: 1.7514935731887817]\n",
      "8 [D loss: 0] [G loss: 0] [VAE loss: 1.914421558380127]\n",
      "9 [D loss: 0] [G loss: 0] [VAE loss: 1.8454270362854004]\n",
      "10 [D loss: 0] [G loss: 0] [VAE loss: 1.849757432937622]\n",
      "11 [D loss: 0] [G loss: 0] [VAE loss: 1.7549457550048828]\n",
      "12 [D loss: 0] [G loss: 0] [VAE loss: 1.9471497535705566]\n",
      "13 [D loss: 0] [G loss: 0] [VAE loss: 1.7906129360198975]\n",
      "14 [D loss: 0] [G loss: 0] [VAE loss: 1.763059139251709]\n",
      "15 [D loss: 0] [G loss: 0] [VAE loss: 1.795743703842163]\n",
      "16 [D loss: 0] [G loss: 0] [VAE loss: 1.8531193733215332]\n",
      "17 [D loss: 0] [G loss: 0] [VAE loss: 1.7016963958740234]\n",
      "18 [D loss: 0] [G loss: 0] [VAE loss: 1.743607759475708]\n",
      "19 [D loss: 0] [G loss: 0] [VAE loss: 1.6797915697097778]\n",
      "20 [D loss: 0] [G loss: 0] [VAE loss: 1.9372236728668213]\n",
      "21 [D loss: 0] [G loss: 0] [VAE loss: 1.868544340133667]\n",
      "22 [D loss: 0] [G loss: 0] [VAE loss: 1.8171786069869995]\n",
      "23 [D loss: 0] [G loss: 0] [VAE loss: 1.9484513998031616]\n",
      "24 [D loss: 0] [G loss: 0] [VAE loss: 1.7910254001617432]\n",
      "25 [D loss: 0] [G loss: 0] [VAE loss: 1.9582329988479614]\n",
      "26 [D loss: 0] [G loss: 0] [VAE loss: 1.8127641677856445]\n",
      "27 [D loss: 0] [G loss: 0] [VAE loss: 1.8185100555419922]\n",
      "28 [D loss: 0] [G loss: 0] [VAE loss: 1.838426113128662]\n",
      "29 [D loss: 0] [G loss: 0] [VAE loss: 1.9094983339309692]\n",
      "30 [D loss: 0] [G loss: 0] [VAE loss: 1.697108507156372]\n",
      "31 [D loss: 0] [G loss: 0] [VAE loss: 1.8744486570358276]\n",
      "32 [D loss: 0] [G loss: 0] [VAE loss: 1.7548147439956665]\n",
      "33 [D loss: 0] [G loss: 0] [VAE loss: 1.998211145401001]\n",
      "34 [D loss: 0] [G loss: 0] [VAE loss: 1.6803674697875977]\n",
      "35 [D loss: 0] [G loss: 0] [VAE loss: 1.7149734497070312]\n",
      "36 [D loss: 0] [G loss: 0] [VAE loss: 1.8054379224777222]\n",
      "37 [D loss: 0] [G loss: 0] [VAE loss: 1.8066887855529785]\n",
      "38 [D loss: 0] [G loss: 0] [VAE loss: 1.7058783769607544]\n",
      "39 [D loss: 0] [G loss: 0] [VAE loss: 1.88527250289917]\n",
      "40 [D loss: 0] [G loss: 0] [VAE loss: 1.9696249961853027]\n",
      "41 [D loss: 0] [G loss: 0] [VAE loss: 1.903799295425415]\n",
      "42 [D loss: 0] [G loss: 0] [VAE loss: 1.7673851251602173]\n",
      "43 [D loss: 0] [G loss: 0] [VAE loss: 1.908471703529358]\n",
      "44 [D loss: 0] [G loss: 0] [VAE loss: 2.055180311203003]\n",
      "45 [D loss: 0] [G loss: 0] [VAE loss: 1.7833836078643799]\n",
      "46 [D loss: 0] [G loss: 0] [VAE loss: 1.9301091432571411]\n",
      "47 [D loss: 0] [G loss: 0] [VAE loss: 1.798424482345581]\n",
      "48 [D loss: 0] [G loss: 0] [VAE loss: 1.7481118440628052]\n",
      "49 [D loss: 0] [G loss: 0] [VAE loss: 1.7901502847671509]\n",
      "50 [D loss: 0] [G loss: 0] [VAE loss: 1.6760069131851196]\n",
      "51 [D loss: 0] [G loss: 0] [VAE loss: 1.9355065822601318]\n",
      "52 [D loss: 0] [G loss: 0] [VAE loss: 1.708899736404419]\n",
      "53 [D loss: 0] [G loss: 0] [VAE loss: 1.991109848022461]\n",
      "54 [D loss: 0] [G loss: 0] [VAE loss: 1.7826123237609863]\n",
      "55 [D loss: 0] [G loss: 0] [VAE loss: 1.6848556995391846]\n",
      "56 [D loss: 0] [G loss: 0] [VAE loss: 1.8439220190048218]\n",
      "57 [D loss: 0] [G loss: 0] [VAE loss: 1.9318249225616455]\n",
      "58 [D loss: 0] [G loss: 0] [VAE loss: 1.799957036972046]\n",
      "59 [D loss: 0] [G loss: 0] [VAE loss: 1.7754554748535156]\n",
      "60 [D loss: 0] [G loss: 0] [VAE loss: 1.8818624019622803]\n",
      "61 [D loss: 0] [G loss: 0] [VAE loss: 1.8002820014953613]\n",
      "62 [D loss: 0] [G loss: 0] [VAE loss: 1.7512577772140503]\n",
      "63 [D loss: 0] [G loss: 0] [VAE loss: 1.9453816413879395]\n",
      "64 [D loss: 0] [G loss: 0] [VAE loss: 1.9561305046081543]\n",
      "65 [D loss: 0] [G loss: 0] [VAE loss: 1.755367398262024]\n",
      "66 [D loss: 0] [G loss: 0] [VAE loss: 1.7697546482086182]\n",
      "67 [D loss: 0] [G loss: 0] [VAE loss: 1.7638413906097412]\n",
      "68 [D loss: 0] [G loss: 0] [VAE loss: 1.7254040241241455]\n",
      "69 [D loss: 0] [G loss: 0] [VAE loss: 1.7759897708892822]\n",
      "70 [D loss: 0] [G loss: 0] [VAE loss: 1.907729983329773]\n",
      "71 [D loss: 0] [G loss: 0] [VAE loss: 1.7732070684432983]\n",
      "72 [D loss: 0] [G loss: 0] [VAE loss: 1.8458548784255981]\n",
      "73 [D loss: 0] [G loss: 0] [VAE loss: 1.8887296915054321]\n",
      "74 [D loss: 0] [G loss: 0] [VAE loss: 1.8630530834197998]\n",
      "75 [D loss: 0] [G loss: 0] [VAE loss: 1.8330837488174438]\n",
      "76 [D loss: 0] [G loss: 0] [VAE loss: 1.8710025548934937]\n",
      "77 [D loss: 0] [G loss: 0] [VAE loss: 1.7935831546783447]\n",
      "78 [D loss: 0] [G loss: 0] [VAE loss: 1.7486181259155273]\n",
      "79 [D loss: 0] [G loss: 0] [VAE loss: 1.7401095628738403]\n",
      "80 [D loss: 0] [G loss: 0] [VAE loss: 1.7229613065719604]\n",
      "81 [D loss: 0] [G loss: 0] [VAE loss: 1.8335827589035034]\n",
      "82 [D loss: 0] [G loss: 0] [VAE loss: 1.6439878940582275]\n",
      "83 [D loss: 0] [G loss: 0] [VAE loss: 1.9312267303466797]\n",
      "84 [D loss: 0] [G loss: 0] [VAE loss: 1.854746699333191]\n",
      "85 [D loss: 0] [G loss: 0] [VAE loss: 1.8207809925079346]\n",
      "86 [D loss: 0] [G loss: 0] [VAE loss: 1.8580880165100098]\n",
      "87 [D loss: 0] [G loss: 0] [VAE loss: 1.879686951637268]\n",
      "88 [D loss: 0] [G loss: 0] [VAE loss: 1.8256862163543701]\n",
      "89 [D loss: 0] [G loss: 0] [VAE loss: 1.8177671432495117]\n",
      "90 [D loss: 0] [G loss: 0] [VAE loss: 1.7981793880462646]\n",
      "91 [D loss: 0] [G loss: 0] [VAE loss: 1.779221534729004]\n",
      "92 [D loss: 0] [G loss: 0] [VAE loss: 1.7482013702392578]\n",
      "93 [D loss: 0] [G loss: 0] [VAE loss: 1.7724189758300781]\n",
      "94 [D loss: 0] [G loss: 0] [VAE loss: 1.6803256273269653]\n",
      "95 [D loss: 0] [G loss: 0] [VAE loss: 1.909353256225586]\n",
      "96 [D loss: 0] [G loss: 0] [VAE loss: 1.9078550338745117]\n",
      "97 [D loss: 0] [G loss: 0] [VAE loss: 1.9477341175079346]\n",
      "98 [D loss: 0] [G loss: 0] [VAE loss: 1.8036985397338867]\n",
      "99 [D loss: 0] [G loss: 0] [VAE loss: 1.9733872413635254]\n",
      "100 [D loss: 0] [G loss: 0] [VAE loss: 1.8104418516159058]\n",
      "101 [D loss: 0] [G loss: 0] [VAE loss: 1.677594542503357]\n",
      "102 [D loss: 0] [G loss: 0] [VAE loss: 1.8110935688018799]\n",
      "103 [D loss: 0] [G loss: 0] [VAE loss: 1.84248685836792]\n",
      "104 [D loss: 0] [G loss: 0] [VAE loss: 1.7682058811187744]\n",
      "105 [D loss: 0] [G loss: 0] [VAE loss: 1.726811170578003]\n",
      "106 [D loss: 0] [G loss: 0] [VAE loss: 1.6993861198425293]\n",
      "107 [D loss: 0] [G loss: 0] [VAE loss: 1.5810502767562866]\n",
      "108 [D loss: 0] [G loss: 0] [VAE loss: 1.7740705013275146]\n",
      "109 [D loss: 0] [G loss: 0] [VAE loss: 1.9189670085906982]\n",
      "110 [D loss: 0] [G loss: 0] [VAE loss: 1.9011884927749634]\n",
      "111 [D loss: 0] [G loss: 0] [VAE loss: 1.8543623685836792]\n",
      "112 [D loss: 0] [G loss: 0] [VAE loss: 1.8312463760375977]\n",
      "113 [D loss: 0] [G loss: 0] [VAE loss: 1.6785557270050049]\n",
      "114 [D loss: 0] [G loss: 0] [VAE loss: 1.709151268005371]\n",
      "115 [D loss: 0] [G loss: 0] [VAE loss: 1.7755358219146729]\n",
      "116 [D loss: 0] [G loss: 0] [VAE loss: 1.9788700342178345]\n",
      "117 [D loss: 0] [G loss: 0] [VAE loss: 1.7865134477615356]\n",
      "118 [D loss: 0] [G loss: 0] [VAE loss: 1.8106480836868286]\n",
      "119 [D loss: 0] [G loss: 0] [VAE loss: 1.83517324924469]\n",
      "120 [D loss: 0] [G loss: 0] [VAE loss: 1.667891263961792]\n",
      "121 [D loss: 0] [G loss: 0] [VAE loss: 1.7995140552520752]\n",
      "122 [D loss: 0] [G loss: 0] [VAE loss: 1.7006592750549316]\n",
      "123 [D loss: 0] [G loss: 0] [VAE loss: 1.8478050231933594]\n",
      "124 [D loss: 0] [G loss: 0] [VAE loss: 1.7662729024887085]\n",
      "125 [D loss: 0] [G loss: 0] [VAE loss: 1.931061029434204]\n",
      "126 [D loss: 0] [G loss: 0] [VAE loss: 1.9402682781219482]\n",
      "127 [D loss: 0] [G loss: 0] [VAE loss: 1.8445309400558472]\n",
      "128 [D loss: 0] [G loss: 0] [VAE loss: 1.7475054264068604]\n",
      "129 [D loss: 0] [G loss: 0] [VAE loss: 1.8899040222167969]\n",
      "130 [D loss: 0] [G loss: 0] [VAE loss: 1.704745888710022]\n",
      "131 [D loss: 0] [G loss: 0] [VAE loss: 1.843639612197876]\n",
      "132 [D loss: 0] [G loss: 0] [VAE loss: 1.8896160125732422]\n",
      "133 [D loss: 0] [G loss: 0] [VAE loss: 1.8641293048858643]\n",
      "134 [D loss: 0] [G loss: 0] [VAE loss: 1.9036916494369507]\n",
      "135 [D loss: 0] [G loss: 0] [VAE loss: 1.841403841972351]\n",
      "136 [D loss: 0] [G loss: 0] [VAE loss: 1.6482610702514648]\n",
      "137 [D loss: 0] [G loss: 0] [VAE loss: 1.7499353885650635]\n",
      "138 [D loss: 0] [G loss: 0] [VAE loss: 1.783400058746338]\n",
      "139 [D loss: 0] [G loss: 0] [VAE loss: 1.6923844814300537]\n",
      "140 [D loss: 0] [G loss: 0] [VAE loss: 1.7259800434112549]\n",
      "141 [D loss: 0] [G loss: 0] [VAE loss: 2.029261589050293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 [D loss: 0] [G loss: 0] [VAE loss: 2.0098111629486084]\n",
      "143 [D loss: 0] [G loss: 0] [VAE loss: 1.8361401557922363]\n",
      "144 [D loss: 0] [G loss: 0] [VAE loss: 1.9030406475067139]\n",
      "145 [D loss: 0] [G loss: 0] [VAE loss: 1.6213717460632324]\n",
      "146 [D loss: 0] [G loss: 0] [VAE loss: 2.0472066402435303]\n",
      "147 [D loss: 0] [G loss: 0] [VAE loss: 1.8904359340667725]\n",
      "148 [D loss: 0] [G loss: 0] [VAE loss: 1.7959051132202148]\n",
      "149 [D loss: 0] [G loss: 0] [VAE loss: 1.7606133222579956]\n",
      "150 [D loss: 0] [G loss: 0] [VAE loss: 1.6956381797790527]\n",
      "151 [D loss: 0] [G loss: 0] [VAE loss: 1.8386625051498413]\n",
      "152 [D loss: 0] [G loss: 0] [VAE loss: 1.9002611637115479]\n",
      "153 [D loss: 0] [G loss: 0] [VAE loss: 1.9641976356506348]\n",
      "154 [D loss: 0] [G loss: 0] [VAE loss: 1.7857688665390015]\n",
      "155 [D loss: 0] [G loss: 0] [VAE loss: 1.7482776641845703]\n",
      "156 [D loss: 0] [G loss: 0] [VAE loss: 2.0294840335845947]\n",
      "157 [D loss: 0] [G loss: 0] [VAE loss: 1.8315781354904175]\n",
      "158 [D loss: 0] [G loss: 0] [VAE loss: 1.778516411781311]\n",
      "159 [D loss: 0] [G loss: 0] [VAE loss: 1.740875005722046]\n",
      "160 [D loss: 0] [G loss: 0] [VAE loss: 1.7142888307571411]\n",
      "161 [D loss: 0] [G loss: 0] [VAE loss: 1.7451804876327515]\n",
      "162 [D loss: 0] [G loss: 0] [VAE loss: 1.7734347581863403]\n",
      "163 [D loss: 0] [G loss: 0] [VAE loss: 1.8300175666809082]\n",
      "164 [D loss: 0] [G loss: 0] [VAE loss: 1.6730601787567139]\n",
      "165 [D loss: 0] [G loss: 0] [VAE loss: 1.7973297834396362]\n",
      "166 [D loss: 0] [G loss: 0] [VAE loss: 1.6848323345184326]\n",
      "167 [D loss: 0] [G loss: 0] [VAE loss: 1.881172776222229]\n",
      "168 [D loss: 0] [G loss: 0] [VAE loss: 1.7308273315429688]\n",
      "169 [D loss: 0] [G loss: 0] [VAE loss: 1.5817501544952393]\n",
      "170 [D loss: 0] [G loss: 0] [VAE loss: 1.830690860748291]\n",
      "171 [D loss: 0] [G loss: 0] [VAE loss: 1.8310840129852295]\n",
      "172 [D loss: 0] [G loss: 0] [VAE loss: 1.8750903606414795]\n",
      "173 [D loss: 0] [G loss: 0] [VAE loss: 1.7636662721633911]\n",
      "174 [D loss: 0] [G loss: 0] [VAE loss: 1.8187673091888428]\n",
      "175 [D loss: 0] [G loss: 0] [VAE loss: 1.8865026235580444]\n",
      "176 [D loss: 0] [G loss: 0] [VAE loss: 1.701912760734558]\n",
      "177 [D loss: 0] [G loss: 0] [VAE loss: 2.0333123207092285]\n",
      "178 [D loss: 0] [G loss: 0] [VAE loss: 1.9859039783477783]\n",
      "179 [D loss: 0] [G loss: 0] [VAE loss: 1.6956977844238281]\n",
      "180 [D loss: 0] [G loss: 0] [VAE loss: 1.8862252235412598]\n",
      "181 [D loss: 0] [G loss: 0] [VAE loss: 1.921186089515686]\n",
      "182 [D loss: 0] [G loss: 0] [VAE loss: 1.66868257522583]\n",
      "183 [D loss: 0] [G loss: 0] [VAE loss: 1.8107987642288208]\n",
      "184 [D loss: 0] [G loss: 0] [VAE loss: 1.707176685333252]\n",
      "185 [D loss: 0] [G loss: 0] [VAE loss: 1.7309540510177612]\n",
      "186 [D loss: 0] [G loss: 0] [VAE loss: 1.6815788745880127]\n",
      "187 [D loss: 0] [G loss: 0] [VAE loss: 1.9181008338928223]\n",
      "188 [D loss: 0] [G loss: 0] [VAE loss: 1.7662363052368164]\n",
      "189 [D loss: 0] [G loss: 0] [VAE loss: 1.7500567436218262]\n",
      "190 [D loss: 0] [G loss: 0] [VAE loss: 1.7795236110687256]\n",
      "191 [D loss: 0] [G loss: 0] [VAE loss: 1.791883945465088]\n",
      "192 [D loss: 0] [G loss: 0] [VAE loss: 1.8892168998718262]\n",
      "193 [D loss: 0] [G loss: 0] [VAE loss: 1.6866395473480225]\n",
      "194 [D loss: 0] [G loss: 0] [VAE loss: 1.8165547847747803]\n",
      "195 [D loss: 0] [G loss: 0] [VAE loss: 1.8245058059692383]\n",
      "196 [D loss: 0] [G loss: 0] [VAE loss: 1.7649527788162231]\n",
      "197 [D loss: 0] [G loss: 0] [VAE loss: 1.7721669673919678]\n",
      "198 [D loss: 0] [G loss: 0] [VAE loss: 1.8212990760803223]\n",
      "199 [D loss: 0] [G loss: 0] [VAE loss: 1.7674707174301147]\n",
      "200 [D loss: 0] [G loss: 0] [VAE loss: 1.7652959823608398]\n",
      "201 [D loss: 0] [G loss: 0] [VAE loss: 1.7990210056304932]\n",
      "202 [D loss: 0] [G loss: 0] [VAE loss: 1.7940564155578613]\n",
      "203 [D loss: 0] [G loss: 0] [VAE loss: 1.8195092678070068]\n",
      "204 [D loss: 0] [G loss: 0] [VAE loss: 1.9408318996429443]\n",
      "205 [D loss: 0] [G loss: 0] [VAE loss: 1.786252498626709]\n",
      "206 [D loss: 0] [G loss: 0] [VAE loss: 1.9149601459503174]\n",
      "207 [D loss: 0] [G loss: 0] [VAE loss: 1.812471628189087]\n",
      "208 [D loss: 0] [G loss: 0] [VAE loss: 1.7334810495376587]\n",
      "209 [D loss: 0] [G loss: 0] [VAE loss: 1.9064313173294067]\n",
      "210 [D loss: 0] [G loss: 0] [VAE loss: 1.8516697883605957]\n",
      "211 [D loss: 0] [G loss: 0] [VAE loss: 1.7214528322219849]\n",
      "212 [D loss: 0] [G loss: 0] [VAE loss: 1.8831489086151123]\n",
      "213 [D loss: 0] [G loss: 0] [VAE loss: 1.7488832473754883]\n",
      "214 [D loss: 0] [G loss: 0] [VAE loss: 1.8018677234649658]\n",
      "215 [D loss: 0] [G loss: 0] [VAE loss: 1.7453460693359375]\n",
      "216 [D loss: 0] [G loss: 0] [VAE loss: 1.754751443862915]\n",
      "217 [D loss: 0] [G loss: 0] [VAE loss: 1.8181328773498535]\n",
      "218 [D loss: 0] [G loss: 0] [VAE loss: 1.6155006885528564]\n",
      "219 [D loss: 0] [G loss: 0] [VAE loss: 1.8718814849853516]\n",
      "220 [D loss: 0] [G loss: 0] [VAE loss: 1.872922420501709]\n",
      "221 [D loss: 0] [G loss: 0] [VAE loss: 1.8101863861083984]\n",
      "222 [D loss: 0] [G loss: 0] [VAE loss: 1.7974945306777954]\n",
      "223 [D loss: 0] [G loss: 0] [VAE loss: 1.8799816370010376]\n",
      "224 [D loss: 0] [G loss: 0] [VAE loss: 1.6930487155914307]\n",
      "225 [D loss: 0] [G loss: 0] [VAE loss: 1.6422829627990723]\n",
      "226 [D loss: 0] [G loss: 0] [VAE loss: 1.9205080270767212]\n",
      "227 [D loss: 0] [G loss: 0] [VAE loss: 1.727198839187622]\n",
      "228 [D loss: 0] [G loss: 0] [VAE loss: 1.767195463180542]\n",
      "229 [D loss: 0] [G loss: 0] [VAE loss: 1.795905351638794]\n",
      "230 [D loss: 0] [G loss: 0] [VAE loss: 1.8442996740341187]\n",
      "231 [D loss: 0] [G loss: 0] [VAE loss: 1.9541034698486328]\n",
      "232 [D loss: 0] [G loss: 0] [VAE loss: 1.6811352968215942]\n",
      "233 [D loss: 0] [G loss: 0] [VAE loss: 1.7944592237472534]\n",
      "234 [D loss: 0] [G loss: 0] [VAE loss: 1.860386610031128]\n",
      "235 [D loss: 0] [G loss: 0] [VAE loss: 1.7174031734466553]\n",
      "236 [D loss: 0] [G loss: 0] [VAE loss: 1.8101352453231812]\n",
      "237 [D loss: 0] [G loss: 0] [VAE loss: 1.9161691665649414]\n",
      "238 [D loss: 0] [G loss: 0] [VAE loss: 1.8250905275344849]\n",
      "239 [D loss: 0] [G loss: 0] [VAE loss: 1.8890115022659302]\n",
      "240 [D loss: 0] [G loss: 0] [VAE loss: 2.0821292400360107]\n",
      "241 [D loss: 0] [G loss: 0] [VAE loss: 1.7666162252426147]\n",
      "242 [D loss: 0] [G loss: 0] [VAE loss: 1.7792564630508423]\n",
      "243 [D loss: 0] [G loss: 0] [VAE loss: 1.7326000928878784]\n",
      "244 [D loss: 0] [G loss: 0] [VAE loss: 1.7349387407302856]\n",
      "245 [D loss: 0] [G loss: 0] [VAE loss: 1.7496044635772705]\n",
      "246 [D loss: 0] [G loss: 0] [VAE loss: 1.7839242219924927]\n",
      "247 [D loss: 0] [G loss: 0] [VAE loss: 1.7792448997497559]\n",
      "248 [D loss: 0] [G loss: 0] [VAE loss: 1.7209774255752563]\n",
      "249 [D loss: 0] [G loss: 0] [VAE loss: 1.8943440914154053]\n",
      "250 [D loss: 0] [G loss: 0] [VAE loss: 1.8627779483795166]\n",
      "251 [D loss: 0] [G loss: 0] [VAE loss: 1.7355859279632568]\n",
      "252 [D loss: 0] [G loss: 0] [VAE loss: 1.7399678230285645]\n",
      "253 [D loss: 0] [G loss: 0] [VAE loss: 1.799826741218567]\n",
      "254 [D loss: 0] [G loss: 0] [VAE loss: 1.7313473224639893]\n",
      "255 [D loss: 0] [G loss: 0] [VAE loss: 1.7783076763153076]\n",
      "256 [D loss: 0] [G loss: 0] [VAE loss: 1.770876407623291]\n",
      "257 [D loss: 0] [G loss: 0] [VAE loss: 1.7336598634719849]\n",
      "258 [D loss: 0] [G loss: 0] [VAE loss: 1.7701373100280762]\n",
      "259 [D loss: 0] [G loss: 0] [VAE loss: 1.778839111328125]\n",
      "260 [D loss: 0] [G loss: 0] [VAE loss: 1.8315109014511108]\n",
      "261 [D loss: 0] [G loss: 0] [VAE loss: 1.7413644790649414]\n",
      "262 [D loss: 0] [G loss: 0] [VAE loss: 1.7304983139038086]\n",
      "263 [D loss: 0] [G loss: 0] [VAE loss: 1.7004843950271606]\n",
      "264 [D loss: 0] [G loss: 0] [VAE loss: 1.7466037273406982]\n",
      "265 [D loss: 0] [G loss: 0] [VAE loss: 1.7698745727539062]\n",
      "266 [D loss: 0] [G loss: 0] [VAE loss: 1.8112821578979492]\n",
      "267 [D loss: 0] [G loss: 0] [VAE loss: 1.6934576034545898]\n",
      "268 [D loss: 0] [G loss: 0] [VAE loss: 1.6466928720474243]\n",
      "269 [D loss: 0] [G loss: 0] [VAE loss: 1.7577149868011475]\n",
      "270 [D loss: 0] [G loss: 0] [VAE loss: 1.7912994623184204]\n",
      "271 [D loss: 0] [G loss: 0] [VAE loss: 1.7869176864624023]\n",
      "272 [D loss: 0] [G loss: 0] [VAE loss: 1.7598462104797363]\n",
      "273 [D loss: 0] [G loss: 0] [VAE loss: 1.78971266746521]\n",
      "274 [D loss: 0] [G loss: 0] [VAE loss: 1.6195387840270996]\n",
      "275 [D loss: 0] [G loss: 0] [VAE loss: 1.759096384048462]\n",
      "276 [D loss: 0] [G loss: 0] [VAE loss: 1.8095626831054688]\n",
      "277 [D loss: 0] [G loss: 0] [VAE loss: 1.9290181398391724]\n",
      "278 [D loss: 0] [G loss: 0] [VAE loss: 1.8687171936035156]\n",
      "279 [D loss: 0] [G loss: 0] [VAE loss: 1.8870813846588135]\n",
      "280 [D loss: 0] [G loss: 0] [VAE loss: 1.903771162033081]\n",
      "281 [D loss: 0] [G loss: 0] [VAE loss: 1.9122004508972168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 [D loss: 0] [G loss: 0] [VAE loss: 1.8275504112243652]\n",
      "283 [D loss: 0] [G loss: 0] [VAE loss: 2.177511215209961]\n",
      "284 [D loss: 0] [G loss: 0] [VAE loss: 1.799926519393921]\n",
      "285 [D loss: 0] [G loss: 0] [VAE loss: 1.8384249210357666]\n",
      "286 [D loss: 0] [G loss: 0] [VAE loss: 1.7504271268844604]\n",
      "287 [D loss: 0] [G loss: 0] [VAE loss: 1.7846286296844482]\n",
      "288 [D loss: 0] [G loss: 0] [VAE loss: 1.8055254220962524]\n",
      "289 [D loss: 0] [G loss: 0] [VAE loss: 1.9432159662246704]\n",
      "290 [D loss: 0] [G loss: 0] [VAE loss: 1.6815484762191772]\n",
      "291 [D loss: 0] [G loss: 0] [VAE loss: 1.6944864988327026]\n",
      "292 [D loss: 0] [G loss: 0] [VAE loss: 1.8179327249526978]\n",
      "293 [D loss: 0] [G loss: 0] [VAE loss: 1.7589201927185059]\n",
      "294 [D loss: 0] [G loss: 0] [VAE loss: 1.7494069337844849]\n",
      "295 [D loss: 0] [G loss: 0] [VAE loss: 1.836616039276123]\n",
      "296 [D loss: 0] [G loss: 0] [VAE loss: 1.6802128553390503]\n",
      "297 [D loss: 0] [G loss: 0] [VAE loss: 1.7440191507339478]\n",
      "298 [D loss: 0] [G loss: 0] [VAE loss: 1.9664175510406494]\n",
      "299 [D loss: 0] [G loss: 0] [VAE loss: 1.7762686014175415]\n",
      "300 [D loss: 0] [G loss: 0] [VAE loss: 2.032698154449463]\n",
      "301 [D loss: 0] [G loss: 0] [VAE loss: 1.6820207834243774]\n",
      "302 [D loss: 0] [G loss: 0] [VAE loss: 1.7560310363769531]\n",
      "303 [D loss: 0] [G loss: 0] [VAE loss: 1.7749484777450562]\n",
      "304 [D loss: 0] [G loss: 0] [VAE loss: 1.8037633895874023]\n",
      "305 [D loss: 0] [G loss: 0] [VAE loss: 1.8691542148590088]\n",
      "306 [D loss: 0] [G loss: 0] [VAE loss: 1.7264991998672485]\n",
      "307 [D loss: 0] [G loss: 0] [VAE loss: 1.9465826749801636]\n",
      "308 [D loss: 0] [G loss: 0] [VAE loss: 1.629760980606079]\n",
      "309 [D loss: 0] [G loss: 0] [VAE loss: 1.746750831604004]\n",
      "310 [D loss: 0] [G loss: 0] [VAE loss: 1.937540888786316]\n",
      "311 [D loss: 0] [G loss: 0] [VAE loss: 1.6167514324188232]\n",
      "312 [D loss: 0] [G loss: 0] [VAE loss: 1.836151123046875]\n",
      "313 [D loss: 0] [G loss: 0] [VAE loss: 1.7731037139892578]\n",
      "314 [D loss: 0] [G loss: 0] [VAE loss: 1.6947338581085205]\n",
      "315 [D loss: 0] [G loss: 0] [VAE loss: 1.7476054430007935]\n",
      "316 [D loss: 0] [G loss: 0] [VAE loss: 1.7823212146759033]\n",
      "317 [D loss: 0] [G loss: 0] [VAE loss: 1.6986911296844482]\n",
      "318 [D loss: 0] [G loss: 0] [VAE loss: 1.8236501216888428]\n",
      "319 [D loss: 0] [G loss: 0] [VAE loss: 1.7897348403930664]\n",
      "320 [D loss: 0] [G loss: 0] [VAE loss: 1.8717983961105347]\n",
      "321 [D loss: 0] [G loss: 0] [VAE loss: 1.6122931241989136]\n",
      "322 [D loss: 0] [G loss: 0] [VAE loss: 1.9567699432373047]\n",
      "323 [D loss: 0] [G loss: 0] [VAE loss: 1.8499207496643066]\n",
      "324 [D loss: 0] [G loss: 0] [VAE loss: 1.7834539413452148]\n",
      "325 [D loss: 0] [G loss: 0] [VAE loss: 1.9622780084609985]\n",
      "326 [D loss: 0] [G loss: 0] [VAE loss: 1.7295359373092651]\n",
      "327 [D loss: 0] [G loss: 0] [VAE loss: 1.8884406089782715]\n",
      "328 [D loss: 0] [G loss: 0] [VAE loss: 1.7756973505020142]\n",
      "329 [D loss: 0] [G loss: 0] [VAE loss: 1.753265619277954]\n",
      "330 [D loss: 0] [G loss: 0] [VAE loss: 1.855047345161438]\n",
      "331 [D loss: 0] [G loss: 0] [VAE loss: 1.734649658203125]\n",
      "332 [D loss: 0] [G loss: 0] [VAE loss: 1.8358442783355713]\n",
      "333 [D loss: 0] [G loss: 0] [VAE loss: 1.7754342555999756]\n",
      "334 [D loss: 0] [G loss: 0] [VAE loss: 1.6870726346969604]\n",
      "335 [D loss: 0] [G loss: 0] [VAE loss: 1.77579665184021]\n",
      "336 [D loss: 0] [G loss: 0] [VAE loss: 1.7014601230621338]\n",
      "337 [D loss: 0] [G loss: 0] [VAE loss: 1.5805072784423828]\n",
      "338 [D loss: 0] [G loss: 0] [VAE loss: 1.7502217292785645]\n",
      "339 [D loss: 0] [G loss: 0] [VAE loss: 1.7757045030593872]\n",
      "340 [D loss: 0] [G loss: 0] [VAE loss: 1.887575387954712]\n",
      "341 [D loss: 0] [G loss: 0] [VAE loss: 1.690521001815796]\n",
      "342 [D loss: 0] [G loss: 0] [VAE loss: 1.7870087623596191]\n",
      "343 [D loss: 0] [G loss: 0] [VAE loss: 1.7392499446868896]\n",
      "344 [D loss: 0] [G loss: 0] [VAE loss: 1.8753814697265625]\n",
      "345 [D loss: 0] [G loss: 0] [VAE loss: 1.76063072681427]\n",
      "346 [D loss: 0] [G loss: 0] [VAE loss: 1.7982417345046997]\n",
      "347 [D loss: 0] [G loss: 0] [VAE loss: 1.8523215055465698]\n",
      "348 [D loss: 0] [G loss: 0] [VAE loss: 2.0615146160125732]\n",
      "349 [D loss: 0] [G loss: 0] [VAE loss: 1.7115778923034668]\n",
      "350 [D loss: 0] [G loss: 0] [VAE loss: 1.7028218507766724]\n",
      "351 [D loss: 0] [G loss: 0] [VAE loss: 1.7919057607650757]\n",
      "352 [D loss: 0] [G loss: 0] [VAE loss: 1.705250859260559]\n",
      "353 [D loss: 0] [G loss: 0] [VAE loss: 1.7532615661621094]\n",
      "354 [D loss: 0] [G loss: 0] [VAE loss: 1.857785940170288]\n",
      "355 [D loss: 0] [G loss: 0] [VAE loss: 1.7107181549072266]\n",
      "356 [D loss: 0] [G loss: 0] [VAE loss: 1.798440933227539]\n",
      "357 [D loss: 0] [G loss: 0] [VAE loss: 1.8582684993743896]\n",
      "358 [D loss: 0] [G loss: 0] [VAE loss: 1.890390396118164]\n",
      "359 [D loss: 0] [G loss: 0] [VAE loss: 1.7777066230773926]\n",
      "360 [D loss: 0] [G loss: 0] [VAE loss: 1.781153678894043]\n",
      "361 [D loss: 0] [G loss: 0] [VAE loss: 1.6447523832321167]\n",
      "362 [D loss: 0] [G loss: 0] [VAE loss: 1.7845250368118286]\n",
      "363 [D loss: 0] [G loss: 0] [VAE loss: 1.7873120307922363]\n",
      "364 [D loss: 0] [G loss: 0] [VAE loss: 1.9225499629974365]\n",
      "365 [D loss: 0] [G loss: 0] [VAE loss: 1.7426090240478516]\n",
      "366 [D loss: 0] [G loss: 0] [VAE loss: 1.7741796970367432]\n",
      "367 [D loss: 0] [G loss: 0] [VAE loss: 1.783743143081665]\n",
      "368 [D loss: 0] [G loss: 0] [VAE loss: 1.8049685955047607]\n",
      "369 [D loss: 0] [G loss: 0] [VAE loss: 1.8051738739013672]\n",
      "370 [D loss: 0] [G loss: 0] [VAE loss: 1.785793423652649]\n",
      "371 [D loss: 0] [G loss: 0] [VAE loss: 1.9340583086013794]\n",
      "372 [D loss: 0] [G loss: 0] [VAE loss: 1.7405176162719727]\n",
      "373 [D loss: 0] [G loss: 0] [VAE loss: 1.8040739297866821]\n",
      "374 [D loss: 0] [G loss: 0] [VAE loss: 1.8033738136291504]\n",
      "375 [D loss: 0] [G loss: 0] [VAE loss: 1.8101922273635864]\n",
      "376 [D loss: 0] [G loss: 0] [VAE loss: 1.7128355503082275]\n",
      "377 [D loss: 0] [G loss: 0] [VAE loss: 1.8718509674072266]\n",
      "378 [D loss: 0] [G loss: 0] [VAE loss: 1.887505292892456]\n",
      "379 [D loss: 0] [G loss: 0] [VAE loss: 1.8288954496383667]\n",
      "380 [D loss: 0] [G loss: 0] [VAE loss: 1.6139755249023438]\n",
      "381 [D loss: 0] [G loss: 0] [VAE loss: 1.8827111721038818]\n",
      "382 [D loss: 0] [G loss: 0] [VAE loss: 1.7054839134216309]\n",
      "383 [D loss: 0] [G loss: 0] [VAE loss: 1.8039145469665527]\n",
      "384 [D loss: 0] [G loss: 0] [VAE loss: 1.7355161905288696]\n",
      "385 [D loss: 0] [G loss: 0] [VAE loss: 1.5998897552490234]\n",
      "386 [D loss: 0] [G loss: 0] [VAE loss: 1.844240427017212]\n",
      "387 [D loss: 0] [G loss: 0] [VAE loss: 1.8401882648468018]\n",
      "388 [D loss: 0] [G loss: 0] [VAE loss: 1.783909559249878]\n",
      "389 [D loss: 0] [G loss: 0] [VAE loss: 1.7330085039138794]\n",
      "390 [D loss: 0] [G loss: 0] [VAE loss: 1.8913882970809937]\n",
      "391 [D loss: 0] [G loss: 0] [VAE loss: 1.9380993843078613]\n",
      "392 [D loss: 0] [G loss: 0] [VAE loss: 1.734675645828247]\n",
      "393 [D loss: 0] [G loss: 0] [VAE loss: 1.8206796646118164]\n",
      "394 [D loss: 0] [G loss: 0] [VAE loss: 1.8183101415634155]\n",
      "395 [D loss: 0] [G loss: 0] [VAE loss: 1.8757524490356445]\n",
      "396 [D loss: 0] [G loss: 0] [VAE loss: 1.8144245147705078]\n",
      "397 [D loss: 0] [G loss: 0] [VAE loss: 1.7423585653305054]\n",
      "398 [D loss: 0] [G loss: 0] [VAE loss: 1.7109320163726807]\n",
      "399 [D loss: 0] [G loss: 0] [VAE loss: 1.7021143436431885]\n",
      "400 [D loss: 0] [G loss: 0] [VAE loss: 1.875770092010498]\n",
      "401 [D loss: 0] [G loss: 0] [VAE loss: 1.7256197929382324]\n",
      "402 [D loss: 0] [G loss: 0] [VAE loss: 1.9544267654418945]\n",
      "403 [D loss: 0] [G loss: 0] [VAE loss: 1.837916374206543]\n",
      "404 [D loss: 0] [G loss: 0] [VAE loss: 1.8347983360290527]\n",
      "405 [D loss: 0] [G loss: 0] [VAE loss: 1.8098666667938232]\n",
      "406 [D loss: 0] [G loss: 0] [VAE loss: 1.8919055461883545]\n",
      "407 [D loss: 0] [G loss: 0] [VAE loss: 1.6191668510437012]\n",
      "408 [D loss: 0] [G loss: 0] [VAE loss: 1.8176162242889404]\n",
      "409 [D loss: 0] [G loss: 0] [VAE loss: 1.79004967212677]\n",
      "410 [D loss: 0] [G loss: 0] [VAE loss: 1.7906244993209839]\n",
      "411 [D loss: 0] [G loss: 0] [VAE loss: 1.9184553623199463]\n",
      "412 [D loss: 0] [G loss: 0] [VAE loss: 1.7869274616241455]\n",
      "413 [D loss: 0] [G loss: 0] [VAE loss: 1.8634445667266846]\n",
      "414 [D loss: 0] [G loss: 0] [VAE loss: 1.7291762828826904]\n",
      "415 [D loss: 0] [G loss: 0] [VAE loss: 1.7812787294387817]\n",
      "416 [D loss: 0] [G loss: 0] [VAE loss: 1.8000907897949219]\n",
      "417 [D loss: 0] [G loss: 0] [VAE loss: 1.803133249282837]\n",
      "418 [D loss: 0] [G loss: 0] [VAE loss: 2.001559019088745]\n",
      "419 [D loss: 0] [G loss: 0] [VAE loss: 1.7138819694519043]\n",
      "420 [D loss: 0] [G loss: 0] [VAE loss: 1.7902230024337769]\n",
      "421 [D loss: 0] [G loss: 0] [VAE loss: 1.6719632148742676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 [D loss: 0] [G loss: 0] [VAE loss: 1.6163570880889893]\n",
      "423 [D loss: 0] [G loss: 0] [VAE loss: 1.858932375907898]\n",
      "424 [D loss: 0] [G loss: 0] [VAE loss: 1.905656099319458]\n",
      "425 [D loss: 0] [G loss: 0] [VAE loss: 1.8278847932815552]\n",
      "426 [D loss: 0] [G loss: 0] [VAE loss: 1.8128838539123535]\n",
      "427 [D loss: 0] [G loss: 0] [VAE loss: 1.8216984272003174]\n",
      "428 [D loss: 0] [G loss: 0] [VAE loss: 1.785996437072754]\n",
      "429 [D loss: 0] [G loss: 0] [VAE loss: 1.7377206087112427]\n",
      "430 [D loss: 0] [G loss: 0] [VAE loss: 1.7325654029846191]\n",
      "431 [D loss: 0] [G loss: 0] [VAE loss: 1.646969199180603]\n",
      "432 [D loss: 0] [G loss: 0] [VAE loss: 1.784805178642273]\n",
      "433 [D loss: 0] [G loss: 0] [VAE loss: 1.7970991134643555]\n",
      "434 [D loss: 0] [G loss: 0] [VAE loss: 1.78309965133667]\n",
      "435 [D loss: 0] [G loss: 0] [VAE loss: 1.8143963813781738]\n",
      "436 [D loss: 0] [G loss: 0] [VAE loss: 1.6637611389160156]\n",
      "437 [D loss: 0] [G loss: 0] [VAE loss: 1.7055460214614868]\n",
      "438 [D loss: 0] [G loss: 0] [VAE loss: 1.7634447813034058]\n",
      "439 [D loss: 0] [G loss: 0] [VAE loss: 1.833160161972046]\n",
      "440 [D loss: 0] [G loss: 0] [VAE loss: 1.824679970741272]\n",
      "441 [D loss: 0] [G loss: 0] [VAE loss: 1.6592578887939453]\n",
      "442 [D loss: 0] [G loss: 0] [VAE loss: 1.9023700952529907]\n",
      "443 [D loss: 0] [G loss: 0] [VAE loss: 1.7677996158599854]\n",
      "444 [D loss: 0] [G loss: 0] [VAE loss: 1.7362910509109497]\n",
      "445 [D loss: 0] [G loss: 0] [VAE loss: 1.7934681177139282]\n",
      "446 [D loss: 0] [G loss: 0] [VAE loss: 1.917257308959961]\n",
      "447 [D loss: 0] [G loss: 0] [VAE loss: 1.7293866872787476]\n",
      "448 [D loss: 0] [G loss: 0] [VAE loss: 1.9188547134399414]\n",
      "449 [D loss: 0] [G loss: 0] [VAE loss: 1.8802509307861328]\n",
      "450 [D loss: 0] [G loss: 0] [VAE loss: 1.825649619102478]\n",
      "451 [D loss: 0] [G loss: 0] [VAE loss: 1.8374089002609253]\n",
      "452 [D loss: 0] [G loss: 0] [VAE loss: 1.6928452253341675]\n",
      "453 [D loss: 0] [G loss: 0] [VAE loss: 1.954982876777649]\n",
      "454 [D loss: 0] [G loss: 0] [VAE loss: 1.9172576665878296]\n",
      "455 [D loss: 0] [G loss: 0] [VAE loss: 1.8852049112319946]\n",
      "456 [D loss: 0] [G loss: 0] [VAE loss: 1.7966688871383667]\n",
      "457 [D loss: 0] [G loss: 0] [VAE loss: 1.7642956972122192]\n",
      "458 [D loss: 0] [G loss: 0] [VAE loss: 1.9373987913131714]\n",
      "459 [D loss: 0] [G loss: 0] [VAE loss: 1.7835369110107422]\n",
      "460 [D loss: 0] [G loss: 0] [VAE loss: 1.8228785991668701]\n",
      "461 [D loss: 0] [G loss: 0] [VAE loss: 1.8648796081542969]\n",
      "462 [D loss: 0] [G loss: 0] [VAE loss: 1.9316017627716064]\n",
      "463 [D loss: 0] [G loss: 0] [VAE loss: 1.748753547668457]\n",
      "464 [D loss: 0] [G loss: 0] [VAE loss: 1.8126487731933594]\n",
      "465 [D loss: 0] [G loss: 0] [VAE loss: 1.7917137145996094]\n",
      "466 [D loss: 0] [G loss: 0] [VAE loss: 1.6847689151763916]\n",
      "467 [D loss: 0] [G loss: 0] [VAE loss: 1.7805125713348389]\n",
      "468 [D loss: 0] [G loss: 0] [VAE loss: 1.8250014781951904]\n",
      "469 [D loss: 0] [G loss: 0] [VAE loss: 1.9287829399108887]\n",
      "470 [D loss: 0] [G loss: 0] [VAE loss: 1.7876694202423096]\n",
      "471 [D loss: 0] [G loss: 0] [VAE loss: 1.9157050848007202]\n",
      "472 [D loss: 0] [G loss: 0] [VAE loss: 1.9727981090545654]\n",
      "473 [D loss: 0] [G loss: 0] [VAE loss: 1.7251394987106323]\n",
      "474 [D loss: 0] [G loss: 0] [VAE loss: 1.5660983324050903]\n",
      "475 [D loss: 0] [G loss: 0] [VAE loss: 1.821634292602539]\n",
      "476 [D loss: 0] [G loss: 0] [VAE loss: 1.7153387069702148]\n",
      "477 [D loss: 0] [G loss: 0] [VAE loss: 1.7307689189910889]\n",
      "478 [D loss: 0] [G loss: 0] [VAE loss: 1.806206226348877]\n",
      "479 [D loss: 0] [G loss: 0] [VAE loss: 1.7666895389556885]\n",
      "480 [D loss: 0] [G loss: 0] [VAE loss: 1.707944631576538]\n",
      "481 [D loss: 0] [G loss: 0] [VAE loss: 1.8250772953033447]\n",
      "482 [D loss: 0] [G loss: 0] [VAE loss: 1.681971788406372]\n",
      "483 [D loss: 0] [G loss: 0] [VAE loss: 1.8400301933288574]\n",
      "484 [D loss: 0] [G loss: 0] [VAE loss: 1.8205143213272095]\n",
      "485 [D loss: 0] [G loss: 0] [VAE loss: 1.718485713005066]\n",
      "486 [D loss: 0] [G loss: 0] [VAE loss: 1.7420928478240967]\n",
      "487 [D loss: 0] [G loss: 0] [VAE loss: 1.6323890686035156]\n",
      "488 [D loss: 0] [G loss: 0] [VAE loss: 1.8231918811798096]\n",
      "489 [D loss: 0] [G loss: 0] [VAE loss: 1.8083839416503906]\n",
      "490 [D loss: 0] [G loss: 0] [VAE loss: 1.7669944763183594]\n",
      "491 [D loss: 0] [G loss: 0] [VAE loss: 1.749376654624939]\n",
      "492 [D loss: 0] [G loss: 0] [VAE loss: 1.795663833618164]\n",
      "493 [D loss: 0] [G loss: 0] [VAE loss: 1.8193793296813965]\n",
      "494 [D loss: 0] [G loss: 0] [VAE loss: 1.837092638015747]\n",
      "495 [D loss: 0] [G loss: 0] [VAE loss: 1.825066089630127]\n",
      "496 [D loss: 0] [G loss: 0] [VAE loss: 1.7604002952575684]\n",
      "497 [D loss: 0] [G loss: 0] [VAE loss: 1.7251286506652832]\n",
      "498 [D loss: 0] [G loss: 0] [VAE loss: 1.9058866500854492]\n",
      "499 [D loss: 0] [G loss: 0] [VAE loss: 1.8565508127212524]\n",
      "500 [D loss: 0] [G loss: 0] [VAE loss: 1.7745304107666016]\n",
      "501 [D loss: 0] [G loss: 0] [VAE loss: 1.766484022140503]\n",
      "502 [D loss: 0] [G loss: 0] [VAE loss: 1.9451932907104492]\n",
      "503 [D loss: 0] [G loss: 0] [VAE loss: 1.6340374946594238]\n",
      "504 [D loss: 0] [G loss: 0] [VAE loss: 1.7471498250961304]\n",
      "505 [D loss: 0] [G loss: 0] [VAE loss: 1.7894436120986938]\n",
      "506 [D loss: 0] [G loss: 0] [VAE loss: 1.8046934604644775]\n",
      "507 [D loss: 0] [G loss: 0] [VAE loss: 1.8578524589538574]\n",
      "508 [D loss: 0] [G loss: 0] [VAE loss: 1.724723219871521]\n",
      "509 [D loss: 0] [G loss: 0] [VAE loss: 1.9790794849395752]\n",
      "510 [D loss: 0] [G loss: 0] [VAE loss: 1.7770414352416992]\n",
      "511 [D loss: 0] [G loss: 0] [VAE loss: 1.6979598999023438]\n",
      "512 [D loss: 0] [G loss: 0] [VAE loss: 1.6592421531677246]\n",
      "513 [D loss: 0] [G loss: 0] [VAE loss: 1.8453655242919922]\n",
      "514 [D loss: 0] [G loss: 0] [VAE loss: 1.7624659538269043]\n",
      "515 [D loss: 0] [G loss: 0] [VAE loss: 1.760660171508789]\n",
      "516 [D loss: 0] [G loss: 0] [VAE loss: 1.827224612236023]\n",
      "517 [D loss: 0] [G loss: 0] [VAE loss: 1.782246470451355]\n",
      "518 [D loss: 0] [G loss: 0] [VAE loss: 1.8219735622406006]\n",
      "519 [D loss: 0] [G loss: 0] [VAE loss: 1.7361695766448975]\n",
      "520 [D loss: 0] [G loss: 0] [VAE loss: 1.8844877481460571]\n",
      "521 [D loss: 0] [G loss: 0] [VAE loss: 1.837674856185913]\n",
      "522 [D loss: 0] [G loss: 0] [VAE loss: 1.6821107864379883]\n",
      "523 [D loss: 0] [G loss: 0] [VAE loss: 1.8209383487701416]\n",
      "524 [D loss: 0] [G loss: 0] [VAE loss: 1.6641050577163696]\n",
      "525 [D loss: 0] [G loss: 0] [VAE loss: 1.7016291618347168]\n",
      "526 [D loss: 0] [G loss: 0] [VAE loss: 1.7025200128555298]\n",
      "527 [D loss: 0] [G loss: 0] [VAE loss: 1.6116491556167603]\n",
      "528 [D loss: 0] [G loss: 0] [VAE loss: 1.764098048210144]\n",
      "529 [D loss: 0] [G loss: 0] [VAE loss: 1.7299994230270386]\n",
      "530 [D loss: 0] [G loss: 0] [VAE loss: 1.8680163621902466]\n",
      "531 [D loss: 0] [G loss: 0] [VAE loss: 1.5676238536834717]\n",
      "532 [D loss: 0] [G loss: 0] [VAE loss: 1.6599888801574707]\n",
      "533 [D loss: 0] [G loss: 0] [VAE loss: 1.704904556274414]\n",
      "534 [D loss: 0] [G loss: 0] [VAE loss: 1.7824876308441162]\n",
      "535 [D loss: 0] [G loss: 0] [VAE loss: 1.7794554233551025]\n",
      "536 [D loss: 0] [G loss: 0] [VAE loss: 1.7105109691619873]\n",
      "537 [D loss: 0] [G loss: 0] [VAE loss: 1.860513687133789]\n",
      "538 [D loss: 0] [G loss: 0] [VAE loss: 1.6628462076187134]\n",
      "539 [D loss: 0] [G loss: 0] [VAE loss: 1.8872572183609009]\n",
      "540 [D loss: 0] [G loss: 0] [VAE loss: 1.8800923824310303]\n",
      "541 [D loss: 0] [G loss: 0] [VAE loss: 1.6922366619110107]\n",
      "542 [D loss: 0] [G loss: 0] [VAE loss: 1.5939521789550781]\n",
      "543 [D loss: 0] [G loss: 0] [VAE loss: 1.725050449371338]\n",
      "544 [D loss: 0] [G loss: 0] [VAE loss: 1.837687373161316]\n",
      "545 [D loss: 0] [G loss: 0] [VAE loss: 1.7426015138626099]\n",
      "546 [D loss: 0] [G loss: 0] [VAE loss: 1.7789013385772705]\n",
      "547 [D loss: 0] [G loss: 0] [VAE loss: 1.8077912330627441]\n",
      "548 [D loss: 0] [G loss: 0] [VAE loss: 1.7184747457504272]\n",
      "549 [D loss: 0] [G loss: 0] [VAE loss: 1.7859841585159302]\n",
      "550 [D loss: 0] [G loss: 0] [VAE loss: 1.9196603298187256]\n",
      "551 [D loss: 0] [G loss: 0] [VAE loss: 1.7358999252319336]\n",
      "552 [D loss: 0] [G loss: 0] [VAE loss: 1.7993032932281494]\n",
      "553 [D loss: 0] [G loss: 0] [VAE loss: 1.707871675491333]\n",
      "554 [D loss: 0] [G loss: 0] [VAE loss: 2.0141825675964355]\n",
      "555 [D loss: 0] [G loss: 0] [VAE loss: 1.7432259321212769]\n",
      "556 [D loss: 0] [G loss: 0] [VAE loss: 1.87729012966156]\n",
      "557 [D loss: 0] [G loss: 0] [VAE loss: 1.5753111839294434]\n",
      "558 [D loss: 0] [G loss: 0] [VAE loss: 1.7490599155426025]\n",
      "559 [D loss: 0] [G loss: 0] [VAE loss: 1.821097493171692]\n",
      "560 [D loss: 0] [G loss: 0] [VAE loss: 1.8158010244369507]\n",
      "561 [D loss: 0] [G loss: 0] [VAE loss: 1.9849140644073486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 [D loss: 0] [G loss: 0] [VAE loss: 1.6520304679870605]\n",
      "563 [D loss: 0] [G loss: 0] [VAE loss: 1.9994229078292847]\n",
      "564 [D loss: 0] [G loss: 0] [VAE loss: 1.6528490781784058]\n",
      "565 [D loss: 0] [G loss: 0] [VAE loss: 1.6775482892990112]\n",
      "566 [D loss: 0] [G loss: 0] [VAE loss: 1.7359588146209717]\n",
      "567 [D loss: 0] [G loss: 0] [VAE loss: 1.7059862613677979]\n",
      "568 [D loss: 0] [G loss: 0] [VAE loss: 1.5631632804870605]\n",
      "569 [D loss: 0] [G loss: 0] [VAE loss: 1.8528833389282227]\n",
      "570 [D loss: 0] [G loss: 0] [VAE loss: 1.859144687652588]\n",
      "571 [D loss: 0] [G loss: 0] [VAE loss: 1.6731691360473633]\n",
      "572 [D loss: 0] [G loss: 0] [VAE loss: 1.7262048721313477]\n",
      "573 [D loss: 0] [G loss: 0] [VAE loss: 1.975089192390442]\n",
      "574 [D loss: 0] [G loss: 0] [VAE loss: 1.8108642101287842]\n",
      "575 [D loss: 0] [G loss: 0] [VAE loss: 1.7133640050888062]\n",
      "576 [D loss: 0] [G loss: 0] [VAE loss: 1.7240711450576782]\n",
      "577 [D loss: 0] [G loss: 0] [VAE loss: 1.7169402837753296]\n",
      "578 [D loss: 0] [G loss: 0] [VAE loss: 1.7415703535079956]\n",
      "579 [D loss: 0] [G loss: 0] [VAE loss: 1.834255337715149]\n",
      "580 [D loss: 0] [G loss: 0] [VAE loss: 1.772526741027832]\n",
      "581 [D loss: 0] [G loss: 0] [VAE loss: 1.8997306823730469]\n",
      "582 [D loss: 0] [G loss: 0] [VAE loss: 1.9103373289108276]\n",
      "583 [D loss: 0] [G loss: 0] [VAE loss: 1.7356584072113037]\n",
      "584 [D loss: 0] [G loss: 0] [VAE loss: 1.8580409288406372]\n",
      "585 [D loss: 0] [G loss: 0] [VAE loss: 1.75841224193573]\n",
      "586 [D loss: 0] [G loss: 0] [VAE loss: 1.7575688362121582]\n",
      "587 [D loss: 0] [G loss: 0] [VAE loss: 1.733795404434204]\n",
      "588 [D loss: 0] [G loss: 0] [VAE loss: 1.9722909927368164]\n",
      "589 [D loss: 0] [G loss: 0] [VAE loss: 1.7666003704071045]\n",
      "590 [D loss: 0] [G loss: 0] [VAE loss: 1.831737995147705]\n",
      "591 [D loss: 0] [G loss: 0] [VAE loss: 1.947663426399231]\n",
      "592 [D loss: 0] [G loss: 0] [VAE loss: 2.022289752960205]\n",
      "593 [D loss: 0] [G loss: 0] [VAE loss: 1.77499258518219]\n",
      "594 [D loss: 0] [G loss: 0] [VAE loss: 1.944119930267334]\n",
      "595 [D loss: 0] [G loss: 0] [VAE loss: 1.7265571355819702]\n",
      "596 [D loss: 0] [G loss: 0] [VAE loss: 1.7326874732971191]\n",
      "597 [D loss: 0] [G loss: 0] [VAE loss: 1.7105430364608765]\n",
      "598 [D loss: 0] [G loss: 0] [VAE loss: 2.1765875816345215]\n",
      "599 [D loss: 0] [G loss: 0] [VAE loss: 1.8073662519454956]\n",
      "600 [D loss: 0] [G loss: 0] [VAE loss: 1.854083776473999]\n",
      "601 [D loss: 0] [G loss: 0] [VAE loss: 1.9348852634429932]\n",
      "602 [D loss: 0] [G loss: 0] [VAE loss: 1.9214575290679932]\n",
      "603 [D loss: 0] [G loss: 0] [VAE loss: 1.796383023262024]\n",
      "604 [D loss: 0] [G loss: 0] [VAE loss: 1.7208805084228516]\n",
      "605 [D loss: 0] [G loss: 0] [VAE loss: 1.7868943214416504]\n",
      "606 [D loss: 0] [G loss: 0] [VAE loss: 1.904443621635437]\n",
      "607 [D loss: 0] [G loss: 0] [VAE loss: 1.96506667137146]\n",
      "608 [D loss: 0] [G loss: 0] [VAE loss: 1.6811413764953613]\n",
      "609 [D loss: 0] [G loss: 0] [VAE loss: 1.7159875631332397]\n",
      "610 [D loss: 0] [G loss: 0] [VAE loss: 1.7682183980941772]\n",
      "611 [D loss: 0] [G loss: 0] [VAE loss: 1.713660717010498]\n",
      "612 [D loss: 0] [G loss: 0] [VAE loss: 1.7488617897033691]\n",
      "613 [D loss: 0] [G loss: 0] [VAE loss: 1.901491403579712]\n",
      "614 [D loss: 0] [G loss: 0] [VAE loss: 1.6978179216384888]\n",
      "615 [D loss: 0] [G loss: 0] [VAE loss: 1.7559502124786377]\n",
      "616 [D loss: 0] [G loss: 0] [VAE loss: 1.8576573133468628]\n",
      "617 [D loss: 0] [G loss: 0] [VAE loss: 1.8321176767349243]\n",
      "618 [D loss: 0] [G loss: 0] [VAE loss: 1.6610267162322998]\n",
      "619 [D loss: 0] [G loss: 0] [VAE loss: 1.648801326751709]\n",
      "620 [D loss: 0] [G loss: 0] [VAE loss: 1.8058536052703857]\n",
      "621 [D loss: 0] [G loss: 0] [VAE loss: 1.8741506338119507]\n",
      "622 [D loss: 0] [G loss: 0] [VAE loss: 1.8090598583221436]\n",
      "623 [D loss: 0] [G loss: 0] [VAE loss: 1.7697868347167969]\n",
      "624 [D loss: 0] [G loss: 0] [VAE loss: 1.820865273475647]\n",
      "625 [D loss: 0] [G loss: 0] [VAE loss: 1.8115270137786865]\n",
      "626 [D loss: 0] [G loss: 0] [VAE loss: 1.681349515914917]\n",
      "627 [D loss: 0] [G loss: 0] [VAE loss: 1.6447547674179077]\n",
      "628 [D loss: 0] [G loss: 0] [VAE loss: 1.7389564514160156]\n",
      "629 [D loss: 0] [G loss: 0] [VAE loss: 1.7621984481811523]\n",
      "630 [D loss: 0] [G loss: 0] [VAE loss: 1.8291596174240112]\n",
      "631 [D loss: 0] [G loss: 0] [VAE loss: 1.7052805423736572]\n",
      "632 [D loss: 0] [G loss: 0] [VAE loss: 1.7780849933624268]\n",
      "633 [D loss: 0] [G loss: 0] [VAE loss: 1.8416147232055664]\n",
      "634 [D loss: 0] [G loss: 0] [VAE loss: 1.6425611972808838]\n",
      "635 [D loss: 0] [G loss: 0] [VAE loss: 1.779937505722046]\n",
      "636 [D loss: 0] [G loss: 0] [VAE loss: 1.9031482934951782]\n",
      "637 [D loss: 0] [G loss: 0] [VAE loss: 1.7857550382614136]\n",
      "638 [D loss: 0] [G loss: 0] [VAE loss: 1.7271437644958496]\n",
      "639 [D loss: 0] [G loss: 0] [VAE loss: 1.6827731132507324]\n",
      "640 [D loss: 0] [G loss: 0] [VAE loss: 1.7426255941390991]\n",
      "641 [D loss: 0] [G loss: 0] [VAE loss: 1.6716256141662598]\n",
      "642 [D loss: 0] [G loss: 0] [VAE loss: 1.8736543655395508]\n",
      "643 [D loss: 0] [G loss: 0] [VAE loss: 1.853804588317871]\n",
      "644 [D loss: 0] [G loss: 0] [VAE loss: 1.8456645011901855]\n",
      "645 [D loss: 0] [G loss: 0] [VAE loss: 1.686956763267517]\n",
      "646 [D loss: 0] [G loss: 0] [VAE loss: 1.785690426826477]\n",
      "647 [D loss: 0] [G loss: 0] [VAE loss: 1.9407835006713867]\n",
      "648 [D loss: 0] [G loss: 0] [VAE loss: 1.8818573951721191]\n",
      "649 [D loss: 0] [G loss: 0] [VAE loss: 1.7966874837875366]\n",
      "650 [D loss: 0] [G loss: 0] [VAE loss: 1.946909785270691]\n",
      "651 [D loss: 0] [G loss: 0] [VAE loss: 1.8020401000976562]\n",
      "652 [D loss: 0] [G loss: 0] [VAE loss: 1.7014760971069336]\n",
      "653 [D loss: 0] [G loss: 0] [VAE loss: 1.9030952453613281]\n",
      "654 [D loss: 0] [G loss: 0] [VAE loss: 1.7925106287002563]\n",
      "655 [D loss: 0] [G loss: 0] [VAE loss: 1.7720203399658203]\n",
      "656 [D loss: 0] [G loss: 0] [VAE loss: 1.7161650657653809]\n",
      "657 [D loss: 0] [G loss: 0] [VAE loss: 1.7369661331176758]\n",
      "658 [D loss: 0] [G loss: 0] [VAE loss: 1.753617286682129]\n",
      "659 [D loss: 0] [G loss: 0] [VAE loss: 1.7061564922332764]\n",
      "660 [D loss: 0] [G loss: 0] [VAE loss: 1.7326725721359253]\n",
      "661 [D loss: 0] [G loss: 0] [VAE loss: 1.7209160327911377]\n",
      "662 [D loss: 0] [G loss: 0] [VAE loss: 2.038940906524658]\n",
      "663 [D loss: 0] [G loss: 0] [VAE loss: 1.6955965757369995]\n",
      "664 [D loss: 0] [G loss: 0] [VAE loss: 1.7739205360412598]\n",
      "665 [D loss: 0] [G loss: 0] [VAE loss: 1.6469230651855469]\n",
      "666 [D loss: 0] [G loss: 0] [VAE loss: 1.8756687641143799]\n",
      "667 [D loss: 0] [G loss: 0] [VAE loss: 1.7975099086761475]\n",
      "668 [D loss: 0] [G loss: 0] [VAE loss: 1.7747098207473755]\n",
      "669 [D loss: 0] [G loss: 0] [VAE loss: 1.9564785957336426]\n",
      "670 [D loss: 0] [G loss: 0] [VAE loss: 1.7309465408325195]\n",
      "671 [D loss: 0] [G loss: 0] [VAE loss: 1.8794288635253906]\n",
      "672 [D loss: 0] [G loss: 0] [VAE loss: 1.7900235652923584]\n",
      "673 [D loss: 0] [G loss: 0] [VAE loss: 1.6844507455825806]\n",
      "674 [D loss: 0] [G loss: 0] [VAE loss: 1.8286194801330566]\n",
      "675 [D loss: 0] [G loss: 0] [VAE loss: 1.746617078781128]\n",
      "676 [D loss: 0] [G loss: 0] [VAE loss: 1.6615173816680908]\n",
      "677 [D loss: 0] [G loss: 0] [VAE loss: 1.9392629861831665]\n",
      "678 [D loss: 0] [G loss: 0] [VAE loss: 1.786428689956665]\n",
      "679 [D loss: 0] [G loss: 0] [VAE loss: 1.7599883079528809]\n",
      "680 [D loss: 0] [G loss: 0] [VAE loss: 1.6800049543380737]\n",
      "681 [D loss: 0] [G loss: 0] [VAE loss: 1.6765682697296143]\n",
      "682 [D loss: 0] [G loss: 0] [VAE loss: 1.7679184675216675]\n",
      "683 [D loss: 0] [G loss: 0] [VAE loss: 1.7680683135986328]\n",
      "684 [D loss: 0] [G loss: 0] [VAE loss: 2.086332321166992]\n",
      "685 [D loss: 0] [G loss: 0] [VAE loss: 1.9193212985992432]\n",
      "686 [D loss: 0] [G loss: 0] [VAE loss: 1.7427241802215576]\n",
      "687 [D loss: 0] [G loss: 0] [VAE loss: 1.887202262878418]\n",
      "688 [D loss: 0] [G loss: 0] [VAE loss: 1.7698687314987183]\n",
      "689 [D loss: 0] [G loss: 0] [VAE loss: 1.9011116027832031]\n",
      "690 [D loss: 0] [G loss: 0] [VAE loss: 1.8643579483032227]\n",
      "691 [D loss: 0] [G loss: 0] [VAE loss: 1.639249563217163]\n",
      "692 [D loss: 0] [G loss: 0] [VAE loss: 1.8690062761306763]\n",
      "693 [D loss: 0] [G loss: 0] [VAE loss: 1.687705159187317]\n",
      "694 [D loss: 0] [G loss: 0] [VAE loss: 1.7341644763946533]\n",
      "695 [D loss: 0] [G loss: 0] [VAE loss: 1.7101569175720215]\n",
      "696 [D loss: 0] [G loss: 0] [VAE loss: 1.8377498388290405]\n",
      "697 [D loss: 0] [G loss: 0] [VAE loss: 1.7889642715454102]\n",
      "698 [D loss: 0] [G loss: 0] [VAE loss: 1.9520654678344727]\n",
      "699 [D loss: 0] [G loss: 0] [VAE loss: 1.7093250751495361]\n",
      "700 [D loss: 0] [G loss: 0] [VAE loss: 1.8500847816467285]\n",
      "701 [D loss: 0] [G loss: 0] [VAE loss: 1.7804065942764282]\n",
      "702 [D loss: 0] [G loss: 0] [VAE loss: 1.8566920757293701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703 [D loss: 0] [G loss: 0] [VAE loss: 1.9775158166885376]\n",
      "704 [D loss: 0] [G loss: 0] [VAE loss: 1.7631022930145264]\n",
      "705 [D loss: 0] [G loss: 0] [VAE loss: 1.7199246883392334]\n",
      "706 [D loss: 0] [G loss: 0] [VAE loss: 1.820326566696167]\n",
      "707 [D loss: 0] [G loss: 0] [VAE loss: 1.9587379693984985]\n",
      "708 [D loss: 0] [G loss: 0] [VAE loss: 1.7515184879302979]\n",
      "709 [D loss: 0] [G loss: 0] [VAE loss: 1.8522907495498657]\n",
      "710 [D loss: 0] [G loss: 0] [VAE loss: 1.7191104888916016]\n",
      "711 [D loss: 0] [G loss: 0] [VAE loss: 1.9159820079803467]\n",
      "712 [D loss: 0] [G loss: 0] [VAE loss: 1.7425020933151245]\n",
      "713 [D loss: 0] [G loss: 0] [VAE loss: 2.04915714263916]\n",
      "714 [D loss: 0] [G loss: 0] [VAE loss: 1.9309613704681396]\n",
      "715 [D loss: 0] [G loss: 0] [VAE loss: 1.588740587234497]\n",
      "716 [D loss: 0] [G loss: 0] [VAE loss: 1.6562378406524658]\n",
      "717 [D loss: 0] [G loss: 0] [VAE loss: 1.80715012550354]\n",
      "718 [D loss: 0] [G loss: 0] [VAE loss: 1.9509779214859009]\n",
      "719 [D loss: 0] [G loss: 0] [VAE loss: 1.9197413921356201]\n",
      "720 [D loss: 0] [G loss: 0] [VAE loss: 1.7587480545043945]\n",
      "721 [D loss: 0] [G loss: 0] [VAE loss: 1.70346999168396]\n",
      "722 [D loss: 0] [G loss: 0] [VAE loss: 1.8881633281707764]\n",
      "723 [D loss: 0] [G loss: 0] [VAE loss: 1.7765531539916992]\n",
      "724 [D loss: 0] [G loss: 0] [VAE loss: 1.79022216796875]\n",
      "725 [D loss: 0] [G loss: 0] [VAE loss: 1.7622079849243164]\n",
      "726 [D loss: 0] [G loss: 0] [VAE loss: 1.8554140329360962]\n",
      "727 [D loss: 0] [G loss: 0] [VAE loss: 1.7274348735809326]\n",
      "728 [D loss: 0] [G loss: 0] [VAE loss: 1.6953544616699219]\n",
      "729 [D loss: 0] [G loss: 0] [VAE loss: 1.8501403331756592]\n",
      "730 [D loss: 0] [G loss: 0] [VAE loss: 1.9146783351898193]\n",
      "731 [D loss: 0] [G loss: 0] [VAE loss: 1.8383854627609253]\n",
      "732 [D loss: 0] [G loss: 0] [VAE loss: 1.950710654258728]\n",
      "733 [D loss: 0] [G loss: 0] [VAE loss: 1.7763108015060425]\n",
      "734 [D loss: 0] [G loss: 0] [VAE loss: 1.8520885705947876]\n",
      "735 [D loss: 0] [G loss: 0] [VAE loss: 1.739335536956787]\n",
      "736 [D loss: 0] [G loss: 0] [VAE loss: 1.7456215620040894]\n",
      "737 [D loss: 0] [G loss: 0] [VAE loss: 1.6969656944274902]\n",
      "738 [D loss: 0] [G loss: 0] [VAE loss: 1.8840289115905762]\n",
      "739 [D loss: 0] [G loss: 0] [VAE loss: 2.0503077507019043]\n",
      "740 [D loss: 0] [G loss: 0] [VAE loss: 1.8512786626815796]\n",
      "741 [D loss: 0] [G loss: 0] [VAE loss: 1.8272294998168945]\n",
      "742 [D loss: 0] [G loss: 0] [VAE loss: 1.7548484802246094]\n",
      "743 [D loss: 0] [G loss: 0] [VAE loss: 1.748476505279541]\n",
      "744 [D loss: 0] [G loss: 0] [VAE loss: 1.6535935401916504]\n",
      "745 [D loss: 0] [G loss: 0] [VAE loss: 1.612260103225708]\n",
      "746 [D loss: 0] [G loss: 0] [VAE loss: 1.7924377918243408]\n",
      "747 [D loss: 0] [G loss: 0] [VAE loss: 1.8025648593902588]\n",
      "748 [D loss: 0] [G loss: 0] [VAE loss: 1.7044583559036255]\n",
      "749 [D loss: 0] [G loss: 0] [VAE loss: 1.798053503036499]\n",
      "750 [D loss: 0] [G loss: 0] [VAE loss: 1.7364352941513062]\n",
      "751 [D loss: 0] [G loss: 0] [VAE loss: 1.582613468170166]\n",
      "752 [D loss: 0] [G loss: 0] [VAE loss: 1.819256067276001]\n",
      "753 [D loss: 0] [G loss: 0] [VAE loss: 1.5839444398880005]\n",
      "754 [D loss: 0] [G loss: 0] [VAE loss: 1.5635945796966553]\n",
      "755 [D loss: 0] [G loss: 0] [VAE loss: 1.896456241607666]\n",
      "756 [D loss: 0] [G loss: 0] [VAE loss: 1.8269286155700684]\n",
      "757 [D loss: 0] [G loss: 0] [VAE loss: 2.0734171867370605]\n",
      "758 [D loss: 0] [G loss: 0] [VAE loss: 1.6503114700317383]\n",
      "759 [D loss: 0] [G loss: 0] [VAE loss: 1.7753608226776123]\n",
      "760 [D loss: 0] [G loss: 0] [VAE loss: 1.894647479057312]\n",
      "761 [D loss: 0] [G loss: 0] [VAE loss: 1.8856136798858643]\n",
      "762 [D loss: 0] [G loss: 0] [VAE loss: 1.6839606761932373]\n",
      "763 [D loss: 0] [G loss: 0] [VAE loss: 1.6526716947555542]\n",
      "764 [D loss: 0] [G loss: 0] [VAE loss: 1.793370246887207]\n",
      "765 [D loss: 0] [G loss: 0] [VAE loss: 1.6877412796020508]\n",
      "766 [D loss: 0] [G loss: 0] [VAE loss: 1.618358850479126]\n",
      "767 [D loss: 0] [G loss: 0] [VAE loss: 1.7980064153671265]\n",
      "768 [D loss: 0] [G loss: 0] [VAE loss: 1.874390959739685]\n",
      "769 [D loss: 0] [G loss: 0] [VAE loss: 1.8410046100616455]\n",
      "770 [D loss: 0] [G loss: 0] [VAE loss: 1.6089526414871216]\n",
      "771 [D loss: 0] [G loss: 0] [VAE loss: 1.7051243782043457]\n",
      "772 [D loss: 0] [G loss: 0] [VAE loss: 1.7354354858398438]\n",
      "773 [D loss: 0] [G loss: 0] [VAE loss: 1.7779515981674194]\n",
      "774 [D loss: 0] [G loss: 0] [VAE loss: 1.7443487644195557]\n",
      "775 [D loss: 0] [G loss: 0] [VAE loss: 1.7239971160888672]\n",
      "776 [D loss: 0] [G loss: 0] [VAE loss: 1.7968690395355225]\n",
      "777 [D loss: 0] [G loss: 0] [VAE loss: 1.684751272201538]\n",
      "778 [D loss: 0] [G loss: 0] [VAE loss: 1.75675630569458]\n",
      "779 [D loss: 0] [G loss: 0] [VAE loss: 1.5837386846542358]\n",
      "780 [D loss: 0] [G loss: 0] [VAE loss: 1.874926209449768]\n",
      "781 [D loss: 0] [G loss: 0] [VAE loss: 1.7573285102844238]\n",
      "782 [D loss: 0] [G loss: 0] [VAE loss: 1.7721562385559082]\n",
      "783 [D loss: 0] [G loss: 0] [VAE loss: 1.84273099899292]\n",
      "784 [D loss: 0] [G loss: 0] [VAE loss: 1.8296133279800415]\n",
      "785 [D loss: 0] [G loss: 0] [VAE loss: 1.8308202028274536]\n",
      "786 [D loss: 0] [G loss: 0] [VAE loss: 1.8293815851211548]\n",
      "787 [D loss: 0] [G loss: 0] [VAE loss: 1.6277079582214355]\n",
      "788 [D loss: 0] [G loss: 0] [VAE loss: 1.6598381996154785]\n",
      "789 [D loss: 0] [G loss: 0] [VAE loss: 1.6564648151397705]\n",
      "790 [D loss: 0] [G loss: 0] [VAE loss: 1.6330008506774902]\n",
      "791 [D loss: 0] [G loss: 0] [VAE loss: 1.6466741561889648]\n",
      "792 [D loss: 0] [G loss: 0] [VAE loss: 1.7130786180496216]\n",
      "793 [D loss: 0] [G loss: 0] [VAE loss: 1.9916404485702515]\n",
      "794 [D loss: 0] [G loss: 0] [VAE loss: 1.8274015188217163]\n",
      "795 [D loss: 0] [G loss: 0] [VAE loss: 1.729910135269165]\n",
      "796 [D loss: 0] [G loss: 0] [VAE loss: 1.9194650650024414]\n",
      "797 [D loss: 0] [G loss: 0] [VAE loss: 1.9828102588653564]\n",
      "798 [D loss: 0] [G loss: 0] [VAE loss: 1.8764495849609375]\n",
      "799 [D loss: 0] [G loss: 0] [VAE loss: 1.8267155885696411]\n",
      "800 [D loss: 0] [G loss: 0] [VAE loss: 1.7082979679107666]\n",
      "801 [D loss: 0] [G loss: 0] [VAE loss: 1.7622628211975098]\n",
      "802 [D loss: 0] [G loss: 0] [VAE loss: 1.7013146877288818]\n",
      "803 [D loss: 0] [G loss: 0] [VAE loss: 1.6704134941101074]\n",
      "804 [D loss: 0] [G loss: 0] [VAE loss: 1.8488614559173584]\n",
      "805 [D loss: 0] [G loss: 0] [VAE loss: 1.8844447135925293]\n",
      "806 [D loss: 0] [G loss: 0] [VAE loss: 1.6628153324127197]\n",
      "807 [D loss: 0] [G loss: 0] [VAE loss: 1.7224655151367188]\n",
      "808 [D loss: 0] [G loss: 0] [VAE loss: 1.7062216997146606]\n",
      "809 [D loss: 0] [G loss: 0] [VAE loss: 1.8629822731018066]\n",
      "810 [D loss: 0] [G loss: 0] [VAE loss: 1.6769471168518066]\n",
      "811 [D loss: 0] [G loss: 0] [VAE loss: 1.758143424987793]\n",
      "812 [D loss: 0] [G loss: 0] [VAE loss: 1.8239755630493164]\n",
      "813 [D loss: 0] [G loss: 0] [VAE loss: 1.717399001121521]\n",
      "814 [D loss: 0] [G loss: 0] [VAE loss: 1.9101130962371826]\n",
      "815 [D loss: 0] [G loss: 0] [VAE loss: 1.7751688957214355]\n",
      "816 [D loss: 0] [G loss: 0] [VAE loss: 1.7385934591293335]\n",
      "817 [D loss: 0] [G loss: 0] [VAE loss: 1.7449231147766113]\n",
      "818 [D loss: 0] [G loss: 0] [VAE loss: 1.8290519714355469]\n",
      "819 [D loss: 0] [G loss: 0] [VAE loss: 1.8366788625717163]\n",
      "820 [D loss: 0] [G loss: 0] [VAE loss: 1.7805159091949463]\n",
      "821 [D loss: 0] [G loss: 0] [VAE loss: 1.6230124235153198]\n",
      "822 [D loss: 0] [G loss: 0] [VAE loss: 1.7908935546875]\n",
      "823 [D loss: 0] [G loss: 0] [VAE loss: 2.1943445205688477]\n",
      "824 [D loss: 0] [G loss: 0] [VAE loss: 1.7715070247650146]\n",
      "825 [D loss: 0] [G loss: 0] [VAE loss: 1.745897889137268]\n",
      "826 [D loss: 0] [G loss: 0] [VAE loss: 1.7370781898498535]\n",
      "827 [D loss: 0] [G loss: 0] [VAE loss: 1.656733512878418]\n",
      "828 [D loss: 0] [G loss: 0] [VAE loss: 1.7867697477340698]\n",
      "829 [D loss: 0] [G loss: 0] [VAE loss: 1.7856206893920898]\n",
      "830 [D loss: 0] [G loss: 0] [VAE loss: 1.7224096059799194]\n",
      "831 [D loss: 0] [G loss: 0] [VAE loss: 1.8024351596832275]\n",
      "832 [D loss: 0] [G loss: 0] [VAE loss: 1.8602299690246582]\n",
      "833 [D loss: 0] [G loss: 0] [VAE loss: 1.7069196701049805]\n",
      "834 [D loss: 0] [G loss: 0] [VAE loss: 1.7526397705078125]\n",
      "835 [D loss: 0] [G loss: 0] [VAE loss: 1.7320239543914795]\n",
      "836 [D loss: 0] [G loss: 0] [VAE loss: 1.7881766557693481]\n",
      "837 [D loss: 0] [G loss: 0] [VAE loss: 1.951804757118225]\n",
      "838 [D loss: 0] [G loss: 0] [VAE loss: 1.7779183387756348]\n",
      "839 [D loss: 0] [G loss: 0] [VAE loss: 1.7193810939788818]\n",
      "840 [D loss: 0] [G loss: 0] [VAE loss: 1.6954673528671265]\n",
      "841 [D loss: 0] [G loss: 0] [VAE loss: 1.7113542556762695]\n",
      "842 [D loss: 0] [G loss: 0] [VAE loss: 1.6893188953399658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843 [D loss: 0] [G loss: 0] [VAE loss: 1.766756534576416]\n",
      "844 [D loss: 0] [G loss: 0] [VAE loss: 1.9468510150909424]\n",
      "845 [D loss: 0] [G loss: 0] [VAE loss: 1.7166764736175537]\n",
      "846 [D loss: 0] [G loss: 0] [VAE loss: 1.7455112934112549]\n",
      "847 [D loss: 0] [G loss: 0] [VAE loss: 1.6817350387573242]\n",
      "848 [D loss: 0] [G loss: 0] [VAE loss: 1.8074445724487305]\n",
      "849 [D loss: 0] [G loss: 0] [VAE loss: 1.5892208814620972]\n",
      "850 [D loss: 0] [G loss: 0] [VAE loss: 1.8930400609970093]\n",
      "851 [D loss: 0] [G loss: 0] [VAE loss: 1.8802918195724487]\n",
      "852 [D loss: 0] [G loss: 0] [VAE loss: 1.8043479919433594]\n",
      "853 [D loss: 0] [G loss: 0] [VAE loss: 1.8108775615692139]\n",
      "854 [D loss: 0] [G loss: 0] [VAE loss: 1.7508976459503174]\n",
      "855 [D loss: 0] [G loss: 0] [VAE loss: 1.856158971786499]\n",
      "856 [D loss: 0] [G loss: 0] [VAE loss: 1.8097939491271973]\n",
      "857 [D loss: 0] [G loss: 0] [VAE loss: 1.6915290355682373]\n",
      "858 [D loss: 0] [G loss: 0] [VAE loss: 1.7526662349700928]\n",
      "859 [D loss: 0] [G loss: 0] [VAE loss: 1.747952938079834]\n",
      "860 [D loss: 0] [G loss: 0] [VAE loss: 1.8319145441055298]\n",
      "861 [D loss: 0] [G loss: 0] [VAE loss: 1.7550737857818604]\n",
      "862 [D loss: 0] [G loss: 0] [VAE loss: 1.625075340270996]\n",
      "863 [D loss: 0] [G loss: 0] [VAE loss: 1.767762541770935]\n",
      "864 [D loss: 0] [G loss: 0] [VAE loss: 1.8050475120544434]\n",
      "865 [D loss: 0] [G loss: 0] [VAE loss: 1.8875064849853516]\n",
      "866 [D loss: 0] [G loss: 0] [VAE loss: 1.7617853879928589]\n",
      "867 [D loss: 0] [G loss: 0] [VAE loss: 1.7001410722732544]\n",
      "868 [D loss: 0] [G loss: 0] [VAE loss: 1.6987141370773315]\n",
      "869 [D loss: 0] [G loss: 0] [VAE loss: 1.758538007736206]\n",
      "870 [D loss: 0] [G loss: 0] [VAE loss: 1.9166417121887207]\n",
      "871 [D loss: 0] [G loss: 0] [VAE loss: 1.6638634204864502]\n",
      "872 [D loss: 0] [G loss: 0] [VAE loss: 1.8332804441452026]\n",
      "873 [D loss: 0] [G loss: 0] [VAE loss: 1.6581052541732788]\n",
      "874 [D loss: 0] [G loss: 0] [VAE loss: 1.771449089050293]\n",
      "875 [D loss: 0] [G loss: 0] [VAE loss: 1.67327880859375]\n",
      "876 [D loss: 0] [G loss: 0] [VAE loss: 1.7006481885910034]\n",
      "877 [D loss: 0] [G loss: 0] [VAE loss: 1.9024925231933594]\n",
      "878 [D loss: 0] [G loss: 0] [VAE loss: 1.5509039163589478]\n",
      "879 [D loss: 0] [G loss: 0] [VAE loss: 1.6876220703125]\n",
      "880 [D loss: 0] [G loss: 0] [VAE loss: 1.781695008277893]\n",
      "881 [D loss: 0] [G loss: 0] [VAE loss: 1.9757169485092163]\n",
      "882 [D loss: 0] [G loss: 0] [VAE loss: 1.7597599029541016]\n",
      "883 [D loss: 0] [G loss: 0] [VAE loss: 1.7157402038574219]\n",
      "884 [D loss: 0] [G loss: 0] [VAE loss: 1.7775371074676514]\n",
      "885 [D loss: 0] [G loss: 0] [VAE loss: 1.9322506189346313]\n",
      "886 [D loss: 0] [G loss: 0] [VAE loss: 1.6778981685638428]\n",
      "887 [D loss: 0] [G loss: 0] [VAE loss: 1.924900770187378]\n",
      "888 [D loss: 0] [G loss: 0] [VAE loss: 1.6910111904144287]\n",
      "889 [D loss: 0] [G loss: 0] [VAE loss: 1.712118148803711]\n",
      "890 [D loss: 0] [G loss: 0] [VAE loss: 1.7401036024093628]\n",
      "891 [D loss: 0] [G loss: 0] [VAE loss: 1.8570218086242676]\n",
      "892 [D loss: 0] [G loss: 0] [VAE loss: 1.86358642578125]\n",
      "893 [D loss: 0] [G loss: 0] [VAE loss: 1.8452246189117432]\n",
      "894 [D loss: 0] [G loss: 0] [VAE loss: 1.7306631803512573]\n",
      "895 [D loss: 0] [G loss: 0] [VAE loss: 1.857263207435608]\n",
      "896 [D loss: 0] [G loss: 0] [VAE loss: 1.7151477336883545]\n",
      "897 [D loss: 0] [G loss: 0] [VAE loss: 1.7715317010879517]\n",
      "898 [D loss: 0] [G loss: 0] [VAE loss: 1.8678314685821533]\n",
      "899 [D loss: 0] [G loss: 0] [VAE loss: 1.8941377401351929]\n",
      "900 [D loss: 0] [G loss: 0] [VAE loss: 1.8053803443908691]\n",
      "901 [D loss: 0] [G loss: 0] [VAE loss: 1.9610621929168701]\n",
      "902 [D loss: 0] [G loss: 0] [VAE loss: 1.8239905834197998]\n",
      "903 [D loss: 0] [G loss: 0] [VAE loss: 1.8462951183319092]\n",
      "904 [D loss: 0] [G loss: 0] [VAE loss: 1.8021214008331299]\n",
      "905 [D loss: 0] [G loss: 0] [VAE loss: 2.036278009414673]\n",
      "906 [D loss: 0] [G loss: 0] [VAE loss: 1.7390637397766113]\n",
      "907 [D loss: 0] [G loss: 0] [VAE loss: 1.717918038368225]\n",
      "908 [D loss: 0] [G loss: 0] [VAE loss: 1.7737139463424683]\n",
      "909 [D loss: 0] [G loss: 0] [VAE loss: 1.772461175918579]\n",
      "910 [D loss: 0] [G loss: 0] [VAE loss: 1.726393222808838]\n",
      "911 [D loss: 0] [G loss: 0] [VAE loss: 1.8178730010986328]\n",
      "912 [D loss: 0] [G loss: 0] [VAE loss: 1.7219243049621582]\n",
      "913 [D loss: 0] [G loss: 0] [VAE loss: 1.7240285873413086]\n",
      "914 [D loss: 0] [G loss: 0] [VAE loss: 1.914770483970642]\n",
      "915 [D loss: 0] [G loss: 0] [VAE loss: 1.7665108442306519]\n",
      "916 [D loss: 0] [G loss: 0] [VAE loss: 1.7797173261642456]\n",
      "917 [D loss: 0] [G loss: 0] [VAE loss: 1.8105547428131104]\n",
      "918 [D loss: 0] [G loss: 0] [VAE loss: 1.748159408569336]\n",
      "919 [D loss: 0] [G loss: 0] [VAE loss: 1.7093580961227417]\n",
      "920 [D loss: 0] [G loss: 0] [VAE loss: 1.6238774061203003]\n",
      "921 [D loss: 0] [G loss: 0] [VAE loss: 1.6625314950942993]\n",
      "922 [D loss: 0] [G loss: 0] [VAE loss: 1.792283296585083]\n",
      "923 [D loss: 0] [G loss: 0] [VAE loss: 1.834727168083191]\n",
      "924 [D loss: 0] [G loss: 0] [VAE loss: 1.7496254444122314]\n",
      "925 [D loss: 0] [G loss: 0] [VAE loss: 1.7591490745544434]\n",
      "926 [D loss: 0] [G loss: 0] [VAE loss: 1.7918927669525146]\n",
      "927 [D loss: 0] [G loss: 0] [VAE loss: 1.6739251613616943]\n",
      "928 [D loss: 0] [G loss: 0] [VAE loss: 1.7493555545806885]\n",
      "929 [D loss: 0] [G loss: 0] [VAE loss: 1.7614638805389404]\n",
      "930 [D loss: 0] [G loss: 0] [VAE loss: 1.7822532653808594]\n",
      "931 [D loss: 0] [G loss: 0] [VAE loss: 1.9790468215942383]\n",
      "932 [D loss: 0] [G loss: 0] [VAE loss: 1.804090142250061]\n",
      "933 [D loss: 0] [G loss: 0] [VAE loss: 1.867143154144287]\n",
      "934 [D loss: 0] [G loss: 0] [VAE loss: 1.6911500692367554]\n",
      "935 [D loss: 0] [G loss: 0] [VAE loss: 1.6852049827575684]\n",
      "936 [D loss: 0] [G loss: 0] [VAE loss: 1.646005630493164]\n",
      "937 [D loss: 0] [G loss: 0] [VAE loss: 1.633482813835144]\n",
      "938 [D loss: 0] [G loss: 0] [VAE loss: 2.005523204803467]\n",
      "939 [D loss: 0] [G loss: 0] [VAE loss: 1.915722131729126]\n",
      "940 [D loss: 0] [G loss: 0] [VAE loss: 1.9298248291015625]\n",
      "941 [D loss: 0] [G loss: 0] [VAE loss: 1.8417952060699463]\n",
      "942 [D loss: 0] [G loss: 0] [VAE loss: 1.8581573963165283]\n",
      "943 [D loss: 0] [G loss: 0] [VAE loss: 1.9601320028305054]\n",
      "944 [D loss: 0] [G loss: 0] [VAE loss: 1.896269679069519]\n",
      "945 [D loss: 0] [G loss: 0] [VAE loss: 1.5726810693740845]\n",
      "946 [D loss: 0] [G loss: 0] [VAE loss: 1.8250244855880737]\n",
      "947 [D loss: 0] [G loss: 0] [VAE loss: 1.6131618022918701]\n",
      "948 [D loss: 0] [G loss: 0] [VAE loss: 1.7356058359146118]\n",
      "949 [D loss: 0] [G loss: 0] [VAE loss: 1.7067548036575317]\n",
      "950 [D loss: 0] [G loss: 0] [VAE loss: 1.952857494354248]\n",
      "951 [D loss: 0] [G loss: 0] [VAE loss: 1.6649656295776367]\n",
      "952 [D loss: 0] [G loss: 0] [VAE loss: 1.6830005645751953]\n",
      "953 [D loss: 0] [G loss: 0] [VAE loss: 1.9093526601791382]\n",
      "954 [D loss: 0] [G loss: 0] [VAE loss: 1.8078070878982544]\n",
      "955 [D loss: 0] [G loss: 0] [VAE loss: 1.777066946029663]\n",
      "956 [D loss: 0] [G loss: 0] [VAE loss: 1.9304457902908325]\n",
      "957 [D loss: 0] [G loss: 0] [VAE loss: 1.7134712934494019]\n",
      "958 [D loss: 0] [G loss: 0] [VAE loss: 1.7779128551483154]\n",
      "959 [D loss: 0] [G loss: 0] [VAE loss: 1.7539855241775513]\n",
      "960 [D loss: 0] [G loss: 0] [VAE loss: 1.7039623260498047]\n",
      "961 [D loss: 0] [G loss: 0] [VAE loss: 1.6834603548049927]\n",
      "962 [D loss: 0] [G loss: 0] [VAE loss: 1.7520350217819214]\n",
      "963 [D loss: 0] [G loss: 0] [VAE loss: 1.6282577514648438]\n",
      "964 [D loss: 0] [G loss: 0] [VAE loss: 1.722052812576294]\n",
      "965 [D loss: 0] [G loss: 0] [VAE loss: 1.8680912256240845]\n",
      "966 [D loss: 0] [G loss: 0] [VAE loss: 1.7879970073699951]\n",
      "967 [D loss: 0] [G loss: 0] [VAE loss: 1.8611853122711182]\n",
      "968 [D loss: 0] [G loss: 0] [VAE loss: 1.695613145828247]\n",
      "969 [D loss: 0] [G loss: 0] [VAE loss: 1.950363278388977]\n",
      "970 [D loss: 0] [G loss: 0] [VAE loss: 1.7263377904891968]\n",
      "971 [D loss: 0] [G loss: 0] [VAE loss: 1.7469587326049805]\n",
      "972 [D loss: 0] [G loss: 0] [VAE loss: 1.9401652812957764]\n",
      "973 [D loss: 0] [G loss: 0] [VAE loss: 1.634279727935791]\n",
      "974 [D loss: 0] [G loss: 0] [VAE loss: 1.7166545391082764]\n",
      "975 [D loss: 0] [G loss: 0] [VAE loss: 1.841552734375]\n",
      "976 [D loss: 0] [G loss: 0] [VAE loss: 1.800450086593628]\n",
      "977 [D loss: 0] [G loss: 0] [VAE loss: 1.6945652961730957]\n",
      "978 [D loss: 0] [G loss: 0] [VAE loss: 1.8300162553787231]\n",
      "979 [D loss: 0] [G loss: 0] [VAE loss: 1.7757233381271362]\n",
      "980 [D loss: 0] [G loss: 0] [VAE loss: 1.7555598020553589]\n",
      "981 [D loss: 0] [G loss: 0] [VAE loss: 1.8455798625946045]\n",
      "982 [D loss: 0] [G loss: 0] [VAE loss: 1.8970754146575928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983 [D loss: 0] [G loss: 0] [VAE loss: 1.740311622619629]\n",
      "984 [D loss: 0] [G loss: 0] [VAE loss: 1.7174328565597534]\n",
      "985 [D loss: 0] [G loss: 0] [VAE loss: 1.7369811534881592]\n",
      "986 [D loss: 0] [G loss: 0] [VAE loss: 1.8811612129211426]\n",
      "987 [D loss: 0] [G loss: 0] [VAE loss: 1.8053292036056519]\n",
      "988 [D loss: 0] [G loss: 0] [VAE loss: 1.8256980180740356]\n",
      "989 [D loss: 0] [G loss: 0] [VAE loss: 1.9744288921356201]\n",
      "990 [D loss: 0] [G loss: 0] [VAE loss: 1.6493171453475952]\n",
      "991 [D loss: 0] [G loss: 0] [VAE loss: 1.810096263885498]\n",
      "992 [D loss: 0] [G loss: 0] [VAE loss: 1.7704672813415527]\n",
      "993 [D loss: 0] [G loss: 0] [VAE loss: 1.863155484199524]\n",
      "994 [D loss: 0] [G loss: 0] [VAE loss: 1.7438347339630127]\n",
      "995 [D loss: 0] [G loss: 0] [VAE loss: 1.6735384464263916]\n",
      "996 [D loss: 0] [G loss: 0] [VAE loss: 1.9797582626342773]\n",
      "997 [D loss: 0] [G loss: 0] [VAE loss: 1.7447524070739746]\n",
      "998 [D loss: 0] [G loss: 0] [VAE loss: 1.7834773063659668]\n",
      "999 [D loss: 0] [G loss: 0] [VAE loss: 1.7943871021270752]\n",
      "1000 [D loss: 0] [G loss: 0] [VAE loss: 1.8496613502502441]\n",
      "1001 [D loss: 0] [G loss: 0] [VAE loss: 1.7641950845718384]\n",
      "1002 [D loss: 0] [G loss: 0] [VAE loss: 1.8704216480255127]\n",
      "1003 [D loss: 0] [G loss: 0] [VAE loss: 1.7114839553833008]\n",
      "1004 [D loss: 0] [G loss: 0] [VAE loss: 1.652021050453186]\n",
      "1005 [D loss: 0] [G loss: 0] [VAE loss: 1.7082890272140503]\n",
      "1006 [D loss: 0] [G loss: 0] [VAE loss: 1.6971906423568726]\n",
      "1007 [D loss: 0] [G loss: 0] [VAE loss: 1.7907183170318604]\n",
      "1008 [D loss: 0] [G loss: 0] [VAE loss: 1.7347863912582397]\n",
      "1009 [D loss: 0] [G loss: 0] [VAE loss: 1.6837701797485352]\n",
      "1010 [D loss: 0] [G loss: 0] [VAE loss: 1.905053734779358]\n",
      "1011 [D loss: 0] [G loss: 0] [VAE loss: 1.7974932193756104]\n",
      "1012 [D loss: 0] [G loss: 0] [VAE loss: 1.762406587600708]\n",
      "1013 [D loss: 0] [G loss: 0] [VAE loss: 1.7283673286437988]\n",
      "1014 [D loss: 0] [G loss: 0] [VAE loss: 1.7331562042236328]\n",
      "1015 [D loss: 0] [G loss: 0] [VAE loss: 1.6452417373657227]\n",
      "1016 [D loss: 0] [G loss: 0] [VAE loss: 1.7008655071258545]\n",
      "1017 [D loss: 0] [G loss: 0] [VAE loss: 1.7006641626358032]\n",
      "1018 [D loss: 0] [G loss: 0] [VAE loss: 1.7462092638015747]\n",
      "1019 [D loss: 0] [G loss: 0] [VAE loss: 1.6512410640716553]\n",
      "1020 [D loss: 0] [G loss: 0] [VAE loss: 1.9523661136627197]\n",
      "1021 [D loss: 0] [G loss: 0] [VAE loss: 1.7718963623046875]\n",
      "1022 [D loss: 0] [G loss: 0] [VAE loss: 1.6991956233978271]\n",
      "1023 [D loss: 0] [G loss: 0] [VAE loss: 1.8236286640167236]\n",
      "1024 [D loss: 0] [G loss: 0] [VAE loss: 1.8295037746429443]\n",
      "1025 [D loss: 0] [G loss: 0] [VAE loss: 1.700981855392456]\n",
      "1026 [D loss: 0] [G loss: 0] [VAE loss: 1.8605557680130005]\n",
      "1027 [D loss: 0] [G loss: 0] [VAE loss: 1.7318813800811768]\n",
      "1028 [D loss: 0] [G loss: 0] [VAE loss: 1.9130007028579712]\n",
      "1029 [D loss: 0] [G loss: 0] [VAE loss: 1.7795500755310059]\n",
      "1030 [D loss: 0] [G loss: 0] [VAE loss: 1.718043565750122]\n",
      "1031 [D loss: 0] [G loss: 0] [VAE loss: 1.8170064687728882]\n",
      "1032 [D loss: 0] [G loss: 0] [VAE loss: 1.8827308416366577]\n",
      "1033 [D loss: 0] [G loss: 0] [VAE loss: 1.6356807947158813]\n",
      "1034 [D loss: 0] [G loss: 0] [VAE loss: 1.7441720962524414]\n",
      "1035 [D loss: 0] [G loss: 0] [VAE loss: 1.7267875671386719]\n",
      "1036 [D loss: 0] [G loss: 0] [VAE loss: 1.8036069869995117]\n",
      "1037 [D loss: 0] [G loss: 0] [VAE loss: 1.7787468433380127]\n",
      "1038 [D loss: 0] [G loss: 0] [VAE loss: 1.685579538345337]\n",
      "1039 [D loss: 0] [G loss: 0] [VAE loss: 1.9459201097488403]\n",
      "1040 [D loss: 0] [G loss: 0] [VAE loss: 1.7290750741958618]\n",
      "1041 [D loss: 0] [G loss: 0] [VAE loss: 1.6750688552856445]\n",
      "1042 [D loss: 0] [G loss: 0] [VAE loss: 1.7570775747299194]\n",
      "1043 [D loss: 0] [G loss: 0] [VAE loss: 1.7033390998840332]\n",
      "1044 [D loss: 0] [G loss: 0] [VAE loss: 1.663474678993225]\n",
      "1045 [D loss: 0] [G loss: 0] [VAE loss: 1.7216873168945312]\n",
      "1046 [D loss: 0] [G loss: 0] [VAE loss: 1.6458032131195068]\n",
      "1047 [D loss: 0] [G loss: 0] [VAE loss: 1.774260401725769]\n",
      "1048 [D loss: 0] [G loss: 0] [VAE loss: 1.8036295175552368]\n",
      "1049 [D loss: 0] [G loss: 0] [VAE loss: 1.6785149574279785]\n",
      "1050 [D loss: 0] [G loss: 0] [VAE loss: 1.8032383918762207]\n",
      "1051 [D loss: 0] [G loss: 0] [VAE loss: 1.696541428565979]\n",
      "1052 [D loss: 0] [G loss: 0] [VAE loss: 1.6696105003356934]\n",
      "1053 [D loss: 0] [G loss: 0] [VAE loss: 1.7806665897369385]\n",
      "1054 [D loss: 0] [G loss: 0] [VAE loss: 1.8115458488464355]\n",
      "1055 [D loss: 0] [G loss: 0] [VAE loss: 1.692726969718933]\n",
      "1056 [D loss: 0] [G loss: 0] [VAE loss: 1.7779021263122559]\n",
      "1057 [D loss: 0] [G loss: 0] [VAE loss: 1.720845341682434]\n",
      "1058 [D loss: 0] [G loss: 0] [VAE loss: 1.7389553785324097]\n",
      "1059 [D loss: 0] [G loss: 0] [VAE loss: 1.7362782955169678]\n",
      "1060 [D loss: 0] [G loss: 0] [VAE loss: 1.7552529573440552]\n",
      "1061 [D loss: 0] [G loss: 0] [VAE loss: 1.7676067352294922]\n",
      "1062 [D loss: 0] [G loss: 0] [VAE loss: 1.7090270519256592]\n",
      "1063 [D loss: 0] [G loss: 0] [VAE loss: 1.7194457054138184]\n",
      "1064 [D loss: 0] [G loss: 0] [VAE loss: 1.663653016090393]\n",
      "1065 [D loss: 0] [G loss: 0] [VAE loss: 1.7623721361160278]\n",
      "1066 [D loss: 0] [G loss: 0] [VAE loss: 1.8803383111953735]\n",
      "1067 [D loss: 0] [G loss: 0] [VAE loss: 1.6887431144714355]\n",
      "1068 [D loss: 0] [G loss: 0] [VAE loss: 1.633897066116333]\n",
      "1069 [D loss: 0] [G loss: 0] [VAE loss: 1.7493208646774292]\n",
      "1070 [D loss: 0] [G loss: 0] [VAE loss: 1.7459791898727417]\n",
      "1071 [D loss: 0] [G loss: 0] [VAE loss: 1.893287181854248]\n",
      "1072 [D loss: 0] [G loss: 0] [VAE loss: 1.9749116897583008]\n",
      "1073 [D loss: 0] [G loss: 0] [VAE loss: 1.741510272026062]\n",
      "1074 [D loss: 0] [G loss: 0] [VAE loss: 1.8001151084899902]\n",
      "1075 [D loss: 0] [G loss: 0] [VAE loss: 1.7182010412216187]\n",
      "1076 [D loss: 0] [G loss: 0] [VAE loss: 1.8657535314559937]\n",
      "1077 [D loss: 0] [G loss: 0] [VAE loss: 1.8471481800079346]\n",
      "1078 [D loss: 0] [G loss: 0] [VAE loss: 1.763047695159912]\n",
      "1079 [D loss: 0] [G loss: 0] [VAE loss: 1.772041916847229]\n",
      "1080 [D loss: 0] [G loss: 0] [VAE loss: 1.7606048583984375]\n",
      "1081 [D loss: 0] [G loss: 0] [VAE loss: 1.787886619567871]\n",
      "1082 [D loss: 0] [G loss: 0] [VAE loss: 1.8209490776062012]\n",
      "1083 [D loss: 0] [G loss: 0] [VAE loss: 1.611242651939392]\n",
      "1084 [D loss: 0] [G loss: 0] [VAE loss: 1.8201192617416382]\n",
      "1085 [D loss: 0] [G loss: 0] [VAE loss: 1.800663709640503]\n",
      "1086 [D loss: 0] [G loss: 0] [VAE loss: 1.8843193054199219]\n",
      "1087 [D loss: 0] [G loss: 0] [VAE loss: 1.7484219074249268]\n",
      "1088 [D loss: 0] [G loss: 0] [VAE loss: 1.8010284900665283]\n",
      "1089 [D loss: 0] [G loss: 0] [VAE loss: 1.778714656829834]\n",
      "1090 [D loss: 0] [G loss: 0] [VAE loss: 1.8498988151550293]\n",
      "1091 [D loss: 0] [G loss: 0] [VAE loss: 1.6970020532608032]\n",
      "1092 [D loss: 0] [G loss: 0] [VAE loss: 1.8073207139968872]\n",
      "1093 [D loss: 0] [G loss: 0] [VAE loss: 1.8380794525146484]\n",
      "1094 [D loss: 0] [G loss: 0] [VAE loss: 1.6418839693069458]\n",
      "1095 [D loss: 0] [G loss: 0] [VAE loss: 1.8649636507034302]\n",
      "1096 [D loss: 0] [G loss: 0] [VAE loss: 1.7188674211502075]\n",
      "1097 [D loss: 0] [G loss: 0] [VAE loss: 1.8116910457611084]\n",
      "1098 [D loss: 0] [G loss: 0] [VAE loss: 1.883824110031128]\n",
      "1099 [D loss: 0] [G loss: 0] [VAE loss: 1.7854328155517578]\n",
      "1100 [D loss: 0] [G loss: 0] [VAE loss: 1.6268904209136963]\n",
      "1101 [D loss: 0] [G loss: 0] [VAE loss: 1.8140009641647339]\n",
      "1102 [D loss: 0] [G loss: 0] [VAE loss: 1.8005090951919556]\n",
      "1103 [D loss: 0] [G loss: 0] [VAE loss: 1.7809357643127441]\n",
      "1104 [D loss: 0] [G loss: 0] [VAE loss: 1.6672112941741943]\n",
      "1105 [D loss: 0] [G loss: 0] [VAE loss: 1.8820356130599976]\n",
      "1106 [D loss: 0] [G loss: 0] [VAE loss: 1.756589651107788]\n",
      "1107 [D loss: 0] [G loss: 0] [VAE loss: 1.8231678009033203]\n",
      "1108 [D loss: 0] [G loss: 0] [VAE loss: 1.7411677837371826]\n",
      "1109 [D loss: 0] [G loss: 0] [VAE loss: 1.7259204387664795]\n",
      "1110 [D loss: 0] [G loss: 0] [VAE loss: 1.6923134326934814]\n",
      "1111 [D loss: 0] [G loss: 0] [VAE loss: 1.612283706665039]\n",
      "1112 [D loss: 0] [G loss: 0] [VAE loss: 1.7158993482589722]\n",
      "1113 [D loss: 0] [G loss: 0] [VAE loss: 1.824961543083191]\n",
      "1114 [D loss: 0] [G loss: 0] [VAE loss: 1.6630797386169434]\n",
      "1115 [D loss: 0] [G loss: 0] [VAE loss: 1.6783970594406128]\n",
      "1116 [D loss: 0] [G loss: 0] [VAE loss: 1.773680567741394]\n",
      "1117 [D loss: 0] [G loss: 0] [VAE loss: 1.7732534408569336]\n",
      "1118 [D loss: 0] [G loss: 0] [VAE loss: 1.7821025848388672]\n",
      "1119 [D loss: 0] [G loss: 0] [VAE loss: 1.7638458013534546]\n",
      "1120 [D loss: 0] [G loss: 0] [VAE loss: 1.8419431447982788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121 [D loss: 0] [G loss: 0] [VAE loss: 1.6556367874145508]\n",
      "1122 [D loss: 0] [G loss: 0] [VAE loss: 1.8522350788116455]\n",
      "1123 [D loss: 0] [G loss: 0] [VAE loss: 1.788598895072937]\n",
      "1124 [D loss: 0] [G loss: 0] [VAE loss: 1.8085298538208008]\n",
      "1125 [D loss: 0] [G loss: 0] [VAE loss: 1.8496429920196533]\n",
      "1126 [D loss: 0] [G loss: 0] [VAE loss: 1.859207034111023]\n",
      "1127 [D loss: 0] [G loss: 0] [VAE loss: 1.7550275325775146]\n",
      "1128 [D loss: 0] [G loss: 0] [VAE loss: 1.8289103507995605]\n",
      "1129 [D loss: 0] [G loss: 0] [VAE loss: 1.8054969310760498]\n",
      "1130 [D loss: 0] [G loss: 0] [VAE loss: 1.7304184436798096]\n",
      "1131 [D loss: 0] [G loss: 0] [VAE loss: 1.8085529804229736]\n",
      "1132 [D loss: 0] [G loss: 0] [VAE loss: 1.7626949548721313]\n",
      "1133 [D loss: 0] [G loss: 0] [VAE loss: 1.705722451210022]\n",
      "1134 [D loss: 0] [G loss: 0] [VAE loss: 1.734039068222046]\n",
      "1135 [D loss: 0] [G loss: 0] [VAE loss: 1.7437015771865845]\n",
      "1136 [D loss: 0] [G loss: 0] [VAE loss: 1.753258228302002]\n",
      "1137 [D loss: 0] [G loss: 0] [VAE loss: 1.815685510635376]\n",
      "1138 [D loss: 0] [G loss: 0] [VAE loss: 1.6875547170639038]\n",
      "1139 [D loss: 0] [G loss: 0] [VAE loss: 1.7699558734893799]\n",
      "1140 [D loss: 0] [G loss: 0] [VAE loss: 1.8572700023651123]\n",
      "1141 [D loss: 0] [G loss: 0] [VAE loss: 1.7170312404632568]\n",
      "1142 [D loss: 0] [G loss: 0] [VAE loss: 1.7865878343582153]\n",
      "1143 [D loss: 0] [G loss: 0] [VAE loss: 1.6601097583770752]\n",
      "1144 [D loss: 0] [G loss: 0] [VAE loss: 1.8499730825424194]\n",
      "1145 [D loss: 0] [G loss: 0] [VAE loss: 1.7493042945861816]\n",
      "1146 [D loss: 0] [G loss: 0] [VAE loss: 1.567751407623291]\n",
      "1147 [D loss: 0] [G loss: 0] [VAE loss: 1.565746545791626]\n",
      "1148 [D loss: 0] [G loss: 0] [VAE loss: 1.7437487840652466]\n",
      "1149 [D loss: 0] [G loss: 0] [VAE loss: 1.9464592933654785]\n",
      "1150 [D loss: 0] [G loss: 0] [VAE loss: 1.8750234842300415]\n",
      "1151 [D loss: 0] [G loss: 0] [VAE loss: 1.7207846641540527]\n",
      "1152 [D loss: 0] [G loss: 0] [VAE loss: 1.8824512958526611]\n",
      "1153 [D loss: 0] [G loss: 0] [VAE loss: 1.6993355751037598]\n",
      "1154 [D loss: 0] [G loss: 0] [VAE loss: 1.6540615558624268]\n",
      "1155 [D loss: 0] [G loss: 0] [VAE loss: 1.723933458328247]\n",
      "1156 [D loss: 0] [G loss: 0] [VAE loss: 1.695669174194336]\n",
      "1157 [D loss: 0] [G loss: 0] [VAE loss: 1.7465193271636963]\n",
      "1158 [D loss: 0] [G loss: 0] [VAE loss: 1.7844033241271973]\n",
      "1159 [D loss: 0] [G loss: 0] [VAE loss: 1.8465994596481323]\n",
      "1160 [D loss: 0] [G loss: 0] [VAE loss: 1.7782528400421143]\n",
      "1161 [D loss: 0] [G loss: 0] [VAE loss: 1.7564830780029297]\n",
      "1162 [D loss: 0] [G loss: 0] [VAE loss: 1.8136589527130127]\n",
      "1163 [D loss: 0] [G loss: 0] [VAE loss: 1.6256413459777832]\n",
      "1164 [D loss: 0] [G loss: 0] [VAE loss: 1.9263427257537842]\n",
      "1165 [D loss: 0] [G loss: 0] [VAE loss: 1.6913115978240967]\n",
      "1166 [D loss: 0] [G loss: 0] [VAE loss: 1.7788946628570557]\n",
      "1167 [D loss: 0] [G loss: 0] [VAE loss: 1.7878930568695068]\n",
      "1168 [D loss: 0] [G loss: 0] [VAE loss: 1.653056263923645]\n",
      "1169 [D loss: 0] [G loss: 0] [VAE loss: 1.7350752353668213]\n",
      "1170 [D loss: 0] [G loss: 0] [VAE loss: 1.8119155168533325]\n",
      "1171 [D loss: 0] [G loss: 0] [VAE loss: 1.7462366819381714]\n",
      "1172 [D loss: 0] [G loss: 0] [VAE loss: 1.949912190437317]\n",
      "1173 [D loss: 0] [G loss: 0] [VAE loss: 1.9104118347167969]\n",
      "1174 [D loss: 0] [G loss: 0] [VAE loss: 1.7298986911773682]\n",
      "1175 [D loss: 0] [G loss: 0] [VAE loss: 1.8253705501556396]\n",
      "1176 [D loss: 0] [G loss: 0] [VAE loss: 1.7841289043426514]\n",
      "1177 [D loss: 0] [G loss: 0] [VAE loss: 1.708396553993225]\n",
      "1178 [D loss: 0] [G loss: 0] [VAE loss: 1.6840662956237793]\n",
      "1179 [D loss: 0] [G loss: 0] [VAE loss: 1.7920855283737183]\n",
      "1180 [D loss: 0] [G loss: 0] [VAE loss: 1.80430269241333]\n",
      "1181 [D loss: 0] [G loss: 0] [VAE loss: 1.923112154006958]\n",
      "1182 [D loss: 0] [G loss: 0] [VAE loss: 1.6706839799880981]\n",
      "1183 [D loss: 0] [G loss: 0] [VAE loss: 1.734687328338623]\n",
      "1184 [D loss: 0] [G loss: 0] [VAE loss: 1.6398258209228516]\n",
      "1185 [D loss: 0] [G loss: 0] [VAE loss: 1.6820236444473267]\n",
      "1186 [D loss: 0] [G loss: 0] [VAE loss: 1.9167176485061646]\n",
      "1187 [D loss: 0] [G loss: 0] [VAE loss: 1.585200309753418]\n",
      "1188 [D loss: 0] [G loss: 0] [VAE loss: 1.8050308227539062]\n",
      "1189 [D loss: 0] [G loss: 0] [VAE loss: 1.8194679021835327]\n",
      "1190 [D loss: 0] [G loss: 0] [VAE loss: 1.7680753469467163]\n",
      "1191 [D loss: 0] [G loss: 0] [VAE loss: 1.9304909706115723]\n",
      "1192 [D loss: 0] [G loss: 0] [VAE loss: 1.9400343894958496]\n",
      "1193 [D loss: 0] [G loss: 0] [VAE loss: 1.7220628261566162]\n",
      "1194 [D loss: 0] [G loss: 0] [VAE loss: 1.8113232851028442]\n",
      "1195 [D loss: 0] [G loss: 0] [VAE loss: 1.7717177867889404]\n",
      "1196 [D loss: 0] [G loss: 0] [VAE loss: 1.7933940887451172]\n",
      "1197 [D loss: 0] [G loss: 0] [VAE loss: 1.8379319906234741]\n",
      "1198 [D loss: 0] [G loss: 0] [VAE loss: 1.650263786315918]\n",
      "1199 [D loss: 0] [G loss: 0] [VAE loss: 1.7364306449890137]\n",
      "1200 [D loss: 0] [G loss: 0] [VAE loss: 1.9585857391357422]\n",
      "1201 [D loss: 0] [G loss: 0] [VAE loss: 1.7101155519485474]\n",
      "1202 [D loss: 0] [G loss: 0] [VAE loss: 1.6899123191833496]\n",
      "1203 [D loss: 0] [G loss: 0] [VAE loss: 1.8196280002593994]\n",
      "1204 [D loss: 0] [G loss: 0] [VAE loss: 1.9833059310913086]\n",
      "1205 [D loss: 0] [G loss: 0] [VAE loss: 1.7864480018615723]\n",
      "1206 [D loss: 0] [G loss: 0] [VAE loss: 1.8315610885620117]\n",
      "1207 [D loss: 0] [G loss: 0] [VAE loss: 1.6786878108978271]\n",
      "1208 [D loss: 0] [G loss: 0] [VAE loss: 1.6301182508468628]\n",
      "1209 [D loss: 0] [G loss: 0] [VAE loss: 1.7245732545852661]\n",
      "1210 [D loss: 0] [G loss: 0] [VAE loss: 1.933892011642456]\n",
      "1211 [D loss: 0] [G loss: 0] [VAE loss: 1.8449132442474365]\n",
      "1212 [D loss: 0] [G loss: 0] [VAE loss: 1.7942500114440918]\n",
      "1213 [D loss: 0] [G loss: 0] [VAE loss: 1.7133207321166992]\n",
      "1214 [D loss: 0] [G loss: 0] [VAE loss: 1.8763573169708252]\n",
      "1215 [D loss: 0] [G loss: 0] [VAE loss: 1.6534488201141357]\n",
      "1216 [D loss: 0] [G loss: 0] [VAE loss: 1.6823110580444336]\n",
      "1217 [D loss: 0] [G loss: 0] [VAE loss: 1.729629635810852]\n",
      "1218 [D loss: 0] [G loss: 0] [VAE loss: 1.730198860168457]\n",
      "1219 [D loss: 0] [G loss: 0] [VAE loss: 1.7011100053787231]\n",
      "1220 [D loss: 0] [G loss: 0] [VAE loss: 1.8614393472671509]\n",
      "1221 [D loss: 0] [G loss: 0] [VAE loss: 1.7859352827072144]\n",
      "1222 [D loss: 0] [G loss: 0] [VAE loss: 1.7342449426651]\n",
      "1223 [D loss: 0] [G loss: 0] [VAE loss: 1.897424578666687]\n",
      "1224 [D loss: 0] [G loss: 0] [VAE loss: 1.718259572982788]\n",
      "1225 [D loss: 0] [G loss: 0] [VAE loss: 1.8423824310302734]\n",
      "1226 [D loss: 0] [G loss: 0] [VAE loss: 1.6454848051071167]\n",
      "1227 [D loss: 0] [G loss: 0] [VAE loss: 1.6687543392181396]\n",
      "1228 [D loss: 0] [G loss: 0] [VAE loss: 1.817713737487793]\n",
      "1229 [D loss: 0] [G loss: 0] [VAE loss: 1.7542319297790527]\n",
      "1230 [D loss: 0] [G loss: 0] [VAE loss: 1.9521772861480713]\n",
      "1231 [D loss: 0] [G loss: 0] [VAE loss: 1.8166489601135254]\n",
      "1232 [D loss: 0] [G loss: 0] [VAE loss: 1.8413746356964111]\n",
      "1233 [D loss: 0] [G loss: 0] [VAE loss: 1.8249657154083252]\n",
      "1234 [D loss: 0] [G loss: 0] [VAE loss: 1.66520357131958]\n",
      "1235 [D loss: 0] [G loss: 0] [VAE loss: 1.8013464212417603]\n",
      "1236 [D loss: 0] [G loss: 0] [VAE loss: 1.6726244688034058]\n",
      "1237 [D loss: 0] [G loss: 0] [VAE loss: 1.7033066749572754]\n",
      "1238 [D loss: 0] [G loss: 0] [VAE loss: 1.7856988906860352]\n",
      "1239 [D loss: 0] [G loss: 0] [VAE loss: 1.6669824123382568]\n",
      "1240 [D loss: 0] [G loss: 0] [VAE loss: 1.7998771667480469]\n",
      "1241 [D loss: 0] [G loss: 0] [VAE loss: 1.6427243947982788]\n",
      "1242 [D loss: 0] [G loss: 0] [VAE loss: 1.6242878437042236]\n",
      "1243 [D loss: 0] [G loss: 0] [VAE loss: 1.8106117248535156]\n",
      "1244 [D loss: 0] [G loss: 0] [VAE loss: 1.7702893018722534]\n",
      "1245 [D loss: 0] [G loss: 0] [VAE loss: 1.7319101095199585]\n",
      "1246 [D loss: 0] [G loss: 0] [VAE loss: 1.7700508832931519]\n",
      "1247 [D loss: 0] [G loss: 0] [VAE loss: 1.8755385875701904]\n",
      "1248 [D loss: 0] [G loss: 0] [VAE loss: 1.8030853271484375]\n",
      "1249 [D loss: 0] [G loss: 0] [VAE loss: 1.6924176216125488]\n",
      "1250 [D loss: 0] [G loss: 0] [VAE loss: 1.7829468250274658]\n",
      "1251 [D loss: 0] [G loss: 0] [VAE loss: 1.626947045326233]\n",
      "1252 [D loss: 0] [G loss: 0] [VAE loss: 1.813521146774292]\n",
      "1253 [D loss: 0] [G loss: 0] [VAE loss: 1.8122626543045044]\n",
      "1254 [D loss: 0] [G loss: 0] [VAE loss: 1.8012678623199463]\n",
      "1255 [D loss: 0] [G loss: 0] [VAE loss: 1.7721240520477295]\n",
      "1256 [D loss: 0] [G loss: 0] [VAE loss: 1.650442123413086]\n",
      "1257 [D loss: 0] [G loss: 0] [VAE loss: 1.7305092811584473]\n",
      "1258 [D loss: 0] [G loss: 0] [VAE loss: 1.746145248413086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259 [D loss: 0] [G loss: 0] [VAE loss: 1.8321104049682617]\n",
      "1260 [D loss: 0] [G loss: 0] [VAE loss: 1.7289223670959473]\n",
      "1261 [D loss: 0] [G loss: 0] [VAE loss: 1.8270174264907837]\n",
      "1262 [D loss: 0] [G loss: 0] [VAE loss: 1.7784874439239502]\n",
      "1263 [D loss: 0] [G loss: 0] [VAE loss: 1.7245023250579834]\n",
      "1264 [D loss: 0] [G loss: 0] [VAE loss: 1.772663950920105]\n",
      "1265 [D loss: 0] [G loss: 0] [VAE loss: 1.8424885272979736]\n",
      "1266 [D loss: 0] [G loss: 0] [VAE loss: 1.8272098302841187]\n",
      "1267 [D loss: 0] [G loss: 0] [VAE loss: 1.8332020044326782]\n",
      "1268 [D loss: 0] [G loss: 0] [VAE loss: 1.7489349842071533]\n",
      "1269 [D loss: 0] [G loss: 0] [VAE loss: 1.9201685190200806]\n",
      "1270 [D loss: 0] [G loss: 0] [VAE loss: 1.7527682781219482]\n",
      "1271 [D loss: 0] [G loss: 0] [VAE loss: 1.895024299621582]\n",
      "1272 [D loss: 0] [G loss: 0] [VAE loss: 1.6827898025512695]\n",
      "1273 [D loss: 0] [G loss: 0] [VAE loss: 2.052767753601074]\n",
      "1274 [D loss: 0] [G loss: 0] [VAE loss: 1.678168773651123]\n",
      "1275 [D loss: 0] [G loss: 0] [VAE loss: 1.7179996967315674]\n",
      "1276 [D loss: 0] [G loss: 0] [VAE loss: 1.7178468704223633]\n",
      "1277 [D loss: 0] [G loss: 0] [VAE loss: 1.8650844097137451]\n",
      "1278 [D loss: 0] [G loss: 0] [VAE loss: 1.6656607389450073]\n",
      "1279 [D loss: 0] [G loss: 0] [VAE loss: 1.7582592964172363]\n",
      "1280 [D loss: 0] [G loss: 0] [VAE loss: 1.7926058769226074]\n",
      "1281 [D loss: 0] [G loss: 0] [VAE loss: 1.6950833797454834]\n",
      "1282 [D loss: 0] [G loss: 0] [VAE loss: 1.7763080596923828]\n",
      "1283 [D loss: 0] [G loss: 0] [VAE loss: 1.8136992454528809]\n",
      "1284 [D loss: 0] [G loss: 0] [VAE loss: 1.84738028049469]\n",
      "1285 [D loss: 0] [G loss: 0] [VAE loss: 1.817701816558838]\n",
      "1286 [D loss: 0] [G loss: 0] [VAE loss: 1.745605230331421]\n",
      "1287 [D loss: 0] [G loss: 0] [VAE loss: 1.787460446357727]\n",
      "1288 [D loss: 0] [G loss: 0] [VAE loss: 1.8300118446350098]\n",
      "1289 [D loss: 0] [G loss: 0] [VAE loss: 1.6860616207122803]\n",
      "1290 [D loss: 0] [G loss: 0] [VAE loss: 1.8072035312652588]\n",
      "1291 [D loss: 0] [G loss: 0] [VAE loss: 1.723158597946167]\n",
      "1292 [D loss: 0] [G loss: 0] [VAE loss: 1.6174237728118896]\n",
      "1293 [D loss: 0] [G loss: 0] [VAE loss: 1.7060750722885132]\n",
      "1294 [D loss: 0] [G loss: 0] [VAE loss: 1.8619310855865479]\n",
      "1295 [D loss: 0] [G loss: 0] [VAE loss: 1.7302289009094238]\n",
      "1296 [D loss: 0] [G loss: 0] [VAE loss: 1.9382545948028564]\n",
      "1297 [D loss: 0] [G loss: 0] [VAE loss: 1.6880011558532715]\n",
      "1298 [D loss: 0] [G loss: 0] [VAE loss: 1.6860681772232056]\n",
      "1299 [D loss: 0] [G loss: 0] [VAE loss: 1.757800817489624]\n",
      "1300 [D loss: 0] [G loss: 0] [VAE loss: 1.799911379814148]\n",
      "1301 [D loss: 0] [G loss: 0] [VAE loss: 1.8327323198318481]\n",
      "1302 [D loss: 0] [G loss: 0] [VAE loss: 1.7348462343215942]\n",
      "1303 [D loss: 0] [G loss: 0] [VAE loss: 1.7874209880828857]\n",
      "1304 [D loss: 0] [G loss: 0] [VAE loss: 1.8975107669830322]\n",
      "1305 [D loss: 0] [G loss: 0] [VAE loss: 1.7734332084655762]\n",
      "1306 [D loss: 0] [G loss: 0] [VAE loss: 1.728712558746338]\n",
      "1307 [D loss: 0] [G loss: 0] [VAE loss: 1.7314105033874512]\n",
      "1308 [D loss: 0] [G loss: 0] [VAE loss: 1.814319133758545]\n",
      "1309 [D loss: 0] [G loss: 0] [VAE loss: 1.8754384517669678]\n",
      "1310 [D loss: 0] [G loss: 0] [VAE loss: 1.7083426713943481]\n",
      "1311 [D loss: 0] [G loss: 0] [VAE loss: 1.7671512365341187]\n",
      "1312 [D loss: 0] [G loss: 0] [VAE loss: 1.9117144346237183]\n",
      "1313 [D loss: 0] [G loss: 0] [VAE loss: 1.6607170104980469]\n",
      "1314 [D loss: 0] [G loss: 0] [VAE loss: 1.7054502964019775]\n",
      "1315 [D loss: 0] [G loss: 0] [VAE loss: 1.6914937496185303]\n",
      "1316 [D loss: 0] [G loss: 0] [VAE loss: 1.7706971168518066]\n",
      "1317 [D loss: 0] [G loss: 0] [VAE loss: 1.9017717838287354]\n",
      "1318 [D loss: 0] [G loss: 0] [VAE loss: 1.787422776222229]\n",
      "1319 [D loss: 0] [G loss: 0] [VAE loss: 1.7084978818893433]\n",
      "1320 [D loss: 0] [G loss: 0] [VAE loss: 1.8171679973602295]\n",
      "1321 [D loss: 0] [G loss: 0] [VAE loss: 1.8311165571212769]\n",
      "1322 [D loss: 0] [G loss: 0] [VAE loss: 1.7012125253677368]\n",
      "1323 [D loss: 0] [G loss: 0] [VAE loss: 1.791541576385498]\n",
      "1324 [D loss: 0] [G loss: 0] [VAE loss: 1.8545914888381958]\n",
      "1325 [D loss: 0] [G loss: 0] [VAE loss: 1.7634079456329346]\n",
      "1326 [D loss: 0] [G loss: 0] [VAE loss: 1.7278940677642822]\n",
      "1327 [D loss: 0] [G loss: 0] [VAE loss: 1.811126947402954]\n",
      "1328 [D loss: 0] [G loss: 0] [VAE loss: 1.830735206604004]\n",
      "1329 [D loss: 0] [G loss: 0] [VAE loss: 1.685448169708252]\n",
      "1330 [D loss: 0] [G loss: 0] [VAE loss: 1.7208693027496338]\n",
      "1331 [D loss: 0] [G loss: 0] [VAE loss: 1.7786929607391357]\n",
      "1332 [D loss: 0] [G loss: 0] [VAE loss: 1.7097465991973877]\n",
      "1333 [D loss: 0] [G loss: 0] [VAE loss: 1.6801044940948486]\n",
      "1334 [D loss: 0] [G loss: 0] [VAE loss: 1.7810258865356445]\n",
      "1335 [D loss: 0] [G loss: 0] [VAE loss: 1.7889806032180786]\n",
      "1336 [D loss: 0] [G loss: 0] [VAE loss: 1.771477222442627]\n",
      "1337 [D loss: 0] [G loss: 0] [VAE loss: 1.786357045173645]\n",
      "1338 [D loss: 0] [G loss: 0] [VAE loss: 1.7495520114898682]\n",
      "1339 [D loss: 0] [G loss: 0] [VAE loss: 1.8544917106628418]\n",
      "1340 [D loss: 0] [G loss: 0] [VAE loss: 1.9064884185791016]\n",
      "1341 [D loss: 0] [G loss: 0] [VAE loss: 1.7014541625976562]\n",
      "1342 [D loss: 0] [G loss: 0] [VAE loss: 1.7934544086456299]\n",
      "1343 [D loss: 0] [G loss: 0] [VAE loss: 1.8540849685668945]\n",
      "1344 [D loss: 0] [G loss: 0] [VAE loss: 1.79555082321167]\n",
      "1345 [D loss: 0] [G loss: 0] [VAE loss: 1.948370337486267]\n",
      "1346 [D loss: 0] [G loss: 0] [VAE loss: 1.84706449508667]\n",
      "1347 [D loss: 0] [G loss: 0] [VAE loss: 1.7108702659606934]\n",
      "1348 [D loss: 0] [G loss: 0] [VAE loss: 1.785497784614563]\n",
      "1349 [D loss: 0] [G loss: 0] [VAE loss: 1.69392728805542]\n",
      "1350 [D loss: 0] [G loss: 0] [VAE loss: 1.8866420984268188]\n",
      "1351 [D loss: 0] [G loss: 0] [VAE loss: 1.7145417928695679]\n",
      "1352 [D loss: 0] [G loss: 0] [VAE loss: 1.7696754932403564]\n",
      "1353 [D loss: 0] [G loss: 0] [VAE loss: 1.8144166469573975]\n",
      "1354 [D loss: 0] [G loss: 0] [VAE loss: 1.8106212615966797]\n",
      "1355 [D loss: 0] [G loss: 0] [VAE loss: 1.8722268342971802]\n",
      "1356 [D loss: 0] [G loss: 0] [VAE loss: 1.7840253114700317]\n",
      "1357 [D loss: 0] [G loss: 0] [VAE loss: 1.746760368347168]\n",
      "1358 [D loss: 0] [G loss: 0] [VAE loss: 1.8094825744628906]\n",
      "1359 [D loss: 0] [G loss: 0] [VAE loss: 1.7403193712234497]\n",
      "1360 [D loss: 0] [G loss: 0] [VAE loss: 1.8010218143463135]\n",
      "1361 [D loss: 0] [G loss: 0] [VAE loss: 1.858480453491211]\n",
      "1362 [D loss: 0] [G loss: 0] [VAE loss: 1.8304829597473145]\n",
      "1363 [D loss: 0] [G loss: 0] [VAE loss: 1.9438376426696777]\n",
      "1364 [D loss: 0] [G loss: 0] [VAE loss: 1.8447169065475464]\n",
      "1365 [D loss: 0] [G loss: 0] [VAE loss: 1.7948873043060303]\n",
      "1366 [D loss: 0] [G loss: 0] [VAE loss: 1.6654794216156006]\n",
      "1367 [D loss: 0] [G loss: 0] [VAE loss: 1.7656898498535156]\n",
      "1368 [D loss: 0] [G loss: 0] [VAE loss: 1.6377601623535156]\n",
      "1369 [D loss: 0] [G loss: 0] [VAE loss: 1.7299978733062744]\n",
      "1370 [D loss: 0] [G loss: 0] [VAE loss: 1.784428596496582]\n",
      "1371 [D loss: 0] [G loss: 0] [VAE loss: 1.7270337343215942]\n",
      "1372 [D loss: 0] [G loss: 0] [VAE loss: 1.7441534996032715]\n",
      "1373 [D loss: 0] [G loss: 0] [VAE loss: 1.8218135833740234]\n",
      "1374 [D loss: 0] [G loss: 0] [VAE loss: 1.7160080671310425]\n",
      "1375 [D loss: 0] [G loss: 0] [VAE loss: 1.6119884252548218]\n",
      "1376 [D loss: 0] [G loss: 0] [VAE loss: 1.7574577331542969]\n",
      "1377 [D loss: 0] [G loss: 0] [VAE loss: 1.700669765472412]\n",
      "1378 [D loss: 0] [G loss: 0] [VAE loss: 1.8115434646606445]\n",
      "1379 [D loss: 0] [G loss: 0] [VAE loss: 1.7316786050796509]\n",
      "1380 [D loss: 0] [G loss: 0] [VAE loss: 1.9185012578964233]\n",
      "1381 [D loss: 0] [G loss: 0] [VAE loss: 1.8989901542663574]\n",
      "1382 [D loss: 0] [G loss: 0] [VAE loss: 1.5728636980056763]\n",
      "1383 [D loss: 0] [G loss: 0] [VAE loss: 1.658927321434021]\n",
      "1384 [D loss: 0] [G loss: 0] [VAE loss: 1.764105200767517]\n",
      "1385 [D loss: 0] [G loss: 0] [VAE loss: 1.837070345878601]\n",
      "1386 [D loss: 0] [G loss: 0] [VAE loss: 1.8249406814575195]\n",
      "1387 [D loss: 0] [G loss: 0] [VAE loss: 1.7858844995498657]\n",
      "1388 [D loss: 0] [G loss: 0] [VAE loss: 1.8818159103393555]\n",
      "1389 [D loss: 0] [G loss: 0] [VAE loss: 1.7346816062927246]\n",
      "1390 [D loss: 0] [G loss: 0] [VAE loss: 1.670396327972412]\n",
      "1391 [D loss: 0] [G loss: 0] [VAE loss: 1.998112440109253]\n",
      "1392 [D loss: 0] [G loss: 0] [VAE loss: 1.9831058979034424]\n",
      "1393 [D loss: 0] [G loss: 0] [VAE loss: 1.7066363096237183]\n",
      "1394 [D loss: 0] [G loss: 0] [VAE loss: 1.7701754570007324]\n",
      "1395 [D loss: 0] [G loss: 0] [VAE loss: 1.7596160173416138]\n",
      "1396 [D loss: 0] [G loss: 0] [VAE loss: 1.802074909210205]\n",
      "1397 [D loss: 0] [G loss: 0] [VAE loss: 1.6340287923812866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398 [D loss: 0] [G loss: 0] [VAE loss: 1.783984661102295]\n",
      "1399 [D loss: 0] [G loss: 0] [VAE loss: 1.6898330450057983]\n",
      "1400 [D loss: 0] [G loss: 0] [VAE loss: 1.777334213256836]\n",
      "1401 [D loss: 0] [G loss: 0] [VAE loss: 1.7419551610946655]\n",
      "1402 [D loss: 0] [G loss: 0] [VAE loss: 1.777750015258789]\n",
      "1403 [D loss: 0] [G loss: 0] [VAE loss: 1.654337763786316]\n",
      "1404 [D loss: 0] [G loss: 0] [VAE loss: 1.7479461431503296]\n",
      "1405 [D loss: 0] [G loss: 0] [VAE loss: 1.584820032119751]\n",
      "1406 [D loss: 0] [G loss: 0] [VAE loss: 1.8123390674591064]\n",
      "1407 [D loss: 0] [G loss: 0] [VAE loss: 1.896997332572937]\n",
      "1408 [D loss: 0] [G loss: 0] [VAE loss: 1.7296427488327026]\n",
      "1409 [D loss: 0] [G loss: 0] [VAE loss: 1.812079906463623]\n",
      "1410 [D loss: 0] [G loss: 0] [VAE loss: 1.7449482679367065]\n",
      "1411 [D loss: 0] [G loss: 0] [VAE loss: 1.6984224319458008]\n",
      "1412 [D loss: 0] [G loss: 0] [VAE loss: 1.7447535991668701]\n",
      "1413 [D loss: 0] [G loss: 0] [VAE loss: 1.6689637899398804]\n",
      "1414 [D loss: 0] [G loss: 0] [VAE loss: 1.7142633199691772]\n",
      "1415 [D loss: 0] [G loss: 0] [VAE loss: 1.8234950304031372]\n",
      "1416 [D loss: 0] [G loss: 0] [VAE loss: 1.7030855417251587]\n",
      "1417 [D loss: 0] [G loss: 0] [VAE loss: 1.6783466339111328]\n",
      "1418 [D loss: 0] [G loss: 0] [VAE loss: 1.878027319908142]\n",
      "1419 [D loss: 0] [G loss: 0] [VAE loss: 1.6897943019866943]\n",
      "1420 [D loss: 0] [G loss: 0] [VAE loss: 1.651358962059021]\n",
      "1421 [D loss: 0] [G loss: 0] [VAE loss: 1.9955083131790161]\n",
      "1422 [D loss: 0] [G loss: 0] [VAE loss: 1.8688966035842896]\n",
      "1423 [D loss: 0] [G loss: 0] [VAE loss: 1.8207149505615234]\n",
      "1424 [D loss: 0] [G loss: 0] [VAE loss: 1.7210793495178223]\n",
      "1425 [D loss: 0] [G loss: 0] [VAE loss: 1.665292501449585]\n",
      "1426 [D loss: 0] [G loss: 0] [VAE loss: 1.8128432035446167]\n",
      "1427 [D loss: 0] [G loss: 0] [VAE loss: 1.677788496017456]\n",
      "1428 [D loss: 0] [G loss: 0] [VAE loss: 1.816081166267395]\n",
      "1429 [D loss: 0] [G loss: 0] [VAE loss: 1.7252179384231567]\n",
      "1430 [D loss: 0] [G loss: 0] [VAE loss: 1.7807625532150269]\n",
      "1431 [D loss: 0] [G loss: 0] [VAE loss: 1.7325741052627563]\n",
      "1432 [D loss: 0] [G loss: 0] [VAE loss: 1.887251615524292]\n",
      "1433 [D loss: 0] [G loss: 0] [VAE loss: 1.7437560558319092]\n",
      "1434 [D loss: 0] [G loss: 0] [VAE loss: 1.6262660026550293]\n",
      "1435 [D loss: 0] [G loss: 0] [VAE loss: 1.7217556238174438]\n",
      "1436 [D loss: 0] [G loss: 0] [VAE loss: 1.7238292694091797]\n",
      "1437 [D loss: 0] [G loss: 0] [VAE loss: 1.762327790260315]\n",
      "1438 [D loss: 0] [G loss: 0] [VAE loss: 1.7036831378936768]\n",
      "1439 [D loss: 0] [G loss: 0] [VAE loss: 1.7605196237564087]\n",
      "1440 [D loss: 0] [G loss: 0] [VAE loss: 1.886160135269165]\n",
      "1441 [D loss: 0] [G loss: 0] [VAE loss: 1.6284103393554688]\n",
      "1442 [D loss: 0] [G loss: 0] [VAE loss: 1.9406068325042725]\n",
      "1443 [D loss: 0] [G loss: 0] [VAE loss: 1.6876451969146729]\n",
      "1444 [D loss: 0] [G loss: 0] [VAE loss: 1.721365213394165]\n",
      "1445 [D loss: 0] [G loss: 0] [VAE loss: 1.7617764472961426]\n",
      "1446 [D loss: 0] [G loss: 0] [VAE loss: 1.880150318145752]\n",
      "1447 [D loss: 0] [G loss: 0] [VAE loss: 1.8074305057525635]\n",
      "1448 [D loss: 0] [G loss: 0] [VAE loss: 1.7446303367614746]\n",
      "1449 [D loss: 0] [G loss: 0] [VAE loss: 1.9407055377960205]\n",
      "1450 [D loss: 0] [G loss: 0] [VAE loss: 1.7620961666107178]\n",
      "1451 [D loss: 0] [G loss: 0] [VAE loss: 1.6572046279907227]\n",
      "1452 [D loss: 0] [G loss: 0] [VAE loss: 1.7439699172973633]\n",
      "1453 [D loss: 0] [G loss: 0] [VAE loss: 1.7857412099838257]\n",
      "1454 [D loss: 0] [G loss: 0] [VAE loss: 1.6280460357666016]\n",
      "1455 [D loss: 0] [G loss: 0] [VAE loss: 1.8053627014160156]\n",
      "1456 [D loss: 0] [G loss: 0] [VAE loss: 1.7410082817077637]\n",
      "1457 [D loss: 0] [G loss: 0] [VAE loss: 1.5769116878509521]\n",
      "1458 [D loss: 0] [G loss: 0] [VAE loss: 1.87211275100708]\n",
      "1459 [D loss: 0] [G loss: 0] [VAE loss: 1.72659170627594]\n",
      "1460 [D loss: 0] [G loss: 0] [VAE loss: 1.5768765211105347]\n",
      "1461 [D loss: 0] [G loss: 0] [VAE loss: 1.823188066482544]\n",
      "1462 [D loss: 0] [G loss: 0] [VAE loss: 1.6697406768798828]\n",
      "1463 [D loss: 0] [G loss: 0] [VAE loss: 1.776301622390747]\n",
      "1464 [D loss: 0] [G loss: 0] [VAE loss: 1.7546625137329102]\n",
      "1465 [D loss: 0] [G loss: 0] [VAE loss: 1.8626623153686523]\n",
      "1466 [D loss: 0] [G loss: 0] [VAE loss: 1.6748472452163696]\n",
      "1467 [D loss: 0] [G loss: 0] [VAE loss: 1.9531172513961792]\n",
      "1468 [D loss: 0] [G loss: 0] [VAE loss: 2.0122060775756836]\n",
      "1469 [D loss: 0] [G loss: 0] [VAE loss: 1.824446439743042]\n",
      "1470 [D loss: 0] [G loss: 0] [VAE loss: 1.7186801433563232]\n",
      "1471 [D loss: 0] [G loss: 0] [VAE loss: 1.7752387523651123]\n",
      "1472 [D loss: 0] [G loss: 0] [VAE loss: 1.8813719749450684]\n",
      "1473 [D loss: 0] [G loss: 0] [VAE loss: 1.7296862602233887]\n",
      "1474 [D loss: 0] [G loss: 0] [VAE loss: 1.643566370010376]\n",
      "1475 [D loss: 0] [G loss: 0] [VAE loss: 1.8337857723236084]\n",
      "1476 [D loss: 0] [G loss: 0] [VAE loss: 1.6937336921691895]\n",
      "1477 [D loss: 0] [G loss: 0] [VAE loss: 1.8811231851577759]\n",
      "1478 [D loss: 0] [G loss: 0] [VAE loss: 1.799372673034668]\n",
      "1479 [D loss: 0] [G loss: 0] [VAE loss: 1.7164640426635742]\n",
      "1480 [D loss: 0] [G loss: 0] [VAE loss: 1.7768876552581787]\n",
      "1481 [D loss: 0] [G loss: 0] [VAE loss: 1.6449804306030273]\n",
      "1482 [D loss: 0] [G loss: 0] [VAE loss: 1.6835651397705078]\n",
      "1483 [D loss: 0] [G loss: 0] [VAE loss: 1.6940884590148926]\n",
      "1484 [D loss: 0] [G loss: 0] [VAE loss: 1.769400715827942]\n",
      "1485 [D loss: 0] [G loss: 0] [VAE loss: 1.6614134311676025]\n",
      "1486 [D loss: 0] [G loss: 0] [VAE loss: 1.7930397987365723]\n",
      "1487 [D loss: 0] [G loss: 0] [VAE loss: 1.7881693840026855]\n",
      "1488 [D loss: 0] [G loss: 0] [VAE loss: 1.752129316329956]\n",
      "1489 [D loss: 0] [G loss: 0] [VAE loss: 1.8450839519500732]\n",
      "1490 [D loss: 0] [G loss: 0] [VAE loss: 1.8191064596176147]\n",
      "1491 [D loss: 0] [G loss: 0] [VAE loss: 1.7281346321105957]\n",
      "1492 [D loss: 0] [G loss: 0] [VAE loss: 1.7847952842712402]\n",
      "1493 [D loss: 0] [G loss: 0] [VAE loss: 1.6658090353012085]\n",
      "1494 [D loss: 0] [G loss: 0] [VAE loss: 1.8208496570587158]\n",
      "1495 [D loss: 0] [G loss: 0] [VAE loss: 1.75829017162323]\n",
      "1496 [D loss: 0] [G loss: 0] [VAE loss: 1.8189051151275635]\n",
      "1497 [D loss: 0] [G loss: 0] [VAE loss: 1.739957571029663]\n",
      "1498 [D loss: 0] [G loss: 0] [VAE loss: 1.7671669721603394]\n",
      "1499 [D loss: 0] [G loss: 0] [VAE loss: 1.7942018508911133]\n",
      "1500 [D loss: 0] [G loss: 0] [VAE loss: 1.9607539176940918]\n",
      "1501 [D loss: 0] [G loss: 0] [VAE loss: 1.6632189750671387]\n",
      "1502 [D loss: 0] [G loss: 0] [VAE loss: 1.7444705963134766]\n",
      "1503 [D loss: 0] [G loss: 0] [VAE loss: 1.6952848434448242]\n",
      "1504 [D loss: 0] [G loss: 0] [VAE loss: 1.7303310632705688]\n",
      "1505 [D loss: 0] [G loss: 0] [VAE loss: 1.898635983467102]\n",
      "1506 [D loss: 0] [G loss: 0] [VAE loss: 1.7298214435577393]\n",
      "1507 [D loss: 0] [G loss: 0] [VAE loss: 1.8136111497879028]\n",
      "1508 [D loss: 0] [G loss: 0] [VAE loss: 1.8742566108703613]\n",
      "1509 [D loss: 0] [G loss: 0] [VAE loss: 1.804486870765686]\n",
      "1510 [D loss: 0] [G loss: 0] [VAE loss: 1.8254444599151611]\n",
      "1511 [D loss: 0] [G loss: 0] [VAE loss: 1.8671603202819824]\n",
      "1512 [D loss: 0] [G loss: 0] [VAE loss: 1.891643762588501]\n",
      "1513 [D loss: 0] [G loss: 0] [VAE loss: 1.7738335132598877]\n",
      "1514 [D loss: 0] [G loss: 0] [VAE loss: 1.7773563861846924]\n",
      "1515 [D loss: 0] [G loss: 0] [VAE loss: 1.9113359451293945]\n",
      "1516 [D loss: 0] [G loss: 0] [VAE loss: 1.705596923828125]\n",
      "1517 [D loss: 0] [G loss: 0] [VAE loss: 1.7586065530776978]\n",
      "1518 [D loss: 0] [G loss: 0] [VAE loss: 1.7839689254760742]\n",
      "1519 [D loss: 0] [G loss: 0] [VAE loss: 1.734243392944336]\n",
      "1520 [D loss: 0] [G loss: 0] [VAE loss: 1.7684012651443481]\n",
      "1521 [D loss: 0] [G loss: 0] [VAE loss: 1.782082438468933]\n",
      "1522 [D loss: 0] [G loss: 0] [VAE loss: 1.6079553365707397]\n",
      "1523 [D loss: 0] [G loss: 0] [VAE loss: 1.9423620700836182]\n",
      "1524 [D loss: 0] [G loss: 0] [VAE loss: 1.7529582977294922]\n",
      "1525 [D loss: 0] [G loss: 0] [VAE loss: 1.8670406341552734]\n",
      "1526 [D loss: 0] [G loss: 0] [VAE loss: 1.609243392944336]\n",
      "1527 [D loss: 0] [G loss: 0] [VAE loss: 1.818128228187561]\n",
      "1528 [D loss: 0] [G loss: 0] [VAE loss: 1.7197532653808594]\n",
      "1529 [D loss: 0] [G loss: 0] [VAE loss: 1.8904249668121338]\n",
      "1530 [D loss: 0] [G loss: 0] [VAE loss: 1.6997036933898926]\n",
      "1531 [D loss: 0] [G loss: 0] [VAE loss: 1.8760074377059937]\n",
      "1532 [D loss: 0] [G loss: 0] [VAE loss: 1.8946423530578613]\n",
      "1533 [D loss: 0] [G loss: 0] [VAE loss: 1.8046324253082275]\n",
      "1534 [D loss: 0] [G loss: 0] [VAE loss: 1.8358309268951416]\n",
      "1535 [D loss: 0] [G loss: 0] [VAE loss: 1.8783342838287354]\n",
      "1536 [D loss: 0] [G loss: 0] [VAE loss: 1.6159189939498901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537 [D loss: 0] [G loss: 0] [VAE loss: 1.6766372919082642]\n",
      "1538 [D loss: 0] [G loss: 0] [VAE loss: 1.684950828552246]\n",
      "1539 [D loss: 0] [G loss: 0] [VAE loss: 1.6065336465835571]\n",
      "1540 [D loss: 0] [G loss: 0] [VAE loss: 1.7495553493499756]\n",
      "1541 [D loss: 0] [G loss: 0] [VAE loss: 1.8858648538589478]\n",
      "1542 [D loss: 0] [G loss: 0] [VAE loss: 1.7619510889053345]\n",
      "1543 [D loss: 0] [G loss: 0] [VAE loss: 1.7326921224594116]\n",
      "1544 [D loss: 0] [G loss: 0] [VAE loss: 1.7584576606750488]\n",
      "1545 [D loss: 0] [G loss: 0] [VAE loss: 1.712282419204712]\n",
      "1546 [D loss: 0] [G loss: 0] [VAE loss: 1.8908218145370483]\n",
      "1547 [D loss: 0] [G loss: 0] [VAE loss: 1.6650323867797852]\n",
      "1548 [D loss: 0] [G loss: 0] [VAE loss: 1.758535623550415]\n",
      "1549 [D loss: 0] [G loss: 0] [VAE loss: 1.7815443277359009]\n",
      "1550 [D loss: 0] [G loss: 0] [VAE loss: 1.6129281520843506]\n",
      "1551 [D loss: 0] [G loss: 0] [VAE loss: 1.6056512594223022]\n",
      "1552 [D loss: 0] [G loss: 0] [VAE loss: 1.743446946144104]\n",
      "1553 [D loss: 0] [G loss: 0] [VAE loss: 1.650604248046875]\n",
      "1554 [D loss: 0] [G loss: 0] [VAE loss: 1.7645821571350098]\n",
      "1555 [D loss: 0] [G loss: 0] [VAE loss: 1.6663060188293457]\n",
      "1556 [D loss: 0] [G loss: 0] [VAE loss: 1.6587039232254028]\n",
      "1557 [D loss: 0] [G loss: 0] [VAE loss: 1.6259982585906982]\n",
      "1558 [D loss: 0] [G loss: 0] [VAE loss: 1.7585015296936035]\n",
      "1559 [D loss: 0] [G loss: 0] [VAE loss: 1.7599468231201172]\n",
      "1560 [D loss: 0] [G loss: 0] [VAE loss: 1.8297741413116455]\n",
      "1561 [D loss: 0] [G loss: 0] [VAE loss: 1.6466140747070312]\n",
      "1562 [D loss: 0] [G loss: 0] [VAE loss: 1.7206794023513794]\n",
      "1563 [D loss: 0] [G loss: 0] [VAE loss: 1.6908221244812012]\n",
      "1564 [D loss: 0] [G loss: 0] [VAE loss: 1.7654955387115479]\n",
      "1565 [D loss: 0] [G loss: 0] [VAE loss: 1.777681589126587]\n",
      "1566 [D loss: 0] [G loss: 0] [VAE loss: 1.7519400119781494]\n",
      "1567 [D loss: 0] [G loss: 0] [VAE loss: 1.7984509468078613]\n",
      "1568 [D loss: 0] [G loss: 0] [VAE loss: 1.7958009243011475]\n",
      "1569 [D loss: 0] [G loss: 0] [VAE loss: 1.657224416732788]\n",
      "1570 [D loss: 0] [G loss: 0] [VAE loss: 1.7712538242340088]\n",
      "1571 [D loss: 0] [G loss: 0] [VAE loss: 1.6311836242675781]\n",
      "1572 [D loss: 0] [G loss: 0] [VAE loss: 1.8247857093811035]\n",
      "1573 [D loss: 0] [G loss: 0] [VAE loss: 1.8571909666061401]\n",
      "1574 [D loss: 0] [G loss: 0] [VAE loss: 1.7467727661132812]\n",
      "1575 [D loss: 0] [G loss: 0] [VAE loss: 1.8803560733795166]\n",
      "1576 [D loss: 0] [G loss: 0] [VAE loss: 1.8653888702392578]\n",
      "1577 [D loss: 0] [G loss: 0] [VAE loss: 1.8236212730407715]\n",
      "1578 [D loss: 0] [G loss: 0] [VAE loss: 1.778623104095459]\n",
      "1579 [D loss: 0] [G loss: 0] [VAE loss: 1.7650552988052368]\n",
      "1580 [D loss: 0] [G loss: 0] [VAE loss: 1.6777368783950806]\n",
      "1581 [D loss: 0] [G loss: 0] [VAE loss: 1.7693675756454468]\n",
      "1582 [D loss: 0] [G loss: 0] [VAE loss: 1.7785632610321045]\n",
      "1583 [D loss: 0] [G loss: 0] [VAE loss: 1.8185063600540161]\n",
      "1584 [D loss: 0] [G loss: 0] [VAE loss: 1.750842571258545]\n",
      "1585 [D loss: 0] [G loss: 0] [VAE loss: 1.7922930717468262]\n",
      "1586 [D loss: 0] [G loss: 0] [VAE loss: 1.6126959323883057]\n",
      "1587 [D loss: 0] [G loss: 0] [VAE loss: 1.870835542678833]\n",
      "1588 [D loss: 0] [G loss: 0] [VAE loss: 1.8912279605865479]\n",
      "1589 [D loss: 0] [G loss: 0] [VAE loss: 1.9911401271820068]\n",
      "1590 [D loss: 0] [G loss: 0] [VAE loss: 1.7381712198257446]\n",
      "1591 [D loss: 0] [G loss: 0] [VAE loss: 1.7376385927200317]\n",
      "1592 [D loss: 0] [G loss: 0] [VAE loss: 1.7672061920166016]\n",
      "1593 [D loss: 0] [G loss: 0] [VAE loss: 1.8721040487289429]\n",
      "1594 [D loss: 0] [G loss: 0] [VAE loss: 1.6689863204956055]\n",
      "1595 [D loss: 0] [G loss: 0] [VAE loss: 1.7404063940048218]\n",
      "1596 [D loss: 0] [G loss: 0] [VAE loss: 1.8571436405181885]\n",
      "1597 [D loss: 0] [G loss: 0] [VAE loss: 1.6591897010803223]\n",
      "1598 [D loss: 0] [G loss: 0] [VAE loss: 1.6145484447479248]\n",
      "1599 [D loss: 0] [G loss: 0] [VAE loss: 1.6683781147003174]\n",
      "1600 [D loss: 0] [G loss: 0] [VAE loss: 1.8780903816223145]\n",
      "1601 [D loss: 0] [G loss: 0] [VAE loss: 1.873637080192566]\n",
      "1602 [D loss: 0] [G loss: 0] [VAE loss: 1.7502127885818481]\n",
      "1603 [D loss: 0] [G loss: 0] [VAE loss: 1.7258257865905762]\n",
      "1604 [D loss: 0] [G loss: 0] [VAE loss: 1.6386135816574097]\n",
      "1605 [D loss: 0] [G loss: 0] [VAE loss: 1.770250916481018]\n",
      "1606 [D loss: 0] [G loss: 0] [VAE loss: 1.6728891134262085]\n",
      "1607 [D loss: 0] [G loss: 0] [VAE loss: 1.6194061040878296]\n",
      "1608 [D loss: 0] [G loss: 0] [VAE loss: 1.7292146682739258]\n",
      "1609 [D loss: 0] [G loss: 0] [VAE loss: 1.768505334854126]\n",
      "1610 [D loss: 0] [G loss: 0] [VAE loss: 1.8570358753204346]\n",
      "1611 [D loss: 0] [G loss: 0] [VAE loss: 1.5965211391448975]\n",
      "1612 [D loss: 0] [G loss: 0] [VAE loss: 1.7586281299591064]\n",
      "1613 [D loss: 0] [G loss: 0] [VAE loss: 1.765181541442871]\n",
      "1614 [D loss: 0] [G loss: 0] [VAE loss: 1.892404556274414]\n",
      "1615 [D loss: 0] [G loss: 0] [VAE loss: 1.8619487285614014]\n",
      "1616 [D loss: 0] [G loss: 0] [VAE loss: 1.777538537979126]\n",
      "1617 [D loss: 0] [G loss: 0] [VAE loss: 1.859062910079956]\n",
      "1618 [D loss: 0] [G loss: 0] [VAE loss: 1.835871696472168]\n",
      "1619 [D loss: 0] [G loss: 0] [VAE loss: 1.769081950187683]\n",
      "1620 [D loss: 0] [G loss: 0] [VAE loss: 1.7665481567382812]\n",
      "1621 [D loss: 0] [G loss: 0] [VAE loss: 1.8959540128707886]\n",
      "1622 [D loss: 0] [G loss: 0] [VAE loss: 1.6971697807312012]\n",
      "1623 [D loss: 0] [G loss: 0] [VAE loss: 1.8052152395248413]\n",
      "1624 [D loss: 0] [G loss: 0] [VAE loss: 1.7734755277633667]\n",
      "1625 [D loss: 0] [G loss: 0] [VAE loss: 1.6986316442489624]\n",
      "1626 [D loss: 0] [G loss: 0] [VAE loss: 1.8366879224777222]\n",
      "1627 [D loss: 0] [G loss: 0] [VAE loss: 1.7031562328338623]\n",
      "1628 [D loss: 0] [G loss: 0] [VAE loss: 1.6261743307113647]\n",
      "1629 [D loss: 0] [G loss: 0] [VAE loss: 1.8302359580993652]\n",
      "1630 [D loss: 0] [G loss: 0] [VAE loss: 1.696171522140503]\n",
      "1631 [D loss: 0] [G loss: 0] [VAE loss: 1.6977115869522095]\n",
      "1632 [D loss: 0] [G loss: 0] [VAE loss: 1.6385953426361084]\n",
      "1633 [D loss: 0] [G loss: 0] [VAE loss: 1.7656323909759521]\n",
      "1634 [D loss: 0] [G loss: 0] [VAE loss: 1.679559350013733]\n",
      "1635 [D loss: 0] [G loss: 0] [VAE loss: 1.711318850517273]\n",
      "1636 [D loss: 0] [G loss: 0] [VAE loss: 1.8470227718353271]\n",
      "1637 [D loss: 0] [G loss: 0] [VAE loss: 1.8911844491958618]\n",
      "1638 [D loss: 0] [G loss: 0] [VAE loss: 1.7965506315231323]\n",
      "1639 [D loss: 0] [G loss: 0] [VAE loss: 1.6931612491607666]\n",
      "1640 [D loss: 0] [G loss: 0] [VAE loss: 1.8871098756790161]\n",
      "1641 [D loss: 0] [G loss: 0] [VAE loss: 1.7784583568572998]\n",
      "1642 [D loss: 0] [G loss: 0] [VAE loss: 1.713159441947937]\n",
      "1643 [D loss: 0] [G loss: 0] [VAE loss: 1.6756550073623657]\n",
      "1644 [D loss: 0] [G loss: 0] [VAE loss: 1.928750991821289]\n",
      "1645 [D loss: 0] [G loss: 0] [VAE loss: 1.6649866104125977]\n",
      "1646 [D loss: 0] [G loss: 0] [VAE loss: 1.7582902908325195]\n",
      "1647 [D loss: 0] [G loss: 0] [VAE loss: 1.8325002193450928]\n",
      "1648 [D loss: 0] [G loss: 0] [VAE loss: 1.8597602844238281]\n",
      "1649 [D loss: 0] [G loss: 0] [VAE loss: 1.7605178356170654]\n",
      "1650 [D loss: 0] [G loss: 0] [VAE loss: 1.824749231338501]\n",
      "1651 [D loss: 0] [G loss: 0] [VAE loss: 1.855193018913269]\n",
      "1652 [D loss: 0] [G loss: 0] [VAE loss: 1.7282733917236328]\n",
      "1653 [D loss: 0] [G loss: 0] [VAE loss: 1.650411605834961]\n",
      "1654 [D loss: 0] [G loss: 0] [VAE loss: 1.7863101959228516]\n",
      "1655 [D loss: 0] [G loss: 0] [VAE loss: 1.8303896188735962]\n",
      "1656 [D loss: 0] [G loss: 0] [VAE loss: 1.7897354364395142]\n",
      "1657 [D loss: 0] [G loss: 0] [VAE loss: 1.892788052558899]\n",
      "1658 [D loss: 0] [G loss: 0] [VAE loss: 1.8074036836624146]\n",
      "1659 [D loss: 0] [G loss: 0] [VAE loss: 1.7173144817352295]\n",
      "1660 [D loss: 0] [G loss: 0] [VAE loss: 1.8148865699768066]\n",
      "1661 [D loss: 0] [G loss: 0] [VAE loss: 1.7178571224212646]\n",
      "1662 [D loss: 0] [G loss: 0] [VAE loss: 1.7845768928527832]\n",
      "1663 [D loss: 0] [G loss: 0] [VAE loss: 1.7265514135360718]\n",
      "1664 [D loss: 0] [G loss: 0] [VAE loss: 1.7622008323669434]\n",
      "1665 [D loss: 0] [G loss: 0] [VAE loss: 1.5797052383422852]\n",
      "1666 [D loss: 0] [G loss: 0] [VAE loss: 1.7585927248001099]\n",
      "1667 [D loss: 0] [G loss: 0] [VAE loss: 1.7233052253723145]\n",
      "1668 [D loss: 0] [G loss: 0] [VAE loss: 1.749803066253662]\n",
      "1669 [D loss: 0] [G loss: 0] [VAE loss: 1.7766399383544922]\n",
      "1670 [D loss: 0] [G loss: 0] [VAE loss: 1.7169272899627686]\n",
      "1671 [D loss: 0] [G loss: 0] [VAE loss: 1.5908254384994507]\n",
      "1672 [D loss: 0] [G loss: 0] [VAE loss: 1.688083529472351]\n",
      "1673 [D loss: 0] [G loss: 0] [VAE loss: 1.7816622257232666]\n",
      "1674 [D loss: 0] [G loss: 0] [VAE loss: 1.7364040613174438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1675 [D loss: 0] [G loss: 0] [VAE loss: 1.7895267009735107]\n",
      "1676 [D loss: 0] [G loss: 0] [VAE loss: 1.7168998718261719]\n",
      "1677 [D loss: 0] [G loss: 0] [VAE loss: 1.5805761814117432]\n",
      "1678 [D loss: 0] [G loss: 0] [VAE loss: 1.7258816957473755]\n",
      "1679 [D loss: 0] [G loss: 0] [VAE loss: 1.629758596420288]\n",
      "1680 [D loss: 0] [G loss: 0] [VAE loss: 1.6741896867752075]\n",
      "1681 [D loss: 0] [G loss: 0] [VAE loss: 1.8828529119491577]\n",
      "1682 [D loss: 0] [G loss: 0] [VAE loss: 1.7771379947662354]\n",
      "1683 [D loss: 0] [G loss: 0] [VAE loss: 1.645371437072754]\n",
      "1684 [D loss: 0] [G loss: 0] [VAE loss: 1.8427249193191528]\n",
      "1685 [D loss: 0] [G loss: 0] [VAE loss: 1.6503878831863403]\n",
      "1686 [D loss: 0] [G loss: 0] [VAE loss: 1.7806668281555176]\n",
      "1687 [D loss: 0] [G loss: 0] [VAE loss: 1.7892980575561523]\n",
      "1688 [D loss: 0] [G loss: 0] [VAE loss: 1.8203959465026855]\n",
      "1689 [D loss: 0] [G loss: 0] [VAE loss: 1.8614654541015625]\n",
      "1690 [D loss: 0] [G loss: 0] [VAE loss: 1.7441394329071045]\n",
      "1691 [D loss: 0] [G loss: 0] [VAE loss: 1.8575286865234375]\n",
      "1692 [D loss: 0] [G loss: 0] [VAE loss: 1.6640430688858032]\n",
      "1693 [D loss: 0] [G loss: 0] [VAE loss: 1.8479386568069458]\n",
      "1694 [D loss: 0] [G loss: 0] [VAE loss: 1.8464505672454834]\n",
      "1695 [D loss: 0] [G loss: 0] [VAE loss: 1.9179110527038574]\n",
      "1696 [D loss: 0] [G loss: 0] [VAE loss: 1.7706083059310913]\n",
      "1697 [D loss: 0] [G loss: 0] [VAE loss: 1.8229273557662964]\n",
      "1698 [D loss: 0] [G loss: 0] [VAE loss: 1.9099353551864624]\n",
      "1699 [D loss: 0] [G loss: 0] [VAE loss: 1.7578846216201782]\n",
      "1700 [D loss: 0] [G loss: 0] [VAE loss: 1.741775393486023]\n",
      "1701 [D loss: 0] [G loss: 0] [VAE loss: 1.8313193321228027]\n",
      "1702 [D loss: 0] [G loss: 0] [VAE loss: 1.7301061153411865]\n",
      "1703 [D loss: 0] [G loss: 0] [VAE loss: 1.6978777647018433]\n",
      "1704 [D loss: 0] [G loss: 0] [VAE loss: 1.8160037994384766]\n",
      "1705 [D loss: 0] [G loss: 0] [VAE loss: 1.8417414426803589]\n",
      "1706 [D loss: 0] [G loss: 0] [VAE loss: 1.7460086345672607]\n",
      "1707 [D loss: 0] [G loss: 0] [VAE loss: 1.6658260822296143]\n",
      "1708 [D loss: 0] [G loss: 0] [VAE loss: 1.805640697479248]\n",
      "1709 [D loss: 0] [G loss: 0] [VAE loss: 1.6999702453613281]\n",
      "1710 [D loss: 0] [G loss: 0] [VAE loss: 1.722700595855713]\n",
      "1711 [D loss: 0] [G loss: 0] [VAE loss: 1.7825303077697754]\n",
      "1712 [D loss: 0] [G loss: 0] [VAE loss: 1.8926643133163452]\n",
      "1713 [D loss: 0] [G loss: 0] [VAE loss: 1.9531188011169434]\n",
      "1714 [D loss: 0] [G loss: 0] [VAE loss: 1.8279428482055664]\n",
      "1715 [D loss: 0] [G loss: 0] [VAE loss: 1.9696999788284302]\n",
      "1716 [D loss: 0] [G loss: 0] [VAE loss: 1.7621687650680542]\n",
      "1717 [D loss: 0] [G loss: 0] [VAE loss: 1.6082082986831665]\n",
      "1718 [D loss: 0] [G loss: 0] [VAE loss: 1.696487545967102]\n",
      "1719 [D loss: 0] [G loss: 0] [VAE loss: 1.6395639181137085]\n",
      "1720 [D loss: 0] [G loss: 0] [VAE loss: 1.7953861951828003]\n",
      "1721 [D loss: 0] [G loss: 0] [VAE loss: 1.6680209636688232]\n",
      "1722 [D loss: 0] [G loss: 0] [VAE loss: 1.9139955043792725]\n",
      "1723 [D loss: 0] [G loss: 0] [VAE loss: 1.8186542987823486]\n",
      "1724 [D loss: 0] [G loss: 0] [VAE loss: 1.8500268459320068]\n",
      "1725 [D loss: 0] [G loss: 0] [VAE loss: 1.7229236364364624]\n",
      "1726 [D loss: 0] [G loss: 0] [VAE loss: 1.703972578048706]\n",
      "1727 [D loss: 0] [G loss: 0] [VAE loss: 1.8105087280273438]\n",
      "1728 [D loss: 0] [G loss: 0] [VAE loss: 1.8970303535461426]\n",
      "1729 [D loss: 0] [G loss: 0] [VAE loss: 1.708514928817749]\n",
      "1730 [D loss: 0] [G loss: 0] [VAE loss: 1.7335255146026611]\n",
      "1731 [D loss: 0] [G loss: 0] [VAE loss: 1.7317932844161987]\n",
      "1732 [D loss: 0] [G loss: 0] [VAE loss: 1.818560242652893]\n",
      "1733 [D loss: 0] [G loss: 0] [VAE loss: 1.8087093830108643]\n",
      "1734 [D loss: 0] [G loss: 0] [VAE loss: 1.7453209161758423]\n",
      "1735 [D loss: 0] [G loss: 0] [VAE loss: 1.7539039850234985]\n",
      "1736 [D loss: 0] [G loss: 0] [VAE loss: 1.7182626724243164]\n",
      "1737 [D loss: 0] [G loss: 0] [VAE loss: 1.748201847076416]\n",
      "1738 [D loss: 0] [G loss: 0] [VAE loss: 1.731795072555542]\n",
      "1739 [D loss: 0] [G loss: 0] [VAE loss: 1.6702239513397217]\n",
      "1740 [D loss: 0] [G loss: 0] [VAE loss: 1.8676925897598267]\n",
      "1741 [D loss: 0] [G loss: 0] [VAE loss: 1.8266735076904297]\n",
      "1742 [D loss: 0] [G loss: 0] [VAE loss: 1.99674654006958]\n",
      "1743 [D loss: 0] [G loss: 0] [VAE loss: 1.7667531967163086]\n",
      "1744 [D loss: 0] [G loss: 0] [VAE loss: 1.7262365818023682]\n",
      "1745 [D loss: 0] [G loss: 0] [VAE loss: 1.7725458145141602]\n",
      "1746 [D loss: 0] [G loss: 0] [VAE loss: 1.8102011680603027]\n",
      "1747 [D loss: 0] [G loss: 0] [VAE loss: 1.7761801481246948]\n",
      "1748 [D loss: 0] [G loss: 0] [VAE loss: 1.6949132680892944]\n",
      "1749 [D loss: 0] [G loss: 0] [VAE loss: 1.6985750198364258]\n",
      "1750 [D loss: 0] [G loss: 0] [VAE loss: 1.853224515914917]\n",
      "1751 [D loss: 0] [G loss: 0] [VAE loss: 1.6160821914672852]\n",
      "1752 [D loss: 0] [G loss: 0] [VAE loss: 1.7934637069702148]\n",
      "1753 [D loss: 0] [G loss: 0] [VAE loss: 1.6742407083511353]\n",
      "1754 [D loss: 0] [G loss: 0] [VAE loss: 1.9286563396453857]\n",
      "1755 [D loss: 0] [G loss: 0] [VAE loss: 1.7330939769744873]\n",
      "1756 [D loss: 0] [G loss: 0] [VAE loss: 1.6668964624404907]\n",
      "1757 [D loss: 0] [G loss: 0] [VAE loss: 1.7961764335632324]\n",
      "1758 [D loss: 0] [G loss: 0] [VAE loss: 1.7146124839782715]\n",
      "1759 [D loss: 0] [G loss: 0] [VAE loss: 1.88312828540802]\n",
      "1760 [D loss: 0] [G loss: 0] [VAE loss: 1.737886667251587]\n",
      "1761 [D loss: 0] [G loss: 0] [VAE loss: 1.9578115940093994]\n",
      "1762 [D loss: 0] [G loss: 0] [VAE loss: 1.821254014968872]\n",
      "1763 [D loss: 0] [G loss: 0] [VAE loss: 1.709991693496704]\n",
      "1764 [D loss: 0] [G loss: 0] [VAE loss: 1.7123994827270508]\n",
      "1765 [D loss: 0] [G loss: 0] [VAE loss: 1.8124451637268066]\n",
      "1766 [D loss: 0] [G loss: 0] [VAE loss: 1.7480294704437256]\n",
      "1767 [D loss: 0] [G loss: 0] [VAE loss: 1.7015957832336426]\n",
      "1768 [D loss: 0] [G loss: 0] [VAE loss: 1.6154017448425293]\n",
      "1769 [D loss: 0] [G loss: 0] [VAE loss: 1.7439020872116089]\n",
      "1770 [D loss: 0] [G loss: 0] [VAE loss: 1.628000020980835]\n",
      "1771 [D loss: 0] [G loss: 0] [VAE loss: 1.7809581756591797]\n",
      "1772 [D loss: 0] [G loss: 0] [VAE loss: 1.825693130493164]\n",
      "1773 [D loss: 0] [G loss: 0] [VAE loss: 1.6719379425048828]\n",
      "1774 [D loss: 0] [G loss: 0] [VAE loss: 1.8423004150390625]\n",
      "1775 [D loss: 0] [G loss: 0] [VAE loss: 1.6890325546264648]\n",
      "1776 [D loss: 0] [G loss: 0] [VAE loss: 1.8222432136535645]\n",
      "1777 [D loss: 0] [G loss: 0] [VAE loss: 1.6991394758224487]\n",
      "1778 [D loss: 0] [G loss: 0] [VAE loss: 1.769056797027588]\n",
      "1779 [D loss: 0] [G loss: 0] [VAE loss: 1.9722968339920044]\n",
      "1780 [D loss: 0] [G loss: 0] [VAE loss: 1.8608057498931885]\n",
      "1781 [D loss: 0] [G loss: 0] [VAE loss: 1.8346331119537354]\n",
      "1782 [D loss: 0] [G loss: 0] [VAE loss: 1.76785409450531]\n",
      "1783 [D loss: 0] [G loss: 0] [VAE loss: 1.8612959384918213]\n",
      "1784 [D loss: 0] [G loss: 0] [VAE loss: 1.8205366134643555]\n",
      "1785 [D loss: 0] [G loss: 0] [VAE loss: 1.6823959350585938]\n",
      "1786 [D loss: 0] [G loss: 0] [VAE loss: 1.9268816709518433]\n",
      "1787 [D loss: 0] [G loss: 0] [VAE loss: 1.7898255586624146]\n",
      "1788 [D loss: 0] [G loss: 0] [VAE loss: 1.6714468002319336]\n",
      "1789 [D loss: 0] [G loss: 0] [VAE loss: 1.9655498266220093]\n",
      "1790 [D loss: 0] [G loss: 0] [VAE loss: 1.6631454229354858]\n",
      "1791 [D loss: 0] [G loss: 0] [VAE loss: 1.6563395261764526]\n",
      "1792 [D loss: 0] [G loss: 0] [VAE loss: 1.6182911396026611]\n",
      "1793 [D loss: 0] [G loss: 0] [VAE loss: 1.6379343271255493]\n",
      "1794 [D loss: 0] [G loss: 0] [VAE loss: 1.793990135192871]\n",
      "1795 [D loss: 0] [G loss: 0] [VAE loss: 1.6496667861938477]\n",
      "1796 [D loss: 0] [G loss: 0] [VAE loss: 1.8475425243377686]\n",
      "1797 [D loss: 0] [G loss: 0] [VAE loss: 1.7314635515213013]\n",
      "1798 [D loss: 0] [G loss: 0] [VAE loss: 1.7959251403808594]\n",
      "1799 [D loss: 0] [G loss: 0] [VAE loss: 1.7302441596984863]\n",
      "1800 [D loss: 0] [G loss: 0] [VAE loss: 1.7409502267837524]\n",
      "1801 [D loss: 0] [G loss: 0] [VAE loss: 1.67317533493042]\n",
      "1802 [D loss: 0] [G loss: 0] [VAE loss: 1.8222887516021729]\n",
      "1803 [D loss: 0] [G loss: 0] [VAE loss: 1.700918436050415]\n",
      "1804 [D loss: 0] [G loss: 0] [VAE loss: 1.8021008968353271]\n",
      "1805 [D loss: 0] [G loss: 0] [VAE loss: 1.5855921506881714]\n",
      "1806 [D loss: 0] [G loss: 0] [VAE loss: 1.8039095401763916]\n",
      "1807 [D loss: 0] [G loss: 0] [VAE loss: 1.7807910442352295]\n",
      "1808 [D loss: 0] [G loss: 0] [VAE loss: 1.7282154560089111]\n",
      "1809 [D loss: 0] [G loss: 0] [VAE loss: 1.7446969747543335]\n",
      "1810 [D loss: 0] [G loss: 0] [VAE loss: 1.737524390220642]\n",
      "1811 [D loss: 0] [G loss: 0] [VAE loss: 1.7512407302856445]\n",
      "1812 [D loss: 0] [G loss: 0] [VAE loss: 1.8639172315597534]\n",
      "1813 [D loss: 0] [G loss: 0] [VAE loss: 1.8022212982177734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814 [D loss: 0] [G loss: 0] [VAE loss: 1.8782474994659424]\n",
      "1815 [D loss: 0] [G loss: 0] [VAE loss: 1.8511292934417725]\n",
      "1816 [D loss: 0] [G loss: 0] [VAE loss: 1.8208189010620117]\n",
      "1817 [D loss: 0] [G loss: 0] [VAE loss: 1.7829867601394653]\n",
      "1818 [D loss: 0] [G loss: 0] [VAE loss: 1.773116111755371]\n",
      "1819 [D loss: 0] [G loss: 0] [VAE loss: 1.814507246017456]\n",
      "1820 [D loss: 0] [G loss: 0] [VAE loss: 1.733324646949768]\n",
      "1821 [D loss: 0] [G loss: 0] [VAE loss: 1.8831011056900024]\n",
      "1822 [D loss: 0] [G loss: 0] [VAE loss: 1.7115528583526611]\n",
      "1823 [D loss: 0] [G loss: 0] [VAE loss: 1.8111135959625244]\n",
      "1824 [D loss: 0] [G loss: 0] [VAE loss: 1.6554784774780273]\n",
      "1825 [D loss: 0] [G loss: 0] [VAE loss: 1.6188312768936157]\n",
      "1826 [D loss: 0] [G loss: 0] [VAE loss: 1.6271445751190186]\n",
      "1827 [D loss: 0] [G loss: 0] [VAE loss: 1.560050368309021]\n",
      "1828 [D loss: 0] [G loss: 0] [VAE loss: 1.8055133819580078]\n",
      "1829 [D loss: 0] [G loss: 0] [VAE loss: 1.624876618385315]\n",
      "1830 [D loss: 0] [G loss: 0] [VAE loss: 1.72711181640625]\n",
      "1831 [D loss: 0] [G loss: 0] [VAE loss: 1.6610181331634521]\n",
      "1832 [D loss: 0] [G loss: 0] [VAE loss: 1.8724825382232666]\n",
      "1833 [D loss: 0] [G loss: 0] [VAE loss: 1.707175374031067]\n",
      "1834 [D loss: 0] [G loss: 0] [VAE loss: 1.7736257314682007]\n",
      "1835 [D loss: 0] [G loss: 0] [VAE loss: 1.7787108421325684]\n",
      "1836 [D loss: 0] [G loss: 0] [VAE loss: 1.771620512008667]\n",
      "1837 [D loss: 0] [G loss: 0] [VAE loss: 1.9284218549728394]\n",
      "1838 [D loss: 0] [G loss: 0] [VAE loss: 1.9591996669769287]\n",
      "1839 [D loss: 0] [G loss: 0] [VAE loss: 1.7852425575256348]\n",
      "1840 [D loss: 0] [G loss: 0] [VAE loss: 1.9216225147247314]\n",
      "1841 [D loss: 0] [G loss: 0] [VAE loss: 1.6984848976135254]\n",
      "1842 [D loss: 0] [G loss: 0] [VAE loss: 1.8557631969451904]\n",
      "1843 [D loss: 0] [G loss: 0] [VAE loss: 1.7366257905960083]\n",
      "1844 [D loss: 0] [G loss: 0] [VAE loss: 1.870089054107666]\n",
      "1845 [D loss: 0] [G loss: 0] [VAE loss: 2.008984327316284]\n",
      "1846 [D loss: 0] [G loss: 0] [VAE loss: 1.8091721534729004]\n",
      "1847 [D loss: 0] [G loss: 0] [VAE loss: 1.659937858581543]\n",
      "1848 [D loss: 0] [G loss: 0] [VAE loss: 1.7849109172821045]\n",
      "1849 [D loss: 0] [G loss: 0] [VAE loss: 1.8679556846618652]\n",
      "1850 [D loss: 0] [G loss: 0] [VAE loss: 1.788642168045044]\n",
      "1851 [D loss: 0] [G loss: 0] [VAE loss: 1.679952621459961]\n",
      "1852 [D loss: 0] [G loss: 0] [VAE loss: 1.8546395301818848]\n",
      "1853 [D loss: 0] [G loss: 0] [VAE loss: 1.670247197151184]\n",
      "1854 [D loss: 0] [G loss: 0] [VAE loss: 1.7533904314041138]\n",
      "1855 [D loss: 0] [G loss: 0] [VAE loss: 1.6724984645843506]\n",
      "1856 [D loss: 0] [G loss: 0] [VAE loss: 1.730806827545166]\n",
      "1857 [D loss: 0] [G loss: 0] [VAE loss: 1.809220552444458]\n",
      "1858 [D loss: 0] [G loss: 0] [VAE loss: 1.9617905616760254]\n",
      "1859 [D loss: 0] [G loss: 0] [VAE loss: 1.6251966953277588]\n",
      "1860 [D loss: 0] [G loss: 0] [VAE loss: 1.7592836618423462]\n",
      "1861 [D loss: 0] [G loss: 0] [VAE loss: 1.9199994802474976]\n",
      "1862 [D loss: 0] [G loss: 0] [VAE loss: 2.0174412727355957]\n",
      "1863 [D loss: 0] [G loss: 0] [VAE loss: 1.7064696550369263]\n",
      "1864 [D loss: 0] [G loss: 0] [VAE loss: 1.7309621572494507]\n",
      "1865 [D loss: 0] [G loss: 0] [VAE loss: 1.7094523906707764]\n",
      "1866 [D loss: 0] [G loss: 0] [VAE loss: 1.7854657173156738]\n",
      "1867 [D loss: 0] [G loss: 0] [VAE loss: 1.8049871921539307]\n",
      "1868 [D loss: 0] [G loss: 0] [VAE loss: 1.738191843032837]\n",
      "1869 [D loss: 0] [G loss: 0] [VAE loss: 1.8438442945480347]\n",
      "1870 [D loss: 0] [G loss: 0] [VAE loss: 1.7226827144622803]\n",
      "1871 [D loss: 0] [G loss: 0] [VAE loss: 1.824664831161499]\n",
      "1872 [D loss: 0] [G loss: 0] [VAE loss: 1.728017807006836]\n",
      "1873 [D loss: 0] [G loss: 0] [VAE loss: 1.6139649152755737]\n",
      "1874 [D loss: 0] [G loss: 0] [VAE loss: 1.811453938484192]\n",
      "1875 [D loss: 0] [G loss: 0] [VAE loss: 1.9067777395248413]\n",
      "1876 [D loss: 0] [G loss: 0] [VAE loss: 1.8733983039855957]\n",
      "1877 [D loss: 0] [G loss: 0] [VAE loss: 1.9118403196334839]\n",
      "1878 [D loss: 0] [G loss: 0] [VAE loss: 1.6891531944274902]\n",
      "1879 [D loss: 0] [G loss: 0] [VAE loss: 1.76700758934021]\n",
      "1880 [D loss: 0] [G loss: 0] [VAE loss: 1.8201736211776733]\n",
      "1881 [D loss: 0] [G loss: 0] [VAE loss: 1.7224533557891846]\n",
      "1882 [D loss: 0] [G loss: 0] [VAE loss: 1.9075074195861816]\n",
      "1883 [D loss: 0] [G loss: 0] [VAE loss: 1.660719871520996]\n",
      "1884 [D loss: 0] [G loss: 0] [VAE loss: 1.6706395149230957]\n",
      "1885 [D loss: 0] [G loss: 0] [VAE loss: 1.721938133239746]\n"
     ]
    }
   ],
   "source": [
    "svg = SVG(inputs, spectralnet=spectral_net, orig_dim=x_train.shape[-1], latent_dim=latent_dim)\n",
    "svg.train_gan(x_train, epochs=2000, n_critic=5, n_vae=20)\n",
    "x_gen = svg.generate_from_samples(x_train)\n",
    "plot(x_gen, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "n_items = 1\n",
    "x_gen = np.zeros((n_samples*n_items, x_train.shape[1]))\n",
    "y_gen = np.zeros((n_samples*n_items,))\n",
    "step = int(len(x_test) / n_items)\n",
    "for i in range(n_samples):\n",
    "    for n in range(n_items):\n",
    "#         print(n_items*i + n, n*step, step)\n",
    "        x_gen[n_items*i + n,:] = x_test[n*step,:]\n",
    "        y_gen[n_items*i + n] = y_test[n*step]\n",
    "    \n",
    "x_gen = svg.generate_from_samples(x_gen)\n",
    "plot(x_gen, y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: nbAgg\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = svg.generate_from_samples(x_test)\n",
    "if dataset == 'mnist':\n",
    "    n_imgs = 10\n",
    "    # num = 7\n",
    "    # sub = y_test == num\n",
    "    sub = y_test == y_test\n",
    "    for i in range(n_imgs):\n",
    "        idx = np.random.randint(len(x[sub]))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(x_test[sub][idx].reshape(28, 28))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(x[sub][idx].reshape(28, 28))\n",
    "        plt.figure()\n",
    "else:\n",
    "    %matplotlib\n",
    "    plot(x, y_test, x2=x_test, y2=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of neighbors within one standard deviation of each element in x_test\n",
    "get_distr = K.function([svg.inputs], [svg.sigma, svg.mu])\n",
    "_sigma, _mu = predict_with_K_fn(get_distr, x_test)\n",
    "_sigma = np.exp(_sigma)\n",
    "\n",
    "num_close = []\n",
    "for i in range(len(_sigma)):\n",
    "    s, m = _sigma[i,:], _mu[i,:]\n",
    "    scaled_dists = (_mu - m)/s\n",
    "    # consider as neighbors all points within the variance of x_i\n",
    "    less_than_std = np.abs(scaled_dists) < 1\n",
    "    less_than_std = np.logical_and(less_than_std[:,0], less_than_std[:,1])\n",
    "    # split neighbors into those of the same class and those of a different class\n",
    "    same, diff = (y_test[less_than_std] == y_test[i]), (y_test[less_than_std] != y_test[i])\n",
    "    num_close.append((np.sum(same), np.sum(diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg.x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiate decoder with respect to inputs to compute another jacobian, and then evaluate it on the same point\n",
    "_jacobian = [tf.expand_dims(tf.gradients(svg.x_recon[:,i], svg.x_enc)[0], 1) for i in range(svg.x_recon.shape[1])]\n",
    "jacobian = tf.reduce_sum(tf.concat(_jacobian, axis=1), axis=0)\n",
    "B = tf.diag(tf.exp(tf.reduce_sum(svg.sigma, axis=0)) ** 2)\n",
    "cov = tf.matmul(jacobian, tf.matmul(B, jacobian, transpose_b=True))\n",
    "cov = tf.reshape(cov, (x_test[0].shape[0], x_test[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create burst from a point and compute covariance matrix\n",
    "burst_size = 1000\n",
    "rand_idx = np.random.randint(len(x_test))\n",
    "x_ = x_test[rand_idx]\n",
    "x_arr = np.array([x_] * burst_size)\n",
    "x_rec = svg.generate_from_samples(x_arr)\n",
    "\n",
    "cov_burst = np.cov((x_rec - np.mean(x_rec, axis=0)).T)\n",
    "\n",
    "# run gradient burst\n",
    "# cov_grad = K.get_session().run([svg.x_recon, cov, B, jacobian], feed_dict={svg.input: np.array([x_]*1)})\n",
    "cov_grad = K.get_session().run([cov], feed_dict={svg.input: np.array([x_]*1)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2140033e-05, 4.2225918e-05],\n",
       "       [4.2225918e-05, 4.2312946e-05]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00160175, 0.00160529],\n",
       "       [0.00160529, 0.00160883]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_burst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_burst: [4.44890386e-08 3.43059085e-03] [1.00000000e+00 7.71109235e+04]\n",
      "l_grad: [1.2267446e-04 5.0271858e-09] [1.000000e+00 4.097989e-05]\n"
     ]
    }
   ],
   "source": [
    "l_burst, _ = np.linalg.eig(cov_burst)\n",
    "l_grad, _ = np.linalg.eig(cov_grad)\n",
    "print('l_burst:', l_burst, l_burst/l_burst[0])\n",
    "print('l_grad:', l_grad, l_grad/l_grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49850416, 0.4999978 ],\n",
       "       [0.49999774, 0.50149584]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_grad/np.linalg.norm(cov_grad, 'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50061509, 0.4999955 ],\n",
       "       [0.4999955 , 0.49939317]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_burst/np.linalg.norm(cov_burst, 'fro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x_rec, x2=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(x_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1034.35929648, -615.64070352],\n",
       "       [-615.64070352, 1034.35929648]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[x for x in range(100)] + [0 for x in range(100)], [0 for x in range(100)] + [x for x in range(100)]])\n",
    "np.cov(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7ccee40898>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test[0,:], test[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
